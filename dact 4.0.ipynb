{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DACT : Dataset Automatic Crawling Tools\n",
    "\n",
    "### 검색엔진에서 입력한 키워드의 이미지를 찾아 자동으로 임시 폴더(temp)에 다운로드\n",
    "### temp의 이미지파일을 7:3 비율로 Train Set, Test Set으로 분할하여 검색어 이름의 폴더로 분할한다.\n",
    "\n",
    "#### v1.1 : PATH 안정화\n",
    "#### v1.2 : tqdm을 이용한 진행도 표시\n",
    "#### v2.0 : 키워드 리스트 저장후 멀티 크롤링 가능\n",
    "#### v2.1 : 코드셀 병합, log print 규격화\n",
    "#### v2.2 : 모든 항목 총 소요시간 계산 후 출력\n",
    "#### v2.3 : test, train 경로 버그 수정\n",
    "#### v3.0 : keras 최신 이미지 전처리 기술과 동기화하여 새로운 디렉토리 생성\n",
    "#### v4.0 : deleter 1.0과 병합하여 크롤링과 데이터 검열 동시에 수행, 데이터셋 폴더 지정가능, 접근성 강화\n",
    "\n",
    "#### 세원아토스 기술연구소 조영탁"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "remove : cat287.jpg\n",
      "remove : cat89.jpg\n",
      "remove : dog637.jpg\n",
      "3개 항목 삭제 완료\n"
     ]
    }
   ],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from bs4 import BeautifulSoup\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "import json\n",
    "import os\n",
    "import argparse\n",
    "import sys\n",
    "\n",
    "\n",
    "import requests\n",
    "import urllib\n",
    "import urllib3\n",
    "from urllib3.exceptions import InsecureRequestWarning\n",
    "\n",
    "import datetime\n",
    "import time\n",
    "import glob\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "\n",
    "urllib3.disable_warnings(InsecureRequestWarning)\n",
    "\n",
    "#searclist에 키워드 입력 (다중 입력 가능)\n",
    "#searchlist = 'tops for ladies', 'ladies outerwear', 'dress', 'ladies underwear', 'women suit', 'women pants'\n",
    "#searchlist = '여자 니트', 'tops for ladies',  '여자 맨투맨', '여자 민소매', '여자 블라우스', '여자 셔츠', '여자 티셔츠', 'lady t-shirt', '여자 상의'\n",
    "#searchlist = '여자 아우터', 'ladies outerwear',  '여자 가디건', '여자 자켓', '여자 점퍼', '여자 집업', '여자 조끼 베스트', '여자 코트', '여자 외투'\n",
    "#searchlist = '여자 원피스 -수영복', 'dress',  '여자 롱 원피스', '여자 미니 원피스', '여성 원피스', '오버롤 원피스', '여자 드레스', '여성 원피스 패션', '원피스 신상'\n",
    "#searchlist = 'women pants', '여성 바지',  '여성 슬랙스', '여성 청바지', '여성 코튼팬츠', '여자 코튼팬츠', '여자 슬랙스', '여성 신상 팬츠', '여성 와이드팬츠'\n",
    "#searchlist = 'lady skirts', 'women skirt',  '롱 스커트', '숏 스커트', '스커트 신상', '여성 스커트', '여성 치마', '여자 스커트', '치마 신상'\n",
    "#searchlist = '여자 투피스 수트', '여성 수트',  'women suit', '여자 투피스 정장', '여성 정장', '여자 정장', '여자 블레이저', '여성 블레이저', 'lady formal suit'\n",
    "\n",
    "############INSERT##############\n",
    "searchlist = 'dog', 'cat' #검색어 리스트\n",
    "pdirs = 'animal' #class 이름 입력\n",
    "path = 'testdataset' # 다운로드 경로 입력\n",
    "############INSERT##############\n",
    "\n",
    "\n",
    "namecount = 1000\n",
    "searchcount = len(searchlist)\n",
    "temp_dirs = 'temp'\n",
    "\n",
    "maxcount = 500 # 700개 이상 하위 노출 데이터는 질이 급감함.\n",
    "os.chdir('C:\\Projects\\keras_talk')\n",
    "\n",
    "chromedriver = 'C://Program Files//chromedriver//chromedriver.exe'\n",
    "#Import Chromedriver -  절대경로를 지정\n",
    "\n",
    "def download_google_staticimages(searchword):\n",
    "    \n",
    "    \n",
    "    if not os.path.exists(path +'/'):\n",
    "        os.mkdir(path +'/')\n",
    "    \n",
    "    if not os.path.exists(path +'/' + pdirs):\n",
    "        os.mkdir(path +'/'+ pdirs)\n",
    "        \n",
    "            \n",
    "    searchurl = 'https://www.google.com/search?q=' + searchword + '&source=lnms&tbm=isch'\n",
    "    options = webdriver.ChromeOptions()\n",
    "    options.add_argument('--no-sandbox')\n",
    "    #options.add_argument('--headless')\n",
    "\n",
    "    try:\n",
    "        browser = webdriver.Chrome(chromedriver, options=options)\n",
    "    except Exception as e:\n",
    "        print(f'No found chromedriver in this environment.')\n",
    "        print(f'Install on your machine. exception: {e}')\n",
    "        sys.exit()\n",
    "\n",
    "    browser.set_window_size(1280, 1024)\n",
    "    browser.get(searchurl)\n",
    "    time.sleep(1)\n",
    "\n",
    "    element = browser.find_element_by_tag_name('body')\n",
    "\n",
    "    # Scroll down\n",
    "    #for i in range(30):\n",
    "    for i in range(50):\n",
    "        element.send_keys(Keys.PAGE_DOWN)\n",
    "        time.sleep(0.3)\n",
    "\n",
    "    try:\n",
    "        browser.find_element_by_id('smb').click()\n",
    "        for i in range(50):\n",
    "            element.send_keys(Keys.PAGE_DOWN)\n",
    "            time.sleep(0.3)\n",
    "    except:\n",
    "        for i in range(10):\n",
    "            element.send_keys(Keys.PAGE_DOWN)\n",
    "            time.sleep(0.3)\n",
    "\n",
    "    time.sleep(0.5)\n",
    "    time.sleep(0.5)\n",
    "\n",
    "    browser.find_element_by_xpath('//input[@value=\"결과 더보기\"]').click() #\n",
    "\n",
    "    # Scroll down 2\n",
    "    for i in range(50):\n",
    "        element.send_keys(Keys.PAGE_DOWN)\n",
    "        time.sleep(0.3)\n",
    "\n",
    "    try:\n",
    "        browser.find_element_by_id('smb').click()\n",
    "        for i in range(50):\n",
    "            element.send_keys(Keys.PAGE_DOWN)\n",
    "            time.sleep(0.3)\n",
    "    except:\n",
    "        for i in range(10):\n",
    "            element.send_keys(Keys.PAGE_DOWN)\n",
    "            time.sleep(0.3)\n",
    "            \n",
    "    print('     - Scrolling -> OK')\n",
    "    page_source = browser.page_source \n",
    "\n",
    "    soup = BeautifulSoup(page_source, 'lxml')\n",
    "    images = soup.find_all('img')\n",
    "\n",
    "    urls = []\n",
    "    for image in images:\n",
    "        try:\n",
    "            url = image['data-src']\n",
    "            if not url.find('https://'):\n",
    "                urls.append(url)\n",
    "        except:\n",
    "            try:\n",
    "                url = image['src']\n",
    "                if not url.find('https://'):\n",
    "                    urls.append(image['src'])\n",
    "            except Exception as e:\n",
    "                print(f'     - No found image sources.')\n",
    "                print(e)\n",
    "\n",
    "    count = 0\n",
    "    if urls:\n",
    "        for url in tqdm(urls):\n",
    "            try:\n",
    "                res = requests.get(url, verify=False, stream=True)\n",
    "                rawdata = res.raw.read()\n",
    "                with open(os.path.join(path +'/'+ pdirs + '/', searchword + str(count) + '.jpg'), 'wb') as f:\n",
    "                    f.write(rawdata)\n",
    "                    count += 1\n",
    "            except Exception as e:\n",
    "                print('     - Failed to write rawdata.')\n",
    "                print(e)      \n",
    "                \n",
    "                \n",
    "    os.path.join('C:\\Projects\\keras_talk')\n",
    "    browser.close()\n",
    "    return count\n",
    "    \n",
    "\n",
    "\n",
    "# Main block\n",
    "def main():\n",
    "    t0 = time.time()\n",
    "    for i in range(searchcount):\n",
    "        print('::: ' + searchlist[i] + ' -> Start Crawling. (' + str(i+1) + '/' + str(len(searchlist)) +')' + ' :::')\n",
    "        count = download_google_staticimages(searchlist[i])\n",
    "        print(f'\\n')\n",
    "    t1 = time.time()\n",
    "    total_time = t1 - t0\n",
    "    print(f'\\n')\n",
    "    print('::: '+str(len(searchlist)) + f'개 항목 총 소요 시간 : {str(total_time)} seconds.' + ' :::')\n",
    "    print(f'\\n')\n",
    "    \n",
    "    count = 0\n",
    "    os.chdir('C:/Projects/keras_talk/'+ path+ '/' + pdirs)\n",
    "    img_list = glob.glob('*.*')\n",
    "\n",
    "    for i in range(len(img_list)):\n",
    "        im = Image.open(img_list[i])\n",
    "\n",
    "        if((im.size[0] * 3.3 < im.size[1]) or (im.size[0] > im.size[1] * 3.3)) :\n",
    "            im.close()\n",
    "            #os.remove(img_list[i])\n",
    "            print('remove : ' + img_list[i])\n",
    "            count = count + 1\n",
    "\n",
    "    print(str(count) + '개 항목 삭제 완료')\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
