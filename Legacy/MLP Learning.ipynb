{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1000\n",
      "700/700 [==============================] - 0s 117us/step - loss: 2.2742 - accuracy: 0.1671 - val_loss: 2.2597 - val_accuracy: 0.1300\n",
      "Epoch 2/1000\n",
      "700/700 [==============================] - 0s 57us/step - loss: 2.2169 - accuracy: 0.1714 - val_loss: 2.2258 - val_accuracy: 0.1333\n",
      "Epoch 3/1000\n",
      "700/700 [==============================] - 0s 58us/step - loss: 2.1781 - accuracy: 0.1829 - val_loss: 2.2017 - val_accuracy: 0.1367\n",
      "Epoch 4/1000\n",
      "700/700 [==============================] - 0s 57us/step - loss: 2.1490 - accuracy: 0.1814 - val_loss: 2.1814 - val_accuracy: 0.1533\n",
      "Epoch 5/1000\n",
      "700/700 [==============================] - 0s 54us/step - loss: 2.1255 - accuracy: 0.1957 - val_loss: 2.1630 - val_accuracy: 0.1633\n",
      "Epoch 6/1000\n",
      "700/700 [==============================] - 0s 53us/step - loss: 2.1043 - accuracy: 0.2086 - val_loss: 2.1468 - val_accuracy: 0.1733\n",
      "Epoch 7/1000\n",
      "700/700 [==============================] - 0s 54us/step - loss: 2.0846 - accuracy: 0.2186 - val_loss: 2.1303 - val_accuracy: 0.2100\n",
      "Epoch 8/1000\n",
      "700/700 [==============================] - 0s 53us/step - loss: 2.0656 - accuracy: 0.2400 - val_loss: 2.1140 - val_accuracy: 0.2100\n",
      "Epoch 9/1000\n",
      "700/700 [==============================] - 0s 54us/step - loss: 2.0468 - accuracy: 0.2543 - val_loss: 2.0955 - val_accuracy: 0.2333\n",
      "Epoch 10/1000\n",
      "700/700 [==============================] - 0s 57us/step - loss: 2.0265 - accuracy: 0.2614 - val_loss: 2.0759 - val_accuracy: 0.2333\n",
      "Epoch 11/1000\n",
      "700/700 [==============================] - 0s 58us/step - loss: 2.0059 - accuracy: 0.2657 - val_loss: 2.0555 - val_accuracy: 0.2400\n",
      "Epoch 12/1000\n",
      "700/700 [==============================] - 0s 58us/step - loss: 1.9834 - accuracy: 0.2800 - val_loss: 2.0347 - val_accuracy: 0.2300\n",
      "Epoch 13/1000\n",
      "700/700 [==============================] - 0s 57us/step - loss: 1.9615 - accuracy: 0.2843 - val_loss: 2.0110 - val_accuracy: 0.2367\n",
      "Epoch 14/1000\n",
      "700/700 [==============================] - 0s 54us/step - loss: 1.9384 - accuracy: 0.2886 - val_loss: 1.9895 - val_accuracy: 0.2433\n",
      "Epoch 15/1000\n",
      "700/700 [==============================] - 0s 53us/step - loss: 1.9167 - accuracy: 0.2914 - val_loss: 1.9689 - val_accuracy: 0.2600\n",
      "Epoch 16/1000\n",
      "700/700 [==============================] - 0s 57us/step - loss: 1.8966 - accuracy: 0.2929 - val_loss: 1.9507 - val_accuracy: 0.2533\n",
      "Epoch 17/1000\n",
      "700/700 [==============================] - 0s 57us/step - loss: 1.8774 - accuracy: 0.2943 - val_loss: 1.9339 - val_accuracy: 0.2533\n",
      "Epoch 18/1000\n",
      "700/700 [==============================] - 0s 54us/step - loss: 1.8611 - accuracy: 0.3014 - val_loss: 1.9181 - val_accuracy: 0.2633\n",
      "Epoch 19/1000\n",
      "700/700 [==============================] - 0s 56us/step - loss: 1.8450 - accuracy: 0.3014 - val_loss: 1.9040 - val_accuracy: 0.2633\n",
      "Epoch 20/1000\n",
      "700/700 [==============================] - 0s 57us/step - loss: 1.8299 - accuracy: 0.3029 - val_loss: 1.8918 - val_accuracy: 0.2633\n",
      "Epoch 21/1000\n",
      "700/700 [==============================] - 0s 60us/step - loss: 1.8167 - accuracy: 0.3043 - val_loss: 1.8804 - val_accuracy: 0.2700\n",
      "Epoch 22/1000\n",
      "700/700 [==============================] - 0s 58us/step - loss: 1.8037 - accuracy: 0.3114 - val_loss: 1.8698 - val_accuracy: 0.2667\n",
      "Epoch 23/1000\n",
      "700/700 [==============================] - 0s 57us/step - loss: 1.7918 - accuracy: 0.3100 - val_loss: 1.8594 - val_accuracy: 0.2633\n",
      "Epoch 24/1000\n",
      "700/700 [==============================] - 0s 57us/step - loss: 1.7794 - accuracy: 0.3143 - val_loss: 1.8544 - val_accuracy: 0.2433\n",
      "Epoch 25/1000\n",
      "700/700 [==============================] - 0s 58us/step - loss: 1.7681 - accuracy: 0.3129 - val_loss: 1.8434 - val_accuracy: 0.2567\n",
      "Epoch 26/1000\n",
      "700/700 [==============================] - 0s 56us/step - loss: 1.7563 - accuracy: 0.3100 - val_loss: 1.8360 - val_accuracy: 0.2500\n",
      "Epoch 27/1000\n",
      "700/700 [==============================] - 0s 57us/step - loss: 1.7439 - accuracy: 0.3114 - val_loss: 1.8255 - val_accuracy: 0.2500\n",
      "Epoch 28/1000\n",
      "700/700 [==============================] - 0s 58us/step - loss: 1.7316 - accuracy: 0.3257 - val_loss: 1.8200 - val_accuracy: 0.2400\n",
      "Epoch 29/1000\n",
      "700/700 [==============================] - 0s 54us/step - loss: 1.7204 - accuracy: 0.3257 - val_loss: 1.8116 - val_accuracy: 0.2433\n",
      "Epoch 30/1000\n",
      "700/700 [==============================] - 0s 54us/step - loss: 1.7082 - accuracy: 0.3257 - val_loss: 1.8018 - val_accuracy: 0.2400\n",
      "Epoch 31/1000\n",
      "700/700 [==============================] - 0s 57us/step - loss: 1.6956 - accuracy: 0.3329 - val_loss: 1.7928 - val_accuracy: 0.2567\n",
      "Epoch 32/1000\n",
      "700/700 [==============================] - 0s 57us/step - loss: 1.6862 - accuracy: 0.3357 - val_loss: 1.7875 - val_accuracy: 0.2567\n",
      "Epoch 33/1000\n",
      "700/700 [==============================] - 0s 57us/step - loss: 1.6754 - accuracy: 0.3429 - val_loss: 1.7807 - val_accuracy: 0.2600\n",
      "Epoch 34/1000\n",
      "700/700 [==============================] - 0s 54us/step - loss: 1.6641 - accuracy: 0.3529 - val_loss: 1.7749 - val_accuracy: 0.2700\n",
      "Epoch 35/1000\n",
      "700/700 [==============================] - 0s 53us/step - loss: 1.6540 - accuracy: 0.3514 - val_loss: 1.7708 - val_accuracy: 0.2633\n",
      "Epoch 36/1000\n",
      "700/700 [==============================] - 0s 51us/step - loss: 1.6449 - accuracy: 0.3600 - val_loss: 1.7626 - val_accuracy: 0.2633\n",
      "Epoch 37/1000\n",
      "700/700 [==============================] - 0s 51us/step - loss: 1.6341 - accuracy: 0.3714 - val_loss: 1.7571 - val_accuracy: 0.2667\n",
      "Epoch 38/1000\n",
      "700/700 [==============================] - 0s 51us/step - loss: 1.6251 - accuracy: 0.3729 - val_loss: 1.7510 - val_accuracy: 0.2767\n",
      "Epoch 39/1000\n",
      "700/700 [==============================] - 0s 50us/step - loss: 1.6153 - accuracy: 0.3843 - val_loss: 1.7451 - val_accuracy: 0.2867\n",
      "Epoch 40/1000\n",
      "700/700 [==============================] - 0s 51us/step - loss: 1.6054 - accuracy: 0.3871 - val_loss: 1.7362 - val_accuracy: 0.2833\n",
      "Epoch 41/1000\n",
      "700/700 [==============================] - 0s 53us/step - loss: 1.5951 - accuracy: 0.3986 - val_loss: 1.7383 - val_accuracy: 0.2967\n",
      "Epoch 42/1000\n",
      "700/700 [==============================] - 0s 54us/step - loss: 1.5855 - accuracy: 0.4043 - val_loss: 1.7281 - val_accuracy: 0.3100\n",
      "Epoch 43/1000\n",
      "700/700 [==============================] - 0s 54us/step - loss: 1.5752 - accuracy: 0.4014 - val_loss: 1.7244 - val_accuracy: 0.3100\n",
      "Epoch 44/1000\n",
      "700/700 [==============================] - 0s 51us/step - loss: 1.5655 - accuracy: 0.4057 - val_loss: 1.7147 - val_accuracy: 0.3100\n",
      "Epoch 45/1000\n",
      "700/700 [==============================] - 0s 56us/step - loss: 1.5557 - accuracy: 0.4157 - val_loss: 1.7075 - val_accuracy: 0.3133\n",
      "Epoch 46/1000\n",
      "700/700 [==============================] - 0s 58us/step - loss: 1.5445 - accuracy: 0.4271 - val_loss: 1.7045 - val_accuracy: 0.3133\n",
      "Epoch 47/1000\n",
      "700/700 [==============================] - 0s 60us/step - loss: 1.5358 - accuracy: 0.4143 - val_loss: 1.6991 - val_accuracy: 0.3300\n",
      "Epoch 48/1000\n",
      "700/700 [==============================] - 0s 56us/step - loss: 1.5245 - accuracy: 0.4329 - val_loss: 1.6944 - val_accuracy: 0.3200\n",
      "Epoch 49/1000\n",
      "700/700 [==============================] - 0s 54us/step - loss: 1.5153 - accuracy: 0.4286 - val_loss: 1.6843 - val_accuracy: 0.3400\n",
      "Epoch 50/1000\n",
      "700/700 [==============================] - 0s 56us/step - loss: 1.5042 - accuracy: 0.4357 - val_loss: 1.6754 - val_accuracy: 0.3367\n",
      "Epoch 51/1000\n",
      "700/700 [==============================] - 0s 53us/step - loss: 1.4939 - accuracy: 0.4443 - val_loss: 1.6711 - val_accuracy: 0.3533\n",
      "Epoch 52/1000\n",
      "700/700 [==============================] - 0s 58us/step - loss: 1.4839 - accuracy: 0.4571 - val_loss: 1.6616 - val_accuracy: 0.3533\n",
      "Epoch 53/1000\n",
      "700/700 [==============================] - 0s 56us/step - loss: 1.4731 - accuracy: 0.4543 - val_loss: 1.6655 - val_accuracy: 0.3500\n",
      "Epoch 54/1000\n",
      "700/700 [==============================] - 0s 51us/step - loss: 1.4647 - accuracy: 0.4614 - val_loss: 1.6499 - val_accuracy: 0.3567\n",
      "Epoch 55/1000\n",
      "700/700 [==============================] - 0s 56us/step - loss: 1.4544 - accuracy: 0.4629 - val_loss: 1.6475 - val_accuracy: 0.3500\n",
      "Epoch 56/1000\n",
      "700/700 [==============================] - 0s 51us/step - loss: 1.4455 - accuracy: 0.4557 - val_loss: 1.6443 - val_accuracy: 0.3533\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 57/1000\n",
      "700/700 [==============================] - 0s 53us/step - loss: 1.4349 - accuracy: 0.4657 - val_loss: 1.6318 - val_accuracy: 0.3367\n",
      "Epoch 58/1000\n",
      "700/700 [==============================] - 0s 56us/step - loss: 1.4263 - accuracy: 0.4586 - val_loss: 1.6286 - val_accuracy: 0.3600\n",
      "Epoch 59/1000\n",
      "700/700 [==============================] - 0s 57us/step - loss: 1.4170 - accuracy: 0.4657 - val_loss: 1.6238 - val_accuracy: 0.3633\n",
      "Epoch 60/1000\n",
      "700/700 [==============================] - 0s 53us/step - loss: 1.4078 - accuracy: 0.4714 - val_loss: 1.6204 - val_accuracy: 0.3600\n",
      "Epoch 61/1000\n",
      "700/700 [==============================] - 0s 56us/step - loss: 1.3995 - accuracy: 0.4771 - val_loss: 1.6140 - val_accuracy: 0.3633\n",
      "Epoch 62/1000\n",
      "700/700 [==============================] - 0s 53us/step - loss: 1.3911 - accuracy: 0.4714 - val_loss: 1.6069 - val_accuracy: 0.3567\n",
      "Epoch 63/1000\n",
      "700/700 [==============================] - 0s 51us/step - loss: 1.3832 - accuracy: 0.4743 - val_loss: 1.5999 - val_accuracy: 0.3533\n",
      "Epoch 64/1000\n",
      "700/700 [==============================] - 0s 56us/step - loss: 1.3750 - accuracy: 0.4900 - val_loss: 1.5952 - val_accuracy: 0.3667\n",
      "Epoch 65/1000\n",
      "700/700 [==============================] - 0s 57us/step - loss: 1.3680 - accuracy: 0.4900 - val_loss: 1.5983 - val_accuracy: 0.3633\n",
      "Epoch 66/1000\n",
      "700/700 [==============================] - 0s 57us/step - loss: 1.3603 - accuracy: 0.4814 - val_loss: 1.5915 - val_accuracy: 0.3533\n",
      "Epoch 67/1000\n",
      "700/700 [==============================] - 0s 56us/step - loss: 1.3528 - accuracy: 0.4829 - val_loss: 1.5781 - val_accuracy: 0.3633\n",
      "Epoch 68/1000\n",
      "700/700 [==============================] - 0s 51us/step - loss: 1.3466 - accuracy: 0.4900 - val_loss: 1.5759 - val_accuracy: 0.3633\n",
      "Epoch 69/1000\n",
      "700/700 [==============================] - 0s 53us/step - loss: 1.3397 - accuracy: 0.4857 - val_loss: 1.5856 - val_accuracy: 0.3567\n",
      "Epoch 70/1000\n",
      "700/700 [==============================] - 0s 56us/step - loss: 1.3336 - accuracy: 0.4943 - val_loss: 1.5749 - val_accuracy: 0.3533\n",
      "Epoch 71/1000\n",
      "700/700 [==============================] - 0s 54us/step - loss: 1.3269 - accuracy: 0.5014 - val_loss: 1.5687 - val_accuracy: 0.3700\n",
      "Epoch 72/1000\n",
      "700/700 [==============================] - 0s 53us/step - loss: 1.3208 - accuracy: 0.5014 - val_loss: 1.5691 - val_accuracy: 0.3700\n",
      "Epoch 73/1000\n",
      "700/700 [==============================] - 0s 54us/step - loss: 1.3143 - accuracy: 0.4957 - val_loss: 1.5634 - val_accuracy: 0.3600\n",
      "Epoch 74/1000\n",
      "700/700 [==============================] - 0s 56us/step - loss: 1.3091 - accuracy: 0.5000 - val_loss: 1.5629 - val_accuracy: 0.3567\n",
      "Epoch 75/1000\n",
      "700/700 [==============================] - 0s 60us/step - loss: 1.3031 - accuracy: 0.4986 - val_loss: 1.5611 - val_accuracy: 0.3600\n",
      "Epoch 76/1000\n",
      "700/700 [==============================] - 0s 57us/step - loss: 1.2954 - accuracy: 0.5014 - val_loss: 1.5540 - val_accuracy: 0.3600\n",
      "Epoch 77/1000\n",
      "700/700 [==============================] - 0s 57us/step - loss: 1.2914 - accuracy: 0.4986 - val_loss: 1.5527 - val_accuracy: 0.3767\n",
      "Epoch 78/1000\n",
      "700/700 [==============================] - 0s 57us/step - loss: 1.2860 - accuracy: 0.4986 - val_loss: 1.5539 - val_accuracy: 0.3633\n",
      "Epoch 79/1000\n",
      "700/700 [==============================] - 0s 53us/step - loss: 1.2806 - accuracy: 0.5086 - val_loss: 1.5534 - val_accuracy: 0.3667\n",
      "Epoch 80/1000\n",
      "700/700 [==============================] - 0s 54us/step - loss: 1.2752 - accuracy: 0.5100 - val_loss: 1.5484 - val_accuracy: 0.3733\n",
      "Epoch 81/1000\n",
      "700/700 [==============================] - 0s 54us/step - loss: 1.2705 - accuracy: 0.5143 - val_loss: 1.5457 - val_accuracy: 0.3567\n",
      "Epoch 82/1000\n",
      "700/700 [==============================] - 0s 57us/step - loss: 1.2652 - accuracy: 0.5129 - val_loss: 1.5503 - val_accuracy: 0.3633\n",
      "Epoch 83/1000\n",
      "700/700 [==============================] - 0s 60us/step - loss: 1.2608 - accuracy: 0.5114 - val_loss: 1.5464 - val_accuracy: 0.3667\n",
      "Epoch 84/1000\n",
      "700/700 [==============================] - 0s 58us/step - loss: 1.2551 - accuracy: 0.5129 - val_loss: 1.5539 - val_accuracy: 0.3733\n",
      "Epoch 85/1000\n",
      "700/700 [==============================] - 0s 59us/step - loss: 1.2515 - accuracy: 0.5100 - val_loss: 1.5352 - val_accuracy: 0.3533\n",
      "Epoch 86/1000\n",
      "700/700 [==============================] - 0s 57us/step - loss: 1.2470 - accuracy: 0.5186 - val_loss: 1.5432 - val_accuracy: 0.3767\n",
      "Epoch 87/1000\n",
      "700/700 [==============================] - 0s 56us/step - loss: 1.2427 - accuracy: 0.5157 - val_loss: 1.5365 - val_accuracy: 0.3667\n",
      "Epoch 88/1000\n",
      "700/700 [==============================] - 0s 56us/step - loss: 1.2377 - accuracy: 0.5171 - val_loss: 1.5440 - val_accuracy: 0.3733\n",
      "Epoch 89/1000\n",
      "700/700 [==============================] - 0s 58us/step - loss: 1.2333 - accuracy: 0.5243 - val_loss: 1.5401 - val_accuracy: 0.3700\n",
      "Epoch 90/1000\n",
      "700/700 [==============================] - 0s 58us/step - loss: 1.2288 - accuracy: 0.5071 - val_loss: 1.5376 - val_accuracy: 0.3700\n",
      "Epoch 91/1000\n",
      "700/700 [==============================] - 0s 58us/step - loss: 1.2249 - accuracy: 0.5114 - val_loss: 1.5304 - val_accuracy: 0.3600\n",
      "Epoch 92/1000\n",
      "700/700 [==============================] - 0s 57us/step - loss: 1.2210 - accuracy: 0.5171 - val_loss: 1.5278 - val_accuracy: 0.3667\n",
      "Epoch 93/1000\n",
      "700/700 [==============================] - 0s 57us/step - loss: 1.2168 - accuracy: 0.5314 - val_loss: 1.5358 - val_accuracy: 0.3667\n",
      "Epoch 94/1000\n",
      "700/700 [==============================] - 0s 57us/step - loss: 1.2136 - accuracy: 0.5229 - val_loss: 1.5240 - val_accuracy: 0.3700\n",
      "Epoch 95/1000\n",
      "700/700 [==============================] - 0s 57us/step - loss: 1.2086 - accuracy: 0.5314 - val_loss: 1.5224 - val_accuracy: 0.3667\n",
      "Epoch 96/1000\n",
      "700/700 [==============================] - 0s 59us/step - loss: 1.2045 - accuracy: 0.5271 - val_loss: 1.5206 - val_accuracy: 0.3767\n",
      "Epoch 97/1000\n",
      "700/700 [==============================] - 0s 60us/step - loss: 1.2021 - accuracy: 0.5229 - val_loss: 1.5287 - val_accuracy: 0.3600\n",
      "Epoch 98/1000\n",
      "700/700 [==============================] - 0s 58us/step - loss: 1.1977 - accuracy: 0.5371 - val_loss: 1.5303 - val_accuracy: 0.3500\n",
      "Epoch 99/1000\n",
      "700/700 [==============================] - 0s 56us/step - loss: 1.1941 - accuracy: 0.5329 - val_loss: 1.5339 - val_accuracy: 0.3700\n",
      "Epoch 100/1000\n",
      "700/700 [==============================] - 0s 57us/step - loss: 1.1895 - accuracy: 0.5429 - val_loss: 1.5262 - val_accuracy: 0.3700\n",
      "Epoch 101/1000\n",
      "700/700 [==============================] - 0s 59us/step - loss: 1.1868 - accuracy: 0.5271 - val_loss: 1.5274 - val_accuracy: 0.3767\n",
      "Epoch 102/1000\n",
      "700/700 [==============================] - 0s 57us/step - loss: 1.1840 - accuracy: 0.5414 - val_loss: 1.5224 - val_accuracy: 0.3600\n",
      "Epoch 103/1000\n",
      "700/700 [==============================] - 0s 60us/step - loss: 1.1794 - accuracy: 0.5543 - val_loss: 1.5274 - val_accuracy: 0.3700\n",
      "Epoch 104/1000\n",
      "700/700 [==============================] - 0s 58us/step - loss: 1.1772 - accuracy: 0.5371 - val_loss: 1.5285 - val_accuracy: 0.3667\n",
      "Epoch 105/1000\n",
      "700/700 [==============================] - 0s 58us/step - loss: 1.1742 - accuracy: 0.5443 - val_loss: 1.5231 - val_accuracy: 0.3700\n",
      "Epoch 106/1000\n",
      "700/700 [==============================] - 0s 57us/step - loss: 1.1709 - accuracy: 0.5514 - val_loss: 1.5241 - val_accuracy: 0.3700\n",
      "Epoch 107/1000\n",
      "700/700 [==============================] - 0s 54us/step - loss: 1.1682 - accuracy: 0.5457 - val_loss: 1.5189 - val_accuracy: 0.3867\n",
      "Epoch 108/1000\n",
      "700/700 [==============================] - 0s 57us/step - loss: 1.1642 - accuracy: 0.5414 - val_loss: 1.5196 - val_accuracy: 0.3767\n",
      "Epoch 109/1000\n",
      "700/700 [==============================] - 0s 60us/step - loss: 1.1613 - accuracy: 0.5557 - val_loss: 1.5309 - val_accuracy: 0.3633\n",
      "Epoch 110/1000\n",
      "700/700 [==============================] - ETA: 0s - loss: 0.9558 - accuracy: 0.60 - 0s 56us/step - loss: 1.1587 - accuracy: 0.5486 - val_loss: 1.5198 - val_accuracy: 0.3733\n",
      "Epoch 111/1000\n",
      "700/700 [==============================] - 0s 56us/step - loss: 1.1557 - accuracy: 0.5543 - val_loss: 1.5194 - val_accuracy: 0.3833\n",
      "Epoch 112/1000\n",
      "700/700 [==============================] - 0s 56us/step - loss: 1.1527 - accuracy: 0.5457 - val_loss: 1.5125 - val_accuracy: 0.3967\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 113/1000\n",
      "700/700 [==============================] - 0s 53us/step - loss: 1.1499 - accuracy: 0.5500 - val_loss: 1.5214 - val_accuracy: 0.3833\n",
      "Epoch 114/1000\n",
      "700/700 [==============================] - 0s 53us/step - loss: 1.1465 - accuracy: 0.5529 - val_loss: 1.5254 - val_accuracy: 0.3733\n",
      "Epoch 115/1000\n",
      "700/700 [==============================] - 0s 57us/step - loss: 1.1404 - accuracy: 0.5557 - val_loss: 1.5589 - val_accuracy: 0.3833\n",
      "Epoch 116/1000\n",
      "700/700 [==============================] - 0s 54us/step - loss: 1.1446 - accuracy: 0.5429 - val_loss: 1.5184 - val_accuracy: 0.3900\n",
      "Epoch 117/1000\n",
      "700/700 [==============================] - 0s 54us/step - loss: 1.1375 - accuracy: 0.5614 - val_loss: 1.5388 - val_accuracy: 0.3800\n",
      "Epoch 118/1000\n",
      "700/700 [==============================] - 0s 54us/step - loss: 1.1367 - accuracy: 0.5543 - val_loss: 1.5245 - val_accuracy: 0.3833\n",
      "Epoch 119/1000\n",
      "700/700 [==============================] - 0s 54us/step - loss: 1.1334 - accuracy: 0.5529 - val_loss: 1.5236 - val_accuracy: 0.3867\n",
      "Epoch 120/1000\n",
      "700/700 [==============================] - 0s 53us/step - loss: 1.1316 - accuracy: 0.5529 - val_loss: 1.5222 - val_accuracy: 0.3900\n",
      "Epoch 121/1000\n",
      "700/700 [==============================] - 0s 51us/step - loss: 1.1290 - accuracy: 0.5529 - val_loss: 1.5269 - val_accuracy: 0.3867\n",
      "Epoch 122/1000\n",
      "700/700 [==============================] - 0s 53us/step - loss: 1.1271 - accuracy: 0.5614 - val_loss: 1.5188 - val_accuracy: 0.3967\n",
      "Epoch 123/1000\n",
      "700/700 [==============================] - 0s 54us/step - loss: 1.1217 - accuracy: 0.5600 - val_loss: 1.5329 - val_accuracy: 0.3700\n",
      "Epoch 124/1000\n",
      "700/700 [==============================] - 0s 56us/step - loss: 1.1201 - accuracy: 0.5600 - val_loss: 1.5271 - val_accuracy: 0.3867\n",
      "Epoch 125/1000\n",
      "700/700 [==============================] - 0s 54us/step - loss: 1.1184 - accuracy: 0.5700 - val_loss: 1.5194 - val_accuracy: 0.3967\n",
      "Epoch 126/1000\n",
      "700/700 [==============================] - 0s 53us/step - loss: 1.1161 - accuracy: 0.5600 - val_loss: 1.5263 - val_accuracy: 0.3833\n",
      "Epoch 127/1000\n",
      "700/700 [==============================] - 0s 56us/step - loss: 1.1128 - accuracy: 0.5671 - val_loss: 1.5235 - val_accuracy: 0.3967\n",
      "Epoch 128/1000\n",
      "700/700 [==============================] - 0s 56us/step - loss: 1.1113 - accuracy: 0.5671 - val_loss: 1.5276 - val_accuracy: 0.3900\n",
      "Epoch 129/1000\n",
      "700/700 [==============================] - 0s 56us/step - loss: 1.1085 - accuracy: 0.5671 - val_loss: 1.5244 - val_accuracy: 0.3833\n",
      "Epoch 130/1000\n",
      "700/700 [==============================] - 0s 56us/step - loss: 1.1050 - accuracy: 0.5671 - val_loss: 1.5248 - val_accuracy: 0.3933\n",
      "Epoch 131/1000\n",
      "700/700 [==============================] - 0s 57us/step - loss: 1.1042 - accuracy: 0.5714 - val_loss: 1.5269 - val_accuracy: 0.3967\n",
      "Epoch 132/1000\n",
      "700/700 [==============================] - 0s 57us/step - loss: 1.1012 - accuracy: 0.5700 - val_loss: 1.5208 - val_accuracy: 0.4000\n",
      "Epoch 133/1000\n",
      "700/700 [==============================] - 0s 56us/step - loss: 1.0983 - accuracy: 0.5814 - val_loss: 1.5203 - val_accuracy: 0.4000\n",
      "Epoch 134/1000\n",
      "700/700 [==============================] - 0s 51us/step - loss: 1.0959 - accuracy: 0.5643 - val_loss: 1.5283 - val_accuracy: 0.4033\n",
      "Epoch 135/1000\n",
      "700/700 [==============================] - 0s 57us/step - loss: 1.0931 - accuracy: 0.5657 - val_loss: 1.5264 - val_accuracy: 0.4000\n",
      "Epoch 136/1000\n",
      "700/700 [==============================] - 0s 60us/step - loss: 1.0928 - accuracy: 0.5757 - val_loss: 1.5295 - val_accuracy: 0.3867\n",
      "Epoch 137/1000\n",
      "700/700 [==============================] - 0s 58us/step - loss: 1.0897 - accuracy: 0.5686 - val_loss: 1.5248 - val_accuracy: 0.4033\n",
      "Epoch 138/1000\n",
      "700/700 [==============================] - 0s 56us/step - loss: 1.0871 - accuracy: 0.5743 - val_loss: 1.5279 - val_accuracy: 0.3933\n",
      "Epoch 139/1000\n",
      "700/700 [==============================] - 0s 54us/step - loss: 1.0851 - accuracy: 0.5743 - val_loss: 1.5276 - val_accuracy: 0.4067\n",
      "Epoch 140/1000\n",
      "700/700 [==============================] - 0s 56us/step - loss: 1.0830 - accuracy: 0.5800 - val_loss: 1.5367 - val_accuracy: 0.4067\n",
      "Epoch 141/1000\n",
      "700/700 [==============================] - 0s 53us/step - loss: 1.0819 - accuracy: 0.5757 - val_loss: 1.5324 - val_accuracy: 0.4000\n",
      "Epoch 142/1000\n",
      "700/700 [==============================] - 0s 57us/step - loss: 1.0791 - accuracy: 0.5729 - val_loss: 1.5326 - val_accuracy: 0.3933\n",
      "Epoch 143/1000\n",
      "700/700 [==============================] - 0s 58us/step - loss: 1.0759 - accuracy: 0.5829 - val_loss: 1.5318 - val_accuracy: 0.4033\n",
      "Epoch 144/1000\n",
      "700/700 [==============================] - 0s 57us/step - loss: 1.0761 - accuracy: 0.5786 - val_loss: 1.5245 - val_accuracy: 0.4100\n",
      "Epoch 145/1000\n",
      "700/700 [==============================] - 0s 57us/step - loss: 1.0735 - accuracy: 0.5757 - val_loss: 1.5260 - val_accuracy: 0.3900\n",
      "Epoch 146/1000\n",
      "700/700 [==============================] - 0s 58us/step - loss: 1.0708 - accuracy: 0.5886 - val_loss: 1.5257 - val_accuracy: 0.4100\n",
      "Epoch 147/1000\n",
      "700/700 [==============================] - 0s 56us/step - loss: 1.0702 - accuracy: 0.5886 - val_loss: 1.5264 - val_accuracy: 0.3967\n",
      "Epoch 148/1000\n",
      "700/700 [==============================] - 0s 56us/step - loss: 1.0671 - accuracy: 0.5843 - val_loss: 1.5230 - val_accuracy: 0.4100\n",
      "Epoch 149/1000\n",
      "700/700 [==============================] - 0s 56us/step - loss: 1.0655 - accuracy: 0.5729 - val_loss: 1.5315 - val_accuracy: 0.4067\n",
      "Epoch 150/1000\n",
      "700/700 [==============================] - 0s 57us/step - loss: 1.0652 - accuracy: 0.5786 - val_loss: 1.5281 - val_accuracy: 0.4133\n",
      "Epoch 151/1000\n",
      "700/700 [==============================] - 0s 56us/step - loss: 1.0606 - accuracy: 0.5757 - val_loss: 1.5262 - val_accuracy: 0.4167\n",
      "Epoch 152/1000\n",
      "700/700 [==============================] - 0s 57us/step - loss: 1.0594 - accuracy: 0.5786 - val_loss: 1.5558 - val_accuracy: 0.4067\n",
      "Epoch 153/1000\n",
      "700/700 [==============================] - 0s 58us/step - loss: 1.0581 - accuracy: 0.5800 - val_loss: 1.5306 - val_accuracy: 0.4133\n",
      "Epoch 154/1000\n",
      "700/700 [==============================] - 0s 56us/step - loss: 1.0560 - accuracy: 0.5871 - val_loss: 1.5357 - val_accuracy: 0.4000\n",
      "Epoch 155/1000\n",
      "700/700 [==============================] - 0s 60us/step - loss: 1.0537 - accuracy: 0.5814 - val_loss: 1.5360 - val_accuracy: 0.4067\n",
      "Epoch 156/1000\n",
      "700/700 [==============================] - 0s 57us/step - loss: 1.0520 - accuracy: 0.5771 - val_loss: 1.5288 - val_accuracy: 0.4133\n",
      "Epoch 157/1000\n",
      "700/700 [==============================] - 0s 57us/step - loss: 1.0503 - accuracy: 0.5886 - val_loss: 1.5355 - val_accuracy: 0.4100\n",
      "Epoch 158/1000\n",
      "700/700 [==============================] - 0s 56us/step - loss: 1.0483 - accuracy: 0.5757 - val_loss: 1.5408 - val_accuracy: 0.4167\n",
      "Epoch 159/1000\n",
      "700/700 [==============================] - 0s 57us/step - loss: 1.0480 - accuracy: 0.5886 - val_loss: 1.5315 - val_accuracy: 0.4100\n",
      "Epoch 160/1000\n",
      "700/700 [==============================] - 0s 56us/step - loss: 1.0454 - accuracy: 0.5929 - val_loss: 1.5355 - val_accuracy: 0.4033\n",
      "Epoch 161/1000\n",
      "700/700 [==============================] - 0s 58us/step - loss: 1.0449 - accuracy: 0.5857 - val_loss: 1.5369 - val_accuracy: 0.4067\n",
      "Epoch 162/1000\n",
      "700/700 [==============================] - 0s 58us/step - loss: 1.0409 - accuracy: 0.5900 - val_loss: 1.5291 - val_accuracy: 0.4167\n",
      "Epoch 163/1000\n",
      "700/700 [==============================] - 0s 58us/step - loss: 1.0397 - accuracy: 0.5914 - val_loss: 1.5448 - val_accuracy: 0.4133\n",
      "Epoch 164/1000\n",
      "700/700 [==============================] - 0s 57us/step - loss: 1.0379 - accuracy: 0.5914 - val_loss: 1.5370 - val_accuracy: 0.4133\n",
      "Epoch 165/1000\n",
      "700/700 [==============================] - 0s 54us/step - loss: 1.0366 - accuracy: 0.5943 - val_loss: 1.5392 - val_accuracy: 0.4200\n",
      "Epoch 166/1000\n",
      "700/700 [==============================] - 0s 54us/step - loss: 1.0343 - accuracy: 0.5914 - val_loss: 1.5388 - val_accuracy: 0.4100\n",
      "Epoch 167/1000\n",
      "700/700 [==============================] - 0s 54us/step - loss: 1.0325 - accuracy: 0.5943 - val_loss: 1.5451 - val_accuracy: 0.4167\n",
      "Epoch 168/1000\n",
      "700/700 [==============================] - 0s 53us/step - loss: 1.0331 - accuracy: 0.5971 - val_loss: 1.5375 - val_accuracy: 0.4100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 169/1000\n",
      "700/700 [==============================] - 0s 54us/step - loss: 1.0302 - accuracy: 0.5886 - val_loss: 1.5393 - val_accuracy: 0.4167\n",
      "Epoch 170/1000\n",
      "700/700 [==============================] - 0s 53us/step - loss: 1.0275 - accuracy: 0.5957 - val_loss: 1.5356 - val_accuracy: 0.4167\n",
      "Epoch 171/1000\n",
      "700/700 [==============================] - 0s 53us/step - loss: 1.0269 - accuracy: 0.5957 - val_loss: 1.5401 - val_accuracy: 0.4000\n",
      "Epoch 172/1000\n",
      "700/700 [==============================] - 0s 53us/step - loss: 1.0240 - accuracy: 0.5929 - val_loss: 1.5445 - val_accuracy: 0.4200\n",
      "Epoch 173/1000\n",
      "700/700 [==============================] - 0s 54us/step - loss: 1.0226 - accuracy: 0.6000 - val_loss: 1.5402 - val_accuracy: 0.4133\n",
      "Epoch 174/1000\n",
      "700/700 [==============================] - 0s 53us/step - loss: 1.0211 - accuracy: 0.5986 - val_loss: 1.5387 - val_accuracy: 0.4133\n",
      "Epoch 175/1000\n",
      "700/700 [==============================] - 0s 56us/step - loss: 1.0182 - accuracy: 0.5986 - val_loss: 1.5485 - val_accuracy: 0.4100\n",
      "Epoch 176/1000\n",
      "700/700 [==============================] - 0s 53us/step - loss: 1.0180 - accuracy: 0.5929 - val_loss: 1.5347 - val_accuracy: 0.4200\n",
      "Epoch 177/1000\n",
      "700/700 [==============================] - 0s 53us/step - loss: 1.0177 - accuracy: 0.6043 - val_loss: 1.5446 - val_accuracy: 0.4133\n",
      "Epoch 178/1000\n",
      "700/700 [==============================] - 0s 53us/step - loss: 1.0150 - accuracy: 0.5957 - val_loss: 1.5381 - val_accuracy: 0.4200\n",
      "Epoch 179/1000\n",
      "700/700 [==============================] - 0s 54us/step - loss: 1.0132 - accuracy: 0.6014 - val_loss: 1.5396 - val_accuracy: 0.4133\n",
      "Epoch 180/1000\n",
      "700/700 [==============================] - 0s 56us/step - loss: 1.0113 - accuracy: 0.6071 - val_loss: 1.5373 - val_accuracy: 0.4200\n",
      "Epoch 181/1000\n",
      "700/700 [==============================] - 0s 54us/step - loss: 1.0104 - accuracy: 0.6157 - val_loss: 1.5519 - val_accuracy: 0.4100\n",
      "Epoch 182/1000\n",
      "700/700 [==============================] - 0s 53us/step - loss: 1.0080 - accuracy: 0.6057 - val_loss: 1.5429 - val_accuracy: 0.4133\n",
      "Epoch 183/1000\n",
      "700/700 [==============================] - 0s 58us/step - loss: 1.0077 - accuracy: 0.6086 - val_loss: 1.5414 - val_accuracy: 0.4167\n",
      "Epoch 184/1000\n",
      "700/700 [==============================] - 0s 60us/step - loss: 1.0050 - accuracy: 0.6114 - val_loss: 1.5407 - val_accuracy: 0.4167\n",
      "Epoch 185/1000\n",
      "700/700 [==============================] - 0s 57us/step - loss: 1.0044 - accuracy: 0.6114 - val_loss: 1.5461 - val_accuracy: 0.4200\n",
      "Epoch 186/1000\n",
      "700/700 [==============================] - 0s 58us/step - loss: 1.0025 - accuracy: 0.6071 - val_loss: 1.5453 - val_accuracy: 0.4200\n",
      "Epoch 187/1000\n",
      "700/700 [==============================] - 0s 54us/step - loss: 1.0013 - accuracy: 0.6157 - val_loss: 1.5485 - val_accuracy: 0.4167\n",
      "Epoch 188/1000\n",
      "700/700 [==============================] - 0s 54us/step - loss: 0.9996 - accuracy: 0.6129 - val_loss: 1.5500 - val_accuracy: 0.4200\n",
      "Epoch 189/1000\n",
      "700/700 [==============================] - 0s 54us/step - loss: 0.9982 - accuracy: 0.6086 - val_loss: 1.5445 - val_accuracy: 0.4267\n",
      "Epoch 190/1000\n",
      "700/700 [==============================] - 0s 57us/step - loss: 0.9982 - accuracy: 0.6086 - val_loss: 1.5494 - val_accuracy: 0.4233\n",
      "Epoch 191/1000\n",
      "700/700 [==============================] - 0s 58us/step - loss: 0.9939 - accuracy: 0.6143 - val_loss: 1.5494 - val_accuracy: 0.4233\n",
      "Epoch 192/1000\n",
      "700/700 [==============================] - 0s 53us/step - loss: 0.9936 - accuracy: 0.6071 - val_loss: 1.5587 - val_accuracy: 0.4100\n",
      "Epoch 193/1000\n",
      "700/700 [==============================] - 0s 53us/step - loss: 0.9926 - accuracy: 0.6157 - val_loss: 1.5483 - val_accuracy: 0.4200\n",
      "Epoch 194/1000\n",
      "700/700 [==============================] - 0s 58us/step - loss: 0.9906 - accuracy: 0.6143 - val_loss: 1.5634 - val_accuracy: 0.4167\n",
      "Epoch 195/1000\n",
      "700/700 [==============================] - 0s 60us/step - loss: 0.9899 - accuracy: 0.6214 - val_loss: 1.5601 - val_accuracy: 0.4133\n",
      "Epoch 196/1000\n",
      "700/700 [==============================] - 0s 57us/step - loss: 0.9868 - accuracy: 0.6171 - val_loss: 1.5664 - val_accuracy: 0.4100\n",
      "Epoch 197/1000\n",
      "700/700 [==============================] - 0s 58us/step - loss: 0.9860 - accuracy: 0.6214 - val_loss: 1.5569 - val_accuracy: 0.4233\n",
      "Epoch 198/1000\n",
      "700/700 [==============================] - 0s 57us/step - loss: 0.9860 - accuracy: 0.6157 - val_loss: 1.5652 - val_accuracy: 0.4133\n",
      "Epoch 199/1000\n",
      "700/700 [==============================] - 0s 56us/step - loss: 0.9830 - accuracy: 0.6114 - val_loss: 1.5538 - val_accuracy: 0.4267\n",
      "Epoch 200/1000\n",
      "700/700 [==============================] - 0s 56us/step - loss: 0.9815 - accuracy: 0.6214 - val_loss: 1.5642 - val_accuracy: 0.4200\n",
      "Epoch 201/1000\n",
      "700/700 [==============================] - 0s 56us/step - loss: 0.9803 - accuracy: 0.6271 - val_loss: 1.5605 - val_accuracy: 0.4300\n",
      "Epoch 202/1000\n",
      "700/700 [==============================] - 0s 60us/step - loss: 0.9809 - accuracy: 0.6186 - val_loss: 1.5575 - val_accuracy: 0.4200\n",
      "Epoch 203/1000\n",
      "700/700 [==============================] - 0s 56us/step - loss: 0.9758 - accuracy: 0.6214 - val_loss: 1.5559 - val_accuracy: 0.4300\n",
      "Epoch 204/1000\n",
      "700/700 [==============================] - 0s 54us/step - loss: 0.9763 - accuracy: 0.6271 - val_loss: 1.5643 - val_accuracy: 0.4233\n",
      "Epoch 205/1000\n",
      "700/700 [==============================] - 0s 51us/step - loss: 0.9754 - accuracy: 0.6329 - val_loss: 1.5729 - val_accuracy: 0.4133\n",
      "Epoch 206/1000\n",
      "700/700 [==============================] - 0s 51us/step - loss: 0.9765 - accuracy: 0.6186 - val_loss: 1.5648 - val_accuracy: 0.4167\n",
      "Epoch 207/1000\n",
      "700/700 [==============================] - 0s 56us/step - loss: 0.9736 - accuracy: 0.6229 - val_loss: 1.5601 - val_accuracy: 0.4267\n",
      "Epoch 208/1000\n",
      "700/700 [==============================] - 0s 51us/step - loss: 0.9696 - accuracy: 0.6200 - val_loss: 1.5542 - val_accuracy: 0.4400\n",
      "Epoch 209/1000\n",
      "700/700 [==============================] - 0s 58us/step - loss: 0.9701 - accuracy: 0.6271 - val_loss: 1.5632 - val_accuracy: 0.4333\n",
      "Epoch 210/1000\n",
      "700/700 [==============================] - 0s 58us/step - loss: 0.9689 - accuracy: 0.6243 - val_loss: 1.5813 - val_accuracy: 0.4233\n",
      "Epoch 211/1000\n",
      "700/700 [==============================] - 0s 57us/step - loss: 0.9689 - accuracy: 0.6329 - val_loss: 1.5664 - val_accuracy: 0.4233\n",
      "Epoch 212/1000\n",
      "700/700 [==============================] - 0s 58us/step - loss: 0.9676 - accuracy: 0.6243 - val_loss: 1.5711 - val_accuracy: 0.4367\n",
      "Epoch 213/1000\n",
      "700/700 [==============================] - 0s 53us/step - loss: 0.9663 - accuracy: 0.6371 - val_loss: 1.5762 - val_accuracy: 0.4267\n",
      "Epoch 214/1000\n",
      "700/700 [==============================] - 0s 58us/step - loss: 0.9614 - accuracy: 0.6314 - val_loss: 1.5708 - val_accuracy: 0.4300\n",
      "Epoch 215/1000\n",
      "700/700 [==============================] - 0s 60us/step - loss: 0.9630 - accuracy: 0.6357 - val_loss: 1.5672 - val_accuracy: 0.4367\n",
      "Epoch 216/1000\n",
      "700/700 [==============================] - 0s 56us/step - loss: 0.9606 - accuracy: 0.6257 - val_loss: 1.5922 - val_accuracy: 0.4300\n",
      "Epoch 217/1000\n",
      "700/700 [==============================] - 0s 54us/step - loss: 0.9599 - accuracy: 0.6386 - val_loss: 1.5945 - val_accuracy: 0.4333\n",
      "Epoch 218/1000\n",
      "700/700 [==============================] - 0s 54us/step - loss: 0.9590 - accuracy: 0.6343 - val_loss: 1.5853 - val_accuracy: 0.4367\n",
      "Epoch 219/1000\n",
      "700/700 [==============================] - 0s 57us/step - loss: 0.9587 - accuracy: 0.6314 - val_loss: 1.5723 - val_accuracy: 0.4333\n",
      "Epoch 220/1000\n",
      "700/700 [==============================] - 0s 60us/step - loss: 0.9540 - accuracy: 0.6357 - val_loss: 1.5843 - val_accuracy: 0.4333\n",
      "Epoch 221/1000\n",
      "700/700 [==============================] - 0s 56us/step - loss: 0.9546 - accuracy: 0.6357 - val_loss: 1.5979 - val_accuracy: 0.4233\n",
      "Epoch 222/1000\n",
      "700/700 [==============================] - 0s 53us/step - loss: 0.9532 - accuracy: 0.6329 - val_loss: 1.5761 - val_accuracy: 0.4333\n",
      "Epoch 223/1000\n",
      "700/700 [==============================] - 0s 53us/step - loss: 0.9547 - accuracy: 0.6357 - val_loss: 1.5709 - val_accuracy: 0.4367\n",
      "Epoch 224/1000\n",
      "700/700 [==============================] - 0s 53us/step - loss: 0.9518 - accuracy: 0.6257 - val_loss: 1.5786 - val_accuracy: 0.4267\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 225/1000\n",
      "700/700 [==============================] - 0s 54us/step - loss: 0.9494 - accuracy: 0.6386 - val_loss: 1.5829 - val_accuracy: 0.4233\n",
      "Epoch 226/1000\n",
      "700/700 [==============================] - 0s 56us/step - loss: 0.9490 - accuracy: 0.6371 - val_loss: 1.5767 - val_accuracy: 0.4367\n",
      "Epoch 227/1000\n",
      "700/700 [==============================] - 0s 51us/step - loss: 0.9498 - accuracy: 0.6400 - val_loss: 1.5873 - val_accuracy: 0.4200\n",
      "Epoch 228/1000\n",
      "700/700 [==============================] - 0s 54us/step - loss: 0.9474 - accuracy: 0.6429 - val_loss: 1.5887 - val_accuracy: 0.4233\n",
      "Epoch 229/1000\n",
      "700/700 [==============================] - 0s 54us/step - loss: 0.9457 - accuracy: 0.6357 - val_loss: 1.5774 - val_accuracy: 0.4333\n",
      "Epoch 230/1000\n",
      "700/700 [==============================] - 0s 57us/step - loss: 0.9463 - accuracy: 0.6400 - val_loss: 1.5918 - val_accuracy: 0.4300\n",
      "Epoch 231/1000\n",
      "700/700 [==============================] - 0s 56us/step - loss: 0.9450 - accuracy: 0.6329 - val_loss: 1.5945 - val_accuracy: 0.4267\n",
      "Epoch 232/1000\n",
      "700/700 [==============================] - 0s 58us/step - loss: 0.9436 - accuracy: 0.6400 - val_loss: 1.5844 - val_accuracy: 0.4433\n",
      "Epoch 233/1000\n",
      "700/700 [==============================] - 0s 60us/step - loss: 0.9439 - accuracy: 0.6357 - val_loss: 1.5929 - val_accuracy: 0.4233\n",
      "Epoch 234/1000\n",
      "700/700 [==============================] - 0s 57us/step - loss: 0.9408 - accuracy: 0.6400 - val_loss: 1.5876 - val_accuracy: 0.4367\n",
      "Epoch 235/1000\n",
      "700/700 [==============================] - 0s 58us/step - loss: 0.9405 - accuracy: 0.6371 - val_loss: 1.5893 - val_accuracy: 0.4200\n",
      "Epoch 236/1000\n",
      "700/700 [==============================] - 0s 58us/step - loss: 0.9388 - accuracy: 0.6429 - val_loss: 1.5817 - val_accuracy: 0.4400\n",
      "Epoch 237/1000\n",
      "700/700 [==============================] - 0s 58us/step - loss: 0.9377 - accuracy: 0.6329 - val_loss: 1.5869 - val_accuracy: 0.4467\n",
      "Epoch 238/1000\n",
      "700/700 [==============================] - 0s 54us/step - loss: 0.9367 - accuracy: 0.6486 - val_loss: 1.5998 - val_accuracy: 0.4200\n",
      "Epoch 239/1000\n",
      "700/700 [==============================] - 0s 50us/step - loss: 0.9358 - accuracy: 0.6429 - val_loss: 1.6018 - val_accuracy: 0.4333\n",
      "Epoch 240/1000\n",
      "700/700 [==============================] - 0s 51us/step - loss: 0.9349 - accuracy: 0.6400 - val_loss: 1.5992 - val_accuracy: 0.4433\n",
      "Epoch 241/1000\n",
      "700/700 [==============================] - 0s 53us/step - loss: 0.9343 - accuracy: 0.6400 - val_loss: 1.5987 - val_accuracy: 0.4167\n",
      "Epoch 242/1000\n",
      "700/700 [==============================] - 0s 60us/step - loss: 0.9326 - accuracy: 0.6429 - val_loss: 1.6019 - val_accuracy: 0.4333\n",
      "Epoch 243/1000\n",
      "700/700 [==============================] - 0s 57us/step - loss: 0.9318 - accuracy: 0.6357 - val_loss: 1.6058 - val_accuracy: 0.4500\n",
      "Epoch 244/1000\n",
      "700/700 [==============================] - 0s 54us/step - loss: 0.9296 - accuracy: 0.6500 - val_loss: 1.5921 - val_accuracy: 0.4367\n",
      "Epoch 245/1000\n",
      "700/700 [==============================] - 0s 57us/step - loss: 0.9298 - accuracy: 0.6443 - val_loss: 1.6052 - val_accuracy: 0.4367\n",
      "Epoch 246/1000\n",
      "700/700 [==============================] - 0s 53us/step - loss: 0.9274 - accuracy: 0.6371 - val_loss: 1.6182 - val_accuracy: 0.4467\n",
      "Epoch 247/1000\n",
      "700/700 [==============================] - 0s 54us/step - loss: 0.9274 - accuracy: 0.6529 - val_loss: 1.6068 - val_accuracy: 0.4300\n",
      "Epoch 248/1000\n",
      "700/700 [==============================] - 0s 53us/step - loss: 0.9262 - accuracy: 0.6429 - val_loss: 1.6080 - val_accuracy: 0.4267\n",
      "Epoch 249/1000\n",
      "700/700 [==============================] - 0s 53us/step - loss: 0.9263 - accuracy: 0.6514 - val_loss: 1.6001 - val_accuracy: 0.4333\n",
      "Epoch 250/1000\n",
      "700/700 [==============================] - 0s 57us/step - loss: 0.9233 - accuracy: 0.6429 - val_loss: 1.6185 - val_accuracy: 0.4467\n",
      "Epoch 251/1000\n",
      "700/700 [==============================] - 0s 59us/step - loss: 0.9239 - accuracy: 0.6414 - val_loss: 1.6063 - val_accuracy: 0.4233\n",
      "Epoch 252/1000\n",
      "700/700 [==============================] - 0s 57us/step - loss: 0.9207 - accuracy: 0.6457 - val_loss: 1.6140 - val_accuracy: 0.4367\n",
      "Epoch 253/1000\n",
      "700/700 [==============================] - 0s 57us/step - loss: 0.9221 - accuracy: 0.6429 - val_loss: 1.6006 - val_accuracy: 0.4367\n",
      "Epoch 254/1000\n",
      "700/700 [==============================] - 0s 57us/step - loss: 0.9197 - accuracy: 0.6386 - val_loss: 1.6175 - val_accuracy: 0.4200\n",
      "Epoch 255/1000\n",
      "700/700 [==============================] - 0s 60us/step - loss: 0.9190 - accuracy: 0.6471 - val_loss: 1.6098 - val_accuracy: 0.4300\n",
      "Epoch 256/1000\n",
      "700/700 [==============================] - 0s 57us/step - loss: 0.9184 - accuracy: 0.6529 - val_loss: 1.6043 - val_accuracy: 0.4400\n",
      "Epoch 257/1000\n",
      "700/700 [==============================] - 0s 53us/step - loss: 0.9177 - accuracy: 0.6386 - val_loss: 1.6162 - val_accuracy: 0.4400\n",
      "Epoch 258/1000\n",
      "700/700 [==============================] - 0s 57us/step - loss: 0.9149 - accuracy: 0.6486 - val_loss: 1.6194 - val_accuracy: 0.4267\n",
      "Epoch 259/1000\n",
      "700/700 [==============================] - 0s 56us/step - loss: 0.9156 - accuracy: 0.6486 - val_loss: 1.6262 - val_accuracy: 0.4333\n",
      "Epoch 260/1000\n",
      "700/700 [==============================] - 0s 58us/step - loss: 0.9147 - accuracy: 0.6529 - val_loss: 1.6153 - val_accuracy: 0.4267\n",
      "Epoch 261/1000\n",
      "700/700 [==============================] - 0s 57us/step - loss: 0.9118 - accuracy: 0.6586 - val_loss: 1.6210 - val_accuracy: 0.4400\n",
      "Epoch 262/1000\n",
      "700/700 [==============================] - 0s 58us/step - loss: 0.9119 - accuracy: 0.6471 - val_loss: 1.6237 - val_accuracy: 0.4533\n",
      "Epoch 263/1000\n",
      "700/700 [==============================] - 0s 58us/step - loss: 0.9098 - accuracy: 0.6543 - val_loss: 1.6218 - val_accuracy: 0.4400\n",
      "Epoch 264/1000\n",
      "700/700 [==============================] - 0s 57us/step - loss: 0.9103 - accuracy: 0.6457 - val_loss: 1.6255 - val_accuracy: 0.4467\n",
      "Epoch 265/1000\n",
      "700/700 [==============================] - 0s 58us/step - loss: 0.9100 - accuracy: 0.6543 - val_loss: 1.6161 - val_accuracy: 0.4300\n",
      "Epoch 266/1000\n",
      "700/700 [==============================] - 0s 58us/step - loss: 0.9104 - accuracy: 0.6514 - val_loss: 1.6186 - val_accuracy: 0.4333\n",
      "Epoch 267/1000\n",
      "700/700 [==============================] - 0s 58us/step - loss: 0.9074 - accuracy: 0.6529 - val_loss: 1.6245 - val_accuracy: 0.4333\n",
      "Epoch 268/1000\n",
      "700/700 [==============================] - 0s 57us/step - loss: 0.9077 - accuracy: 0.6471 - val_loss: 1.6253 - val_accuracy: 0.4333\n",
      "Epoch 269/1000\n",
      "700/700 [==============================] - 0s 58us/step - loss: 0.9070 - accuracy: 0.6514 - val_loss: 1.6232 - val_accuracy: 0.4267\n",
      "Epoch 270/1000\n",
      "700/700 [==============================] - 0s 60us/step - loss: 0.9040 - accuracy: 0.6471 - val_loss: 1.6167 - val_accuracy: 0.4367\n",
      "Epoch 271/1000\n",
      "700/700 [==============================] - 0s 58us/step - loss: 0.9053 - accuracy: 0.6514 - val_loss: 1.6301 - val_accuracy: 0.4267\n",
      "Epoch 272/1000\n",
      "700/700 [==============================] - 0s 59us/step - loss: 0.9032 - accuracy: 0.6457 - val_loss: 1.6294 - val_accuracy: 0.4400\n",
      "Epoch 273/1000\n",
      "700/700 [==============================] - 0s 57us/step - loss: 0.9031 - accuracy: 0.6471 - val_loss: 1.6314 - val_accuracy: 0.4367\n",
      "Epoch 274/1000\n",
      "700/700 [==============================] - 0s 57us/step - loss: 0.9001 - accuracy: 0.6543 - val_loss: 1.6250 - val_accuracy: 0.4333\n",
      "Epoch 275/1000\n",
      "700/700 [==============================] - 0s 56us/step - loss: 0.9012 - accuracy: 0.6471 - val_loss: 1.6205 - val_accuracy: 0.4300\n",
      "Epoch 276/1000\n",
      "700/700 [==============================] - 0s 57us/step - loss: 0.8995 - accuracy: 0.6500 - val_loss: 1.6398 - val_accuracy: 0.4267\n",
      "Epoch 277/1000\n",
      "700/700 [==============================] - 0s 58us/step - loss: 0.8987 - accuracy: 0.6471 - val_loss: 1.6411 - val_accuracy: 0.4400\n",
      "Epoch 278/1000\n",
      "700/700 [==============================] - 0s 57us/step - loss: 0.8988 - accuracy: 0.6557 - val_loss: 1.6337 - val_accuracy: 0.4367\n",
      "Epoch 279/1000\n",
      "700/700 [==============================] - 0s 56us/step - loss: 0.8967 - accuracy: 0.6514 - val_loss: 1.6440 - val_accuracy: 0.4300\n",
      "Epoch 280/1000\n",
      "700/700 [==============================] - 0s 54us/step - loss: 0.8989 - accuracy: 0.6457 - val_loss: 1.6345 - val_accuracy: 0.4300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 281/1000\n",
      "700/700 [==============================] - 0s 54us/step - loss: 0.8963 - accuracy: 0.6586 - val_loss: 1.6378 - val_accuracy: 0.4400\n",
      "Epoch 282/1000\n",
      "700/700 [==============================] - 0s 51us/step - loss: 0.8957 - accuracy: 0.6586 - val_loss: 1.6260 - val_accuracy: 0.4400\n",
      "Epoch 283/1000\n",
      "700/700 [==============================] - 0s 51us/step - loss: 0.8944 - accuracy: 0.6471 - val_loss: 1.6471 - val_accuracy: 0.4467\n",
      "Epoch 284/1000\n",
      "700/700 [==============================] - 0s 53us/step - loss: 0.8938 - accuracy: 0.6543 - val_loss: 1.6385 - val_accuracy: 0.4267\n",
      "Epoch 285/1000\n",
      "700/700 [==============================] - 0s 54us/step - loss: 0.8940 - accuracy: 0.6543 - val_loss: 1.6379 - val_accuracy: 0.4300\n",
      "Epoch 286/1000\n",
      "700/700 [==============================] - 0s 57us/step - loss: 0.8916 - accuracy: 0.6600 - val_loss: 1.6441 - val_accuracy: 0.4267\n",
      "Epoch 287/1000\n",
      "700/700 [==============================] - 0s 58us/step - loss: 0.8900 - accuracy: 0.6529 - val_loss: 1.6522 - val_accuracy: 0.4400\n",
      "Epoch 288/1000\n",
      "700/700 [==============================] - 0s 58us/step - loss: 0.8899 - accuracy: 0.6500 - val_loss: 1.6505 - val_accuracy: 0.4433\n",
      "Epoch 289/1000\n",
      "700/700 [==============================] - 0s 57us/step - loss: 0.8880 - accuracy: 0.6614 - val_loss: 1.6460 - val_accuracy: 0.4300\n",
      "Epoch 290/1000\n",
      "700/700 [==============================] - 0s 57us/step - loss: 0.8872 - accuracy: 0.6529 - val_loss: 1.6528 - val_accuracy: 0.4467\n",
      "Epoch 291/1000\n",
      "700/700 [==============================] - 0s 57us/step - loss: 0.8884 - accuracy: 0.6571 - val_loss: 1.6506 - val_accuracy: 0.4400\n",
      "Epoch 292/1000\n",
      "700/700 [==============================] - 0s 54us/step - loss: 0.8868 - accuracy: 0.6643 - val_loss: 1.6620 - val_accuracy: 0.4367\n",
      "Epoch 293/1000\n",
      "700/700 [==============================] - 0s 53us/step - loss: 0.8865 - accuracy: 0.6457 - val_loss: 1.6555 - val_accuracy: 0.4300\n",
      "Epoch 294/1000\n",
      "700/700 [==============================] - 0s 53us/step - loss: 0.8844 - accuracy: 0.6586 - val_loss: 1.6584 - val_accuracy: 0.4233\n",
      "Epoch 295/1000\n",
      "700/700 [==============================] - 0s 53us/step - loss: 0.8842 - accuracy: 0.6629 - val_loss: 1.6556 - val_accuracy: 0.4467\n",
      "Epoch 296/1000\n",
      "700/700 [==============================] - 0s 53us/step - loss: 0.8837 - accuracy: 0.6543 - val_loss: 1.6566 - val_accuracy: 0.4533\n",
      "Epoch 297/1000\n",
      "700/700 [==============================] - 0s 53us/step - loss: 0.8834 - accuracy: 0.6557 - val_loss: 1.6513 - val_accuracy: 0.4433\n",
      "Epoch 298/1000\n",
      "700/700 [==============================] - 0s 53us/step - loss: 0.8804 - accuracy: 0.6600 - val_loss: 1.6548 - val_accuracy: 0.4500\n",
      "Epoch 299/1000\n",
      "700/700 [==============================] - 0s 53us/step - loss: 0.8806 - accuracy: 0.6557 - val_loss: 1.6568 - val_accuracy: 0.4333\n",
      "Epoch 300/1000\n",
      "700/700 [==============================] - 0s 54us/step - loss: 0.8799 - accuracy: 0.6529 - val_loss: 1.6764 - val_accuracy: 0.4500\n",
      "Epoch 301/1000\n",
      "700/700 [==============================] - 0s 56us/step - loss: 0.8804 - accuracy: 0.6629 - val_loss: 1.6712 - val_accuracy: 0.4433\n",
      "Epoch 302/1000\n",
      "700/700 [==============================] - 0s 54us/step - loss: 0.8771 - accuracy: 0.6600 - val_loss: 1.6982 - val_accuracy: 0.4333\n",
      "Epoch 303/1000\n",
      "700/700 [==============================] - 0s 60us/step - loss: 0.8806 - accuracy: 0.6600 - val_loss: 1.6619 - val_accuracy: 0.4433\n",
      "Epoch 304/1000\n",
      "700/700 [==============================] - 0s 58us/step - loss: 0.8784 - accuracy: 0.6600 - val_loss: 1.6792 - val_accuracy: 0.4367\n",
      "Epoch 305/1000\n",
      "700/700 [==============================] - 0s 53us/step - loss: 0.8776 - accuracy: 0.6571 - val_loss: 1.6656 - val_accuracy: 0.4300\n",
      "Epoch 306/1000\n",
      "700/700 [==============================] - 0s 57us/step - loss: 0.8749 - accuracy: 0.6643 - val_loss: 1.6736 - val_accuracy: 0.4367\n",
      "Epoch 307/1000\n",
      "700/700 [==============================] - 0s 57us/step - loss: 0.8754 - accuracy: 0.6629 - val_loss: 1.6634 - val_accuracy: 0.4467\n",
      "Epoch 308/1000\n",
      "700/700 [==============================] - 0s 53us/step - loss: 0.8744 - accuracy: 0.6686 - val_loss: 1.6651 - val_accuracy: 0.4333\n",
      "Epoch 309/1000\n",
      "700/700 [==============================] - 0s 53us/step - loss: 0.8734 - accuracy: 0.6557 - val_loss: 1.6690 - val_accuracy: 0.4267\n",
      "Epoch 310/1000\n",
      "700/700 [==============================] - 0s 54us/step - loss: 0.8728 - accuracy: 0.6643 - val_loss: 1.6664 - val_accuracy: 0.4333\n",
      "Epoch 311/1000\n",
      "700/700 [==============================] - 0s 54us/step - loss: 0.8723 - accuracy: 0.6657 - val_loss: 1.6613 - val_accuracy: 0.4467\n",
      "Epoch 312/1000\n",
      "700/700 [==============================] - 0s 50us/step - loss: 0.8710 - accuracy: 0.6671 - val_loss: 1.6810 - val_accuracy: 0.4467\n",
      "Epoch 313/1000\n",
      "700/700 [==============================] - 0s 53us/step - loss: 0.8697 - accuracy: 0.6686 - val_loss: 1.6802 - val_accuracy: 0.4467\n",
      "Epoch 314/1000\n",
      "700/700 [==============================] - 0s 54us/step - loss: 0.8693 - accuracy: 0.6614 - val_loss: 1.6736 - val_accuracy: 0.4367\n",
      "Epoch 315/1000\n",
      "700/700 [==============================] - 0s 54us/step - loss: 0.8696 - accuracy: 0.6629 - val_loss: 1.6810 - val_accuracy: 0.4467\n",
      "Epoch 316/1000\n",
      "700/700 [==============================] - 0s 54us/step - loss: 0.8689 - accuracy: 0.6614 - val_loss: 1.6790 - val_accuracy: 0.4433\n",
      "Epoch 317/1000\n",
      "700/700 [==============================] - 0s 56us/step - loss: 0.8684 - accuracy: 0.6686 - val_loss: 1.6839 - val_accuracy: 0.4433\n",
      "Epoch 318/1000\n",
      "700/700 [==============================] - 0s 58us/step - loss: 0.8650 - accuracy: 0.6757 - val_loss: 1.6830 - val_accuracy: 0.4400\n",
      "Epoch 319/1000\n",
      "700/700 [==============================] - 0s 57us/step - loss: 0.8674 - accuracy: 0.6529 - val_loss: 1.6842 - val_accuracy: 0.4433\n",
      "Epoch 320/1000\n",
      "700/700 [==============================] - 0s 60us/step - loss: 0.8648 - accuracy: 0.6671 - val_loss: 1.6848 - val_accuracy: 0.4267\n",
      "Epoch 321/1000\n",
      "700/700 [==============================] - 0s 58us/step - loss: 0.8648 - accuracy: 0.6686 - val_loss: 1.6847 - val_accuracy: 0.4300\n",
      "Epoch 322/1000\n",
      "700/700 [==============================] - 0s 58us/step - loss: 0.8630 - accuracy: 0.6629 - val_loss: 1.6852 - val_accuracy: 0.4267\n",
      "Epoch 323/1000\n",
      "700/700 [==============================] - 0s 57us/step - loss: 0.8626 - accuracy: 0.6686 - val_loss: 1.6846 - val_accuracy: 0.4400\n",
      "Epoch 324/1000\n",
      "700/700 [==============================] - 0s 53us/step - loss: 0.8638 - accuracy: 0.6657 - val_loss: 1.6900 - val_accuracy: 0.4533\n",
      "Epoch 325/1000\n",
      "700/700 [==============================] - 0s 53us/step - loss: 0.8611 - accuracy: 0.6686 - val_loss: 1.6889 - val_accuracy: 0.4333\n",
      "Epoch 326/1000\n",
      "700/700 [==============================] - 0s 53us/step - loss: 0.8613 - accuracy: 0.6657 - val_loss: 1.6904 - val_accuracy: 0.4300\n",
      "Epoch 327/1000\n",
      "700/700 [==============================] - 0s 53us/step - loss: 0.8606 - accuracy: 0.6671 - val_loss: 1.6967 - val_accuracy: 0.4300\n",
      "Epoch 328/1000\n",
      "700/700 [==============================] - 0s 53us/step - loss: 0.8590 - accuracy: 0.6629 - val_loss: 1.7018 - val_accuracy: 0.4200\n",
      "Epoch 329/1000\n",
      "700/700 [==============================] - 0s 50us/step - loss: 0.8594 - accuracy: 0.6657 - val_loss: 1.7029 - val_accuracy: 0.4200\n",
      "Epoch 330/1000\n",
      "700/700 [==============================] - 0s 57us/step - loss: 0.8581 - accuracy: 0.6729 - val_loss: 1.7167 - val_accuracy: 0.4433\n",
      "Epoch 331/1000\n",
      "700/700 [==============================] - 0s 54us/step - loss: 0.8562 - accuracy: 0.6700 - val_loss: 1.7308 - val_accuracy: 0.4500\n",
      "Epoch 332/1000\n",
      "700/700 [==============================] - 0s 53us/step - loss: 0.8578 - accuracy: 0.6700 - val_loss: 1.7116 - val_accuracy: 0.4467\n",
      "Epoch 333/1000\n",
      "700/700 [==============================] - 0s 54us/step - loss: 0.8582 - accuracy: 0.6686 - val_loss: 1.7013 - val_accuracy: 0.4300\n",
      "Epoch 334/1000\n",
      "700/700 [==============================] - 0s 56us/step - loss: 0.8565 - accuracy: 0.6629 - val_loss: 1.7082 - val_accuracy: 0.4500\n",
      "Epoch 335/1000\n",
      "700/700 [==============================] - 0s 56us/step - loss: 0.8551 - accuracy: 0.6757 - val_loss: 1.7040 - val_accuracy: 0.4300\n",
      "Epoch 336/1000\n",
      "700/700 [==============================] - 0s 57us/step - loss: 0.8546 - accuracy: 0.6686 - val_loss: 1.7075 - val_accuracy: 0.4433\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 337/1000\n",
      "700/700 [==============================] - 0s 58us/step - loss: 0.8530 - accuracy: 0.6657 - val_loss: 1.6932 - val_accuracy: 0.4467\n",
      "Epoch 338/1000\n",
      "700/700 [==============================] - 0s 59us/step - loss: 0.8535 - accuracy: 0.6743 - val_loss: 1.7147 - val_accuracy: 0.4467\n",
      "Epoch 339/1000\n",
      "700/700 [==============================] - 0s 54us/step - loss: 0.8514 - accuracy: 0.6743 - val_loss: 1.7302 - val_accuracy: 0.4467\n",
      "Epoch 340/1000\n",
      "700/700 [==============================] - 0s 56us/step - loss: 0.8530 - accuracy: 0.6729 - val_loss: 1.7102 - val_accuracy: 0.4333\n",
      "Epoch 341/1000\n",
      "700/700 [==============================] - 0s 58us/step - loss: 0.8506 - accuracy: 0.6786 - val_loss: 1.7022 - val_accuracy: 0.4400\n",
      "Epoch 342/1000\n",
      "700/700 [==============================] - 0s 58us/step - loss: 0.8509 - accuracy: 0.6743 - val_loss: 1.7318 - val_accuracy: 0.4400\n",
      "Epoch 343/1000\n",
      "700/700 [==============================] - 0s 60us/step - loss: 0.8479 - accuracy: 0.6743 - val_loss: 1.7217 - val_accuracy: 0.4367\n",
      "Epoch 344/1000\n",
      "700/700 [==============================] - 0s 58us/step - loss: 0.8476 - accuracy: 0.6729 - val_loss: 1.7133 - val_accuracy: 0.4167\n",
      "Epoch 345/1000\n",
      "700/700 [==============================] - 0s 56us/step - loss: 0.8491 - accuracy: 0.6700 - val_loss: 1.7158 - val_accuracy: 0.4433\n",
      "Epoch 346/1000\n",
      "700/700 [==============================] - 0s 53us/step - loss: 0.8492 - accuracy: 0.6757 - val_loss: 1.7257 - val_accuracy: 0.4167\n",
      "Epoch 347/1000\n",
      "700/700 [==============================] - 0s 54us/step - loss: 0.8483 - accuracy: 0.6757 - val_loss: 1.7326 - val_accuracy: 0.4433\n",
      "Epoch 348/1000\n",
      "700/700 [==============================] - 0s 57us/step - loss: 0.8482 - accuracy: 0.6671 - val_loss: 1.7475 - val_accuracy: 0.4500\n",
      "Epoch 349/1000\n",
      "700/700 [==============================] - 0s 54us/step - loss: 0.8462 - accuracy: 0.6700 - val_loss: 1.7224 - val_accuracy: 0.4367\n",
      "Epoch 350/1000\n",
      "700/700 [==============================] - 0s 57us/step - loss: 0.8457 - accuracy: 0.6700 - val_loss: 1.7183 - val_accuracy: 0.4233\n",
      "Epoch 351/1000\n",
      "700/700 [==============================] - 0s 56us/step - loss: 0.8442 - accuracy: 0.6757 - val_loss: 1.7485 - val_accuracy: 0.4500\n",
      "Epoch 352/1000\n",
      "700/700 [==============================] - 0s 56us/step - loss: 0.8446 - accuracy: 0.6829 - val_loss: 1.7470 - val_accuracy: 0.4367\n",
      "Epoch 353/1000\n",
      "700/700 [==============================] - 0s 54us/step - loss: 0.8422 - accuracy: 0.6700 - val_loss: 1.7261 - val_accuracy: 0.4167\n",
      "Epoch 354/1000\n",
      "700/700 [==============================] - 0s 53us/step - loss: 0.8426 - accuracy: 0.6757 - val_loss: 1.7408 - val_accuracy: 0.4533\n",
      "Epoch 355/1000\n",
      "700/700 [==============================] - 0s 56us/step - loss: 0.8425 - accuracy: 0.6743 - val_loss: 1.7380 - val_accuracy: 0.4467\n",
      "Epoch 356/1000\n",
      "700/700 [==============================] - 0s 58us/step - loss: 0.8403 - accuracy: 0.6714 - val_loss: 1.7440 - val_accuracy: 0.4167\n",
      "Epoch 357/1000\n",
      "700/700 [==============================] - 0s 57us/step - loss: 0.8407 - accuracy: 0.6829 - val_loss: 1.7314 - val_accuracy: 0.4367\n",
      "Epoch 358/1000\n",
      "700/700 [==============================] - 0s 58us/step - loss: 0.8393 - accuracy: 0.6757 - val_loss: 1.7557 - val_accuracy: 0.4400\n",
      "Epoch 359/1000\n",
      "700/700 [==============================] - 0s 54us/step - loss: 0.8412 - accuracy: 0.6829 - val_loss: 1.7513 - val_accuracy: 0.4533\n",
      "Epoch 360/1000\n",
      "700/700 [==============================] - 0s 53us/step - loss: 0.8384 - accuracy: 0.6771 - val_loss: 1.7251 - val_accuracy: 0.4300\n",
      "Epoch 361/1000\n",
      "700/700 [==============================] - 0s 53us/step - loss: 0.8384 - accuracy: 0.6786 - val_loss: 1.7335 - val_accuracy: 0.4400\n",
      "Epoch 362/1000\n",
      "700/700 [==============================] - 0s 53us/step - loss: 0.8385 - accuracy: 0.6829 - val_loss: 1.7466 - val_accuracy: 0.4467\n",
      "Epoch 363/1000\n",
      "700/700 [==============================] - 0s 54us/step - loss: 0.8380 - accuracy: 0.6843 - val_loss: 1.7401 - val_accuracy: 0.4433\n",
      "Epoch 364/1000\n",
      "700/700 [==============================] - 0s 51us/step - loss: 0.8376 - accuracy: 0.6729 - val_loss: 1.7410 - val_accuracy: 0.4333\n",
      "Epoch 365/1000\n",
      "700/700 [==============================] - 0s 54us/step - loss: 0.8367 - accuracy: 0.6800 - val_loss: 1.7498 - val_accuracy: 0.4300\n",
      "Epoch 366/1000\n",
      "700/700 [==============================] - 0s 56us/step - loss: 0.8356 - accuracy: 0.6771 - val_loss: 1.7420 - val_accuracy: 0.4333\n",
      "Epoch 367/1000\n",
      "700/700 [==============================] - 0s 53us/step - loss: 0.8350 - accuracy: 0.6814 - val_loss: 1.7629 - val_accuracy: 0.4467\n",
      "Epoch 368/1000\n",
      "700/700 [==============================] - ETA: 0s - loss: 0.6944 - accuracy: 0.80 - 0s 53us/step - loss: 0.8341 - accuracy: 0.6829 - val_loss: 1.7488 - val_accuracy: 0.4367\n",
      "Epoch 369/1000\n",
      "700/700 [==============================] - 0s 56us/step - loss: 0.8340 - accuracy: 0.6814 - val_loss: 1.7460 - val_accuracy: 0.4333\n",
      "Epoch 370/1000\n",
      "700/700 [==============================] - 0s 57us/step - loss: 0.8320 - accuracy: 0.6843 - val_loss: 1.7761 - val_accuracy: 0.4500\n",
      "Epoch 371/1000\n",
      "700/700 [==============================] - 0s 60us/step - loss: 0.8342 - accuracy: 0.6800 - val_loss: 1.7573 - val_accuracy: 0.4300\n",
      "Epoch 372/1000\n",
      "700/700 [==============================] - 0s 60us/step - loss: 0.8328 - accuracy: 0.6843 - val_loss: 1.7599 - val_accuracy: 0.4467\n",
      "Epoch 373/1000\n",
      "700/700 [==============================] - 0s 58us/step - loss: 0.8316 - accuracy: 0.6786 - val_loss: 1.7511 - val_accuracy: 0.4367\n",
      "Epoch 374/1000\n",
      "700/700 [==============================] - 0s 57us/step - loss: 0.8296 - accuracy: 0.6843 - val_loss: 1.7627 - val_accuracy: 0.4200\n",
      "Epoch 375/1000\n",
      "700/700 [==============================] - 0s 57us/step - loss: 0.8316 - accuracy: 0.6786 - val_loss: 1.7551 - val_accuracy: 0.4333\n",
      "Epoch 376/1000\n",
      "700/700 [==============================] - 0s 56us/step - loss: 0.8320 - accuracy: 0.6786 - val_loss: 1.7636 - val_accuracy: 0.4400\n",
      "Epoch 377/1000\n",
      "700/700 [==============================] - 0s 58us/step - loss: 0.8296 - accuracy: 0.6771 - val_loss: 1.7626 - val_accuracy: 0.4333\n",
      "Epoch 378/1000\n",
      "700/700 [==============================] - 0s 57us/step - loss: 0.8300 - accuracy: 0.6857 - val_loss: 1.7612 - val_accuracy: 0.4300\n",
      "Epoch 379/1000\n",
      "700/700 [==============================] - 0s 57us/step - loss: 0.8283 - accuracy: 0.6871 - val_loss: 1.7636 - val_accuracy: 0.4300\n",
      "Epoch 380/1000\n",
      "700/700 [==============================] - 0s 54us/step - loss: 0.8284 - accuracy: 0.6829 - val_loss: 1.7803 - val_accuracy: 0.4333\n",
      "Epoch 381/1000\n",
      "700/700 [==============================] - 0s 61us/step - loss: 0.8272 - accuracy: 0.6786 - val_loss: 1.7650 - val_accuracy: 0.4333\n",
      "Epoch 382/1000\n",
      "700/700 [==============================] - 0s 56us/step - loss: 0.8264 - accuracy: 0.6786 - val_loss: 1.7869 - val_accuracy: 0.4433\n",
      "Epoch 383/1000\n",
      "700/700 [==============================] - 0s 56us/step - loss: 0.8268 - accuracy: 0.6843 - val_loss: 1.7788 - val_accuracy: 0.4433\n",
      "Epoch 384/1000\n",
      "700/700 [==============================] - 0s 57us/step - loss: 0.8263 - accuracy: 0.6786 - val_loss: 1.7728 - val_accuracy: 0.4300\n",
      "Epoch 385/1000\n",
      "700/700 [==============================] - 0s 57us/step - loss: 0.8255 - accuracy: 0.6843 - val_loss: 1.7741 - val_accuracy: 0.4267\n",
      "Epoch 386/1000\n",
      "700/700 [==============================] - 0s 57us/step - loss: 0.8227 - accuracy: 0.6857 - val_loss: 1.7939 - val_accuracy: 0.4400\n",
      "Epoch 387/1000\n",
      "700/700 [==============================] - 0s 58us/step - loss: 0.8245 - accuracy: 0.6814 - val_loss: 1.7974 - val_accuracy: 0.4433\n",
      "Epoch 388/1000\n",
      "700/700 [==============================] - 0s 58us/step - loss: 0.8232 - accuracy: 0.6843 - val_loss: 1.7843 - val_accuracy: 0.4433\n",
      "Epoch 389/1000\n",
      "700/700 [==============================] - 0s 60us/step - loss: 0.8234 - accuracy: 0.6871 - val_loss: 1.7960 - val_accuracy: 0.4500\n",
      "Epoch 390/1000\n",
      "700/700 [==============================] - 0s 60us/step - loss: 0.8212 - accuracy: 0.6829 - val_loss: 1.7603 - val_accuracy: 0.4233\n",
      "Epoch 391/1000\n",
      "700/700 [==============================] - 0s 60us/step - loss: 0.8218 - accuracy: 0.6814 - val_loss: 1.7849 - val_accuracy: 0.4333\n",
      "Epoch 392/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "700/700 [==============================] - 0s 60us/step - loss: 0.8217 - accuracy: 0.6871 - val_loss: 1.7921 - val_accuracy: 0.4333\n",
      "Epoch 393/1000\n",
      "700/700 [==============================] - 0s 57us/step - loss: 0.8205 - accuracy: 0.6800 - val_loss: 1.8295 - val_accuracy: 0.4400\n",
      "Epoch 394/1000\n",
      "700/700 [==============================] - 0s 56us/step - loss: 0.8206 - accuracy: 0.6800 - val_loss: 1.7916 - val_accuracy: 0.4400\n",
      "Epoch 395/1000\n",
      "700/700 [==============================] - 0s 58us/step - loss: 0.8190 - accuracy: 0.6857 - val_loss: 1.8212 - val_accuracy: 0.4333\n",
      "Epoch 396/1000\n",
      "700/700 [==============================] - 0s 54us/step - loss: 0.8198 - accuracy: 0.6843 - val_loss: 1.7958 - val_accuracy: 0.4433\n",
      "Epoch 397/1000\n",
      "700/700 [==============================] - 0s 53us/step - loss: 0.8173 - accuracy: 0.6771 - val_loss: 1.7964 - val_accuracy: 0.4400\n",
      "Epoch 398/1000\n",
      "700/700 [==============================] - 0s 53us/step - loss: 0.8175 - accuracy: 0.6886 - val_loss: 1.8182 - val_accuracy: 0.4433\n",
      "Epoch 399/1000\n",
      "700/700 [==============================] - 0s 56us/step - loss: 0.8160 - accuracy: 0.6857 - val_loss: 1.8076 - val_accuracy: 0.4367\n",
      "Epoch 400/1000\n",
      "700/700 [==============================] - 0s 57us/step - loss: 0.8179 - accuracy: 0.6857 - val_loss: 1.7957 - val_accuracy: 0.4333\n",
      "Epoch 401/1000\n",
      "700/700 [==============================] - 0s 57us/step - loss: 0.8164 - accuracy: 0.6814 - val_loss: 1.8126 - val_accuracy: 0.4433\n",
      "Epoch 402/1000\n",
      "700/700 [==============================] - 0s 57us/step - loss: 0.8161 - accuracy: 0.6857 - val_loss: 1.7892 - val_accuracy: 0.4300\n",
      "Epoch 403/1000\n",
      "700/700 [==============================] - 0s 56us/step - loss: 0.8164 - accuracy: 0.6829 - val_loss: 1.8083 - val_accuracy: 0.4367\n",
      "Epoch 404/1000\n",
      "700/700 [==============================] - 0s 54us/step - loss: 0.8150 - accuracy: 0.6814 - val_loss: 1.7910 - val_accuracy: 0.4367\n",
      "Epoch 405/1000\n",
      "700/700 [==============================] - 0s 54us/step - loss: 0.8149 - accuracy: 0.6829 - val_loss: 1.8055 - val_accuracy: 0.4333\n",
      "Epoch 406/1000\n",
      "700/700 [==============================] - 0s 54us/step - loss: 0.8133 - accuracy: 0.6814 - val_loss: 1.8068 - val_accuracy: 0.4333\n",
      "Epoch 407/1000\n",
      "700/700 [==============================] - 0s 51us/step - loss: 0.8127 - accuracy: 0.6857 - val_loss: 1.8135 - val_accuracy: 0.4400\n",
      "Epoch 408/1000\n",
      "700/700 [==============================] - 0s 57us/step - loss: 0.8123 - accuracy: 0.6871 - val_loss: 1.8042 - val_accuracy: 0.4400\n",
      "Epoch 409/1000\n",
      "700/700 [==============================] - 0s 57us/step - loss: 0.8136 - accuracy: 0.6857 - val_loss: 1.8144 - val_accuracy: 0.4367\n",
      "Epoch 410/1000\n",
      "700/700 [==============================] - 0s 57us/step - loss: 0.8099 - accuracy: 0.6914 - val_loss: 1.8025 - val_accuracy: 0.4233\n",
      "Epoch 411/1000\n",
      "700/700 [==============================] - 0s 57us/step - loss: 0.8119 - accuracy: 0.6829 - val_loss: 1.8236 - val_accuracy: 0.4367\n",
      "Epoch 412/1000\n",
      "700/700 [==============================] - 0s 57us/step - loss: 0.8103 - accuracy: 0.6886 - val_loss: 1.8298 - val_accuracy: 0.4367\n",
      "Epoch 413/1000\n",
      "700/700 [==============================] - 0s 56us/step - loss: 0.8111 - accuracy: 0.6829 - val_loss: 1.8018 - val_accuracy: 0.4333\n",
      "Epoch 414/1000\n",
      "700/700 [==============================] - 0s 56us/step - loss: 0.8088 - accuracy: 0.6971 - val_loss: 1.8359 - val_accuracy: 0.4400\n",
      "Epoch 415/1000\n",
      "700/700 [==============================] - 0s 57us/step - loss: 0.8099 - accuracy: 0.6900 - val_loss: 1.8318 - val_accuracy: 0.4267\n",
      "Epoch 416/1000\n",
      "700/700 [==============================] - 0s 58us/step - loss: 0.8084 - accuracy: 0.6871 - val_loss: 1.8198 - val_accuracy: 0.4267\n",
      "Epoch 417/1000\n",
      "700/700 [==============================] - 0s 57us/step - loss: 0.8077 - accuracy: 0.6871 - val_loss: 1.8297 - val_accuracy: 0.4300\n",
      "Epoch 418/1000\n",
      "700/700 [==============================] - 0s 57us/step - loss: 0.8087 - accuracy: 0.6857 - val_loss: 1.8275 - val_accuracy: 0.4333\n",
      "Epoch 419/1000\n",
      "700/700 [==============================] - 0s 58us/step - loss: 0.8065 - accuracy: 0.6886 - val_loss: 1.8305 - val_accuracy: 0.4367\n",
      "Epoch 420/1000\n",
      "700/700 [==============================] - 0s 54us/step - loss: 0.8057 - accuracy: 0.6871 - val_loss: 1.8139 - val_accuracy: 0.4400\n",
      "Epoch 421/1000\n",
      "700/700 [==============================] - 0s 56us/step - loss: 0.8056 - accuracy: 0.6900 - val_loss: 1.8361 - val_accuracy: 0.4300\n",
      "Epoch 422/1000\n",
      "700/700 [==============================] - 0s 54us/step - loss: 0.8056 - accuracy: 0.6843 - val_loss: 1.8442 - val_accuracy: 0.4300\n",
      "Epoch 423/1000\n",
      "700/700 [==============================] - 0s 51us/step - loss: 0.8055 - accuracy: 0.6857 - val_loss: 1.8281 - val_accuracy: 0.4267\n",
      "Epoch 424/1000\n",
      "700/700 [==============================] - 0s 54us/step - loss: 0.8050 - accuracy: 0.6871 - val_loss: 1.8376 - val_accuracy: 0.4300\n",
      "Epoch 425/1000\n",
      "700/700 [==============================] - 0s 53us/step - loss: 0.8042 - accuracy: 0.6857 - val_loss: 1.8503 - val_accuracy: 0.4400\n",
      "Epoch 426/1000\n",
      "700/700 [==============================] - 0s 50us/step - loss: 0.8026 - accuracy: 0.6957 - val_loss: 1.8251 - val_accuracy: 0.4267\n",
      "Epoch 427/1000\n",
      "700/700 [==============================] - 0s 56us/step - loss: 0.8034 - accuracy: 0.6914 - val_loss: 1.8489 - val_accuracy: 0.4433\n",
      "Epoch 428/1000\n",
      "700/700 [==============================] - 0s 56us/step - loss: 0.8016 - accuracy: 0.6914 - val_loss: 1.8310 - val_accuracy: 0.4333\n",
      "Epoch 429/1000\n",
      "700/700 [==============================] - 0s 54us/step - loss: 0.8028 - accuracy: 0.6857 - val_loss: 1.8456 - val_accuracy: 0.4333\n",
      "Epoch 430/1000\n",
      "700/700 [==============================] - 0s 56us/step - loss: 0.8016 - accuracy: 0.6886 - val_loss: 1.8289 - val_accuracy: 0.4333\n",
      "Epoch 431/1000\n",
      "700/700 [==============================] - 0s 56us/step - loss: 0.8012 - accuracy: 0.6871 - val_loss: 1.8395 - val_accuracy: 0.4333\n",
      "Epoch 432/1000\n",
      "700/700 [==============================] - 0s 53us/step - loss: 0.7998 - accuracy: 0.6943 - val_loss: 1.8411 - val_accuracy: 0.4333\n",
      "Epoch 433/1000\n",
      "700/700 [==============================] - 0s 54us/step - loss: 0.8001 - accuracy: 0.6900 - val_loss: 1.8517 - val_accuracy: 0.4233\n",
      "Epoch 434/1000\n",
      "700/700 [==============================] - 0s 56us/step - loss: 0.7994 - accuracy: 0.6957 - val_loss: 1.8613 - val_accuracy: 0.4267\n",
      "Epoch 435/1000\n",
      "700/700 [==============================] - 0s 54us/step - loss: 0.7984 - accuracy: 0.6900 - val_loss: 1.8672 - val_accuracy: 0.4267\n",
      "Epoch 436/1000\n",
      "700/700 [==============================] - 0s 54us/step - loss: 0.7970 - accuracy: 0.6900 - val_loss: 1.8656 - val_accuracy: 0.4300\n",
      "Epoch 437/1000\n",
      "700/700 [==============================] - 0s 56us/step - loss: 0.7986 - accuracy: 0.6900 - val_loss: 1.8482 - val_accuracy: 0.4367\n",
      "Epoch 438/1000\n",
      "700/700 [==============================] - 0s 53us/step - loss: 0.7980 - accuracy: 0.6914 - val_loss: 1.8631 - val_accuracy: 0.4367\n",
      "Epoch 439/1000\n",
      "700/700 [==============================] - 0s 56us/step - loss: 0.7983 - accuracy: 0.6929 - val_loss: 1.8553 - val_accuracy: 0.4300\n",
      "Epoch 440/1000\n",
      "700/700 [==============================] - 0s 54us/step - loss: 0.7971 - accuracy: 0.6857 - val_loss: 1.8768 - val_accuracy: 0.4267\n",
      "Epoch 441/1000\n",
      "700/700 [==============================] - 0s 57us/step - loss: 0.7961 - accuracy: 0.6871 - val_loss: 1.8573 - val_accuracy: 0.4367\n",
      "Epoch 442/1000\n",
      "700/700 [==============================] - 0s 58us/step - loss: 0.7948 - accuracy: 0.6857 - val_loss: 1.8487 - val_accuracy: 0.4333\n",
      "Epoch 443/1000\n",
      "700/700 [==============================] - 0s 56us/step - loss: 0.7943 - accuracy: 0.6943 - val_loss: 1.8677 - val_accuracy: 0.4200\n",
      "Epoch 444/1000\n",
      "700/700 [==============================] - 0s 57us/step - loss: 0.7948 - accuracy: 0.6929 - val_loss: 1.8678 - val_accuracy: 0.4233\n",
      "Epoch 445/1000\n",
      "700/700 [==============================] - 0s 53us/step - loss: 0.7936 - accuracy: 0.6986 - val_loss: 1.8622 - val_accuracy: 0.4300\n",
      "Epoch 446/1000\n",
      "700/700 [==============================] - 0s 58us/step - loss: 0.7943 - accuracy: 0.6971 - val_loss: 1.8837 - val_accuracy: 0.4333\n",
      "Epoch 447/1000\n",
      "700/700 [==============================] - 0s 61us/step - loss: 0.7943 - accuracy: 0.6871 - val_loss: 1.8712 - val_accuracy: 0.4267\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 448/1000\n",
      "700/700 [==============================] - 0s 57us/step - loss: 0.7921 - accuracy: 0.6986 - val_loss: 1.8790 - val_accuracy: 0.4333\n",
      "Epoch 449/1000\n",
      "700/700 [==============================] - 0s 51us/step - loss: 0.7934 - accuracy: 0.6900 - val_loss: 1.8607 - val_accuracy: 0.4300\n",
      "Epoch 450/1000\n",
      "700/700 [==============================] - 0s 60us/step - loss: 0.7918 - accuracy: 0.6957 - val_loss: 1.8769 - val_accuracy: 0.4267\n",
      "Epoch 451/1000\n",
      "700/700 [==============================] - 0s 56us/step - loss: 0.7928 - accuracy: 0.6943 - val_loss: 1.8629 - val_accuracy: 0.4333\n",
      "Epoch 452/1000\n",
      "700/700 [==============================] - 0s 56us/step - loss: 0.7895 - accuracy: 0.6929 - val_loss: 1.8752 - val_accuracy: 0.4233\n",
      "Epoch 453/1000\n",
      "700/700 [==============================] - 0s 53us/step - loss: 0.7903 - accuracy: 0.6914 - val_loss: 1.8872 - val_accuracy: 0.4233\n",
      "Epoch 454/1000\n",
      "700/700 [==============================] - 0s 56us/step - loss: 0.7895 - accuracy: 0.7014 - val_loss: 1.8915 - val_accuracy: 0.4300\n",
      "Epoch 455/1000\n",
      "700/700 [==============================] - 0s 53us/step - loss: 0.7906 - accuracy: 0.6943 - val_loss: 1.8868 - val_accuracy: 0.4267\n",
      "Epoch 456/1000\n",
      "700/700 [==============================] - 0s 53us/step - loss: 0.7902 - accuracy: 0.6957 - val_loss: 1.9018 - val_accuracy: 0.4233\n",
      "Epoch 457/1000\n",
      "700/700 [==============================] - 0s 54us/step - loss: 0.7884 - accuracy: 0.6957 - val_loss: 1.9013 - val_accuracy: 0.4333\n",
      "Epoch 458/1000\n",
      "700/700 [==============================] - 0s 54us/step - loss: 0.7871 - accuracy: 0.6971 - val_loss: 1.8825 - val_accuracy: 0.4200\n",
      "Epoch 459/1000\n",
      "700/700 [==============================] - 0s 58us/step - loss: 0.7898 - accuracy: 0.6900 - val_loss: 1.8828 - val_accuracy: 0.4300\n",
      "Epoch 460/1000\n",
      "700/700 [==============================] - 0s 57us/step - loss: 0.7878 - accuracy: 0.6986 - val_loss: 1.9021 - val_accuracy: 0.4300\n",
      "Epoch 461/1000\n",
      "700/700 [==============================] - 0s 57us/step - loss: 0.7865 - accuracy: 0.6986 - val_loss: 1.8981 - val_accuracy: 0.4300\n",
      "Epoch 462/1000\n",
      "700/700 [==============================] - 0s 58us/step - loss: 0.7866 - accuracy: 0.6957 - val_loss: 1.8773 - val_accuracy: 0.4300\n",
      "Epoch 463/1000\n",
      "700/700 [==============================] - 0s 57us/step - loss: 0.7864 - accuracy: 0.6971 - val_loss: 1.8970 - val_accuracy: 0.4233\n",
      "Epoch 464/1000\n",
      "700/700 [==============================] - 0s 56us/step - loss: 0.7863 - accuracy: 0.6943 - val_loss: 1.8942 - val_accuracy: 0.4267\n",
      "Epoch 465/1000\n",
      "700/700 [==============================] - 0s 54us/step - loss: 0.7848 - accuracy: 0.6957 - val_loss: 1.8898 - val_accuracy: 0.4367\n",
      "Epoch 466/1000\n",
      "700/700 [==============================] - 0s 53us/step - loss: 0.7853 - accuracy: 0.6971 - val_loss: 1.9112 - val_accuracy: 0.4333\n",
      "Epoch 467/1000\n",
      "700/700 [==============================] - 0s 51us/step - loss: 0.7833 - accuracy: 0.6857 - val_loss: 1.8808 - val_accuracy: 0.4333\n",
      "Epoch 468/1000\n",
      "700/700 [==============================] - 0s 53us/step - loss: 0.7842 - accuracy: 0.7000 - val_loss: 1.8940 - val_accuracy: 0.4300\n",
      "Epoch 469/1000\n",
      "700/700 [==============================] - 0s 56us/step - loss: 0.7836 - accuracy: 0.6943 - val_loss: 1.8867 - val_accuracy: 0.4333\n",
      "Epoch 470/1000\n",
      "700/700 [==============================] - 0s 58us/step - loss: 0.7829 - accuracy: 0.6957 - val_loss: 1.9001 - val_accuracy: 0.4333\n",
      "Epoch 471/1000\n",
      "700/700 [==============================] - 0s 57us/step - loss: 0.7831 - accuracy: 0.6986 - val_loss: 1.8997 - val_accuracy: 0.4267\n",
      "Epoch 472/1000\n",
      "700/700 [==============================] - 0s 56us/step - loss: 0.7834 - accuracy: 0.6929 - val_loss: 1.9183 - val_accuracy: 0.4300\n",
      "Epoch 473/1000\n",
      "700/700 [==============================] - 0s 57us/step - loss: 0.7812 - accuracy: 0.6957 - val_loss: 1.8904 - val_accuracy: 0.4333\n",
      "Epoch 474/1000\n",
      "700/700 [==============================] - 0s 59us/step - loss: 0.7802 - accuracy: 0.7000 - val_loss: 1.9243 - val_accuracy: 0.4267\n",
      "Epoch 475/1000\n",
      "700/700 [==============================] - 0s 60us/step - loss: 0.7808 - accuracy: 0.7000 - val_loss: 1.9123 - val_accuracy: 0.4233\n",
      "Epoch 476/1000\n",
      "700/700 [==============================] - 0s 56us/step - loss: 0.7789 - accuracy: 0.7043 - val_loss: 1.9249 - val_accuracy: 0.4233\n",
      "Epoch 477/1000\n",
      "700/700 [==============================] - 0s 56us/step - loss: 0.7804 - accuracy: 0.7014 - val_loss: 1.9159 - val_accuracy: 0.4233\n",
      "Epoch 478/1000\n",
      "700/700 [==============================] - 0s 54us/step - loss: 0.7772 - accuracy: 0.7057 - val_loss: 1.9248 - val_accuracy: 0.4233\n",
      "Epoch 479/1000\n",
      "700/700 [==============================] - 0s 52us/step - loss: 0.7790 - accuracy: 0.7000 - val_loss: 1.9046 - val_accuracy: 0.4233\n",
      "Epoch 480/1000\n",
      "700/700 [==============================] - 0s 53us/step - loss: 0.7769 - accuracy: 0.6986 - val_loss: 1.9160 - val_accuracy: 0.4200\n",
      "Epoch 481/1000\n",
      "700/700 [==============================] - 0s 53us/step - loss: 0.7783 - accuracy: 0.6957 - val_loss: 1.9000 - val_accuracy: 0.4200\n",
      "Epoch 482/1000\n",
      "700/700 [==============================] - 0s 57us/step - loss: 0.7769 - accuracy: 0.7000 - val_loss: 1.9261 - val_accuracy: 0.4333\n",
      "Epoch 483/1000\n",
      "700/700 [==============================] - 0s 54us/step - loss: 0.7771 - accuracy: 0.6971 - val_loss: 1.9141 - val_accuracy: 0.4233\n",
      "Epoch 484/1000\n",
      "700/700 [==============================] - 0s 54us/step - loss: 0.7771 - accuracy: 0.7014 - val_loss: 1.9151 - val_accuracy: 0.4233\n",
      "Epoch 485/1000\n",
      "700/700 [==============================] - 0s 57us/step - loss: 0.7757 - accuracy: 0.6971 - val_loss: 1.9705 - val_accuracy: 0.4233\n",
      "Epoch 486/1000\n",
      "700/700 [==============================] - 0s 54us/step - loss: 0.7772 - accuracy: 0.6957 - val_loss: 1.9355 - val_accuracy: 0.4233\n",
      "Epoch 487/1000\n",
      "700/700 [==============================] - 0s 53us/step - loss: 0.7751 - accuracy: 0.6986 - val_loss: 1.9269 - val_accuracy: 0.4233\n",
      "Epoch 488/1000\n",
      "700/700 [==============================] - 0s 54us/step - loss: 0.7741 - accuracy: 0.7000 - val_loss: 1.9402 - val_accuracy: 0.4400\n",
      "Epoch 489/1000\n",
      "700/700 [==============================] - 0s 56us/step - loss: 0.7748 - accuracy: 0.7029 - val_loss: 1.9243 - val_accuracy: 0.4267\n",
      "Epoch 490/1000\n",
      "700/700 [==============================] - 0s 57us/step - loss: 0.7745 - accuracy: 0.6971 - val_loss: 1.9453 - val_accuracy: 0.4233\n",
      "Epoch 491/1000\n",
      "700/700 [==============================] - 0s 60us/step - loss: 0.7738 - accuracy: 0.7043 - val_loss: 1.9337 - val_accuracy: 0.4233\n",
      "Epoch 492/1000\n",
      "700/700 [==============================] - 0s 54us/step - loss: 0.7725 - accuracy: 0.7057 - val_loss: 1.9417 - val_accuracy: 0.4167\n",
      "Epoch 493/1000\n",
      "700/700 [==============================] - 0s 54us/step - loss: 0.7720 - accuracy: 0.6971 - val_loss: 1.9423 - val_accuracy: 0.4267\n",
      "Epoch 494/1000\n",
      "700/700 [==============================] - 0s 57us/step - loss: 0.7728 - accuracy: 0.6971 - val_loss: 1.9316 - val_accuracy: 0.4233\n",
      "Epoch 495/1000\n",
      "700/700 [==============================] - 0s 58us/step - loss: 0.7713 - accuracy: 0.6986 - val_loss: 1.9410 - val_accuracy: 0.4233\n",
      "Epoch 496/1000\n",
      "700/700 [==============================] - 0s 60us/step - loss: 0.7719 - accuracy: 0.7014 - val_loss: 1.9544 - val_accuracy: 0.4267\n",
      "Epoch 497/1000\n",
      "700/700 [==============================] - 0s 57us/step - loss: 0.7718 - accuracy: 0.7029 - val_loss: 1.9447 - val_accuracy: 0.4233\n",
      "Epoch 498/1000\n",
      "700/700 [==============================] - 0s 53us/step - loss: 0.7707 - accuracy: 0.6986 - val_loss: 1.9477 - val_accuracy: 0.4233\n",
      "Epoch 499/1000\n",
      "700/700 [==============================] - 0s 58us/step - loss: 0.7701 - accuracy: 0.7057 - val_loss: 1.9723 - val_accuracy: 0.4233\n",
      "Epoch 500/1000\n",
      "700/700 [==============================] - 0s 57us/step - loss: 0.7704 - accuracy: 0.6971 - val_loss: 1.9578 - val_accuracy: 0.4233\n",
      "Epoch 501/1000\n",
      "700/700 [==============================] - 0s 53us/step - loss: 0.7682 - accuracy: 0.7000 - val_loss: 1.9498 - val_accuracy: 0.4200\n",
      "Epoch 502/1000\n",
      "700/700 [==============================] - 0s 53us/step - loss: 0.7680 - accuracy: 0.7000 - val_loss: 1.9669 - val_accuracy: 0.4200\n",
      "Epoch 503/1000\n",
      "700/700 [==============================] - 0s 58us/step - loss: 0.7686 - accuracy: 0.6986 - val_loss: 1.9471 - val_accuracy: 0.4267\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 504/1000\n",
      "700/700 [==============================] - 0s 61us/step - loss: 0.7674 - accuracy: 0.7057 - val_loss: 1.9717 - val_accuracy: 0.4300\n",
      "Epoch 505/1000\n",
      "700/700 [==============================] - 0s 58us/step - loss: 0.7675 - accuracy: 0.7029 - val_loss: 1.9525 - val_accuracy: 0.4200\n",
      "Epoch 506/1000\n",
      "700/700 [==============================] - 0s 56us/step - loss: 0.7670 - accuracy: 0.7086 - val_loss: 1.9473 - val_accuracy: 0.4200\n",
      "Epoch 507/1000\n",
      "700/700 [==============================] - 0s 54us/step - loss: 0.7682 - accuracy: 0.7000 - val_loss: 1.9632 - val_accuracy: 0.4300\n",
      "Epoch 508/1000\n",
      "700/700 [==============================] - 0s 57us/step - loss: 0.7653 - accuracy: 0.7057 - val_loss: 1.9568 - val_accuracy: 0.4300\n",
      "Epoch 509/1000\n",
      "700/700 [==============================] - 0s 58us/step - loss: 0.7662 - accuracy: 0.7043 - val_loss: 1.9554 - val_accuracy: 0.4200\n",
      "Epoch 510/1000\n",
      "700/700 [==============================] - 0s 58us/step - loss: 0.7654 - accuracy: 0.7057 - val_loss: 1.9678 - val_accuracy: 0.4167\n",
      "Epoch 511/1000\n",
      "700/700 [==============================] - 0s 56us/step - loss: 0.7652 - accuracy: 0.7000 - val_loss: 1.9738 - val_accuracy: 0.4267\n",
      "Epoch 512/1000\n",
      "700/700 [==============================] - 0s 53us/step - loss: 0.7634 - accuracy: 0.6986 - val_loss: 2.0099 - val_accuracy: 0.4200\n",
      "Epoch 513/1000\n",
      "700/700 [==============================] - 0s 53us/step - loss: 0.7643 - accuracy: 0.6971 - val_loss: 1.9649 - val_accuracy: 0.4333\n",
      "Epoch 514/1000\n",
      "700/700 [==============================] - 0s 54us/step - loss: 0.7626 - accuracy: 0.6986 - val_loss: 1.9730 - val_accuracy: 0.4367\n",
      "Epoch 515/1000\n",
      "700/700 [==============================] - 0s 54us/step - loss: 0.7629 - accuracy: 0.7029 - val_loss: 1.9588 - val_accuracy: 0.4267\n",
      "Epoch 516/1000\n",
      "700/700 [==============================] - 0s 56us/step - loss: 0.7647 - accuracy: 0.7029 - val_loss: 1.9730 - val_accuracy: 0.4300\n",
      "Epoch 517/1000\n",
      "700/700 [==============================] - 0s 53us/step - loss: 0.7616 - accuracy: 0.7014 - val_loss: 1.9567 - val_accuracy: 0.4233\n",
      "Epoch 518/1000\n",
      "700/700 [==============================] - 0s 53us/step - loss: 0.7613 - accuracy: 0.7071 - val_loss: 1.9757 - val_accuracy: 0.4200\n",
      "Epoch 519/1000\n",
      "700/700 [==============================] - 0s 56us/step - loss: 0.7622 - accuracy: 0.6986 - val_loss: 1.9853 - val_accuracy: 0.4300\n",
      "Epoch 520/1000\n",
      "700/700 [==============================] - 0s 54us/step - loss: 0.7614 - accuracy: 0.7071 - val_loss: 1.9773 - val_accuracy: 0.4233\n",
      "Epoch 521/1000\n",
      "700/700 [==============================] - 0s 59us/step - loss: 0.7610 - accuracy: 0.7043 - val_loss: 1.9744 - val_accuracy: 0.4200\n",
      "Epoch 522/1000\n",
      "700/700 [==============================] - 0s 57us/step - loss: 0.7602 - accuracy: 0.7071 - val_loss: 1.9690 - val_accuracy: 0.4267\n",
      "Epoch 523/1000\n",
      "700/700 [==============================] - 0s 56us/step - loss: 0.7618 - accuracy: 0.7014 - val_loss: 1.9936 - val_accuracy: 0.4200\n",
      "Epoch 524/1000\n",
      "700/700 [==============================] - 0s 56us/step - loss: 0.7595 - accuracy: 0.7029 - val_loss: 1.9969 - val_accuracy: 0.4200\n",
      "Epoch 525/1000\n",
      "700/700 [==============================] - 0s 58us/step - loss: 0.7591 - accuracy: 0.7086 - val_loss: 1.9988 - val_accuracy: 0.4167\n",
      "Epoch 526/1000\n",
      "700/700 [==============================] - 0s 56us/step - loss: 0.7586 - accuracy: 0.7071 - val_loss: 1.9775 - val_accuracy: 0.4333\n",
      "Epoch 527/1000\n",
      "700/700 [==============================] - 0s 57us/step - loss: 0.7596 - accuracy: 0.7057 - val_loss: 1.9817 - val_accuracy: 0.4233\n",
      "Epoch 528/1000\n",
      "700/700 [==============================] - 0s 58us/step - loss: 0.7564 - accuracy: 0.7000 - val_loss: 1.9895 - val_accuracy: 0.4300\n",
      "Epoch 529/1000\n",
      "700/700 [==============================] - 0s 56us/step - loss: 0.7573 - accuracy: 0.7071 - val_loss: 1.9776 - val_accuracy: 0.4333\n",
      "Epoch 530/1000\n",
      "700/700 [==============================] - 0s 58us/step - loss: 0.7573 - accuracy: 0.7100 - val_loss: 2.0038 - val_accuracy: 0.4133\n",
      "Epoch 531/1000\n",
      "700/700 [==============================] - 0s 57us/step - loss: 0.7571 - accuracy: 0.7071 - val_loss: 1.9906 - val_accuracy: 0.4233\n",
      "Epoch 532/1000\n",
      "700/700 [==============================] - 0s 57us/step - loss: 0.7556 - accuracy: 0.7000 - val_loss: 2.0238 - val_accuracy: 0.4200\n",
      "Epoch 533/1000\n",
      "700/700 [==============================] - 0s 57us/step - loss: 0.7573 - accuracy: 0.7057 - val_loss: 2.0040 - val_accuracy: 0.4200\n",
      "Epoch 534/1000\n",
      "700/700 [==============================] - 0s 56us/step - loss: 0.7567 - accuracy: 0.7071 - val_loss: 1.9867 - val_accuracy: 0.4267\n",
      "Epoch 535/1000\n",
      "700/700 [==============================] - 0s 60us/step - loss: 0.7550 - accuracy: 0.7071 - val_loss: 1.9979 - val_accuracy: 0.4267\n",
      "Epoch 536/1000\n",
      "700/700 [==============================] - 0s 57us/step - loss: 0.7561 - accuracy: 0.7100 - val_loss: 1.9945 - val_accuracy: 0.4200\n",
      "Epoch 537/1000\n",
      "700/700 [==============================] - 0s 57us/step - loss: 0.7551 - accuracy: 0.7043 - val_loss: 1.9864 - val_accuracy: 0.4300\n",
      "Epoch 538/1000\n",
      "700/700 [==============================] - 0s 57us/step - loss: 0.7540 - accuracy: 0.7057 - val_loss: 1.9849 - val_accuracy: 0.4267\n",
      "Epoch 539/1000\n",
      "700/700 [==============================] - 0s 58us/step - loss: 0.7540 - accuracy: 0.7114 - val_loss: 2.0000 - val_accuracy: 0.4267\n",
      "Epoch 540/1000\n",
      "700/700 [==============================] - 0s 56us/step - loss: 0.7526 - accuracy: 0.7071 - val_loss: 1.9742 - val_accuracy: 0.4267\n",
      "Epoch 541/1000\n",
      "700/700 [==============================] - 0s 60us/step - loss: 0.7541 - accuracy: 0.7086 - val_loss: 2.0148 - val_accuracy: 0.4233\n",
      "Epoch 542/1000\n",
      "700/700 [==============================] - 0s 56us/step - loss: 0.7519 - accuracy: 0.7114 - val_loss: 1.9942 - val_accuracy: 0.4233\n",
      "Epoch 543/1000\n",
      "700/700 [==============================] - 0s 58us/step - loss: 0.7527 - accuracy: 0.7100 - val_loss: 2.0174 - val_accuracy: 0.4200\n",
      "Epoch 544/1000\n",
      "700/700 [==============================] - 0s 56us/step - loss: 0.7526 - accuracy: 0.7071 - val_loss: 2.0058 - val_accuracy: 0.4300\n",
      "Epoch 545/1000\n",
      "700/700 [==============================] - 0s 54us/step - loss: 0.7520 - accuracy: 0.7100 - val_loss: 2.0051 - val_accuracy: 0.4267\n",
      "Epoch 546/1000\n",
      "700/700 [==============================] - 0s 54us/step - loss: 0.7517 - accuracy: 0.7086 - val_loss: 2.0283 - val_accuracy: 0.4200\n",
      "Epoch 547/1000\n",
      "700/700 [==============================] - 0s 54us/step - loss: 0.7511 - accuracy: 0.7071 - val_loss: 1.9881 - val_accuracy: 0.4267\n",
      "Epoch 548/1000\n",
      "700/700 [==============================] - 0s 53us/step - loss: 0.7509 - accuracy: 0.7114 - val_loss: 2.0249 - val_accuracy: 0.4267\n",
      "Epoch 549/1000\n",
      "700/700 [==============================] - 0s 57us/step - loss: 0.7514 - accuracy: 0.7071 - val_loss: 2.0167 - val_accuracy: 0.4200\n",
      "Epoch 550/1000\n",
      "700/700 [==============================] - 0s 57us/step - loss: 0.7492 - accuracy: 0.7157 - val_loss: 2.0296 - val_accuracy: 0.4233\n",
      "Epoch 551/1000\n",
      "700/700 [==============================] - 0s 57us/step - loss: 0.7486 - accuracy: 0.7143 - val_loss: 1.9971 - val_accuracy: 0.4233\n",
      "Epoch 552/1000\n",
      "700/700 [==============================] - 0s 59us/step - loss: 0.7493 - accuracy: 0.7129 - val_loss: 2.0349 - val_accuracy: 0.4200\n",
      "Epoch 553/1000\n",
      "700/700 [==============================] - 0s 56us/step - loss: 0.7487 - accuracy: 0.7143 - val_loss: 2.0274 - val_accuracy: 0.4133\n",
      "Epoch 554/1000\n",
      "700/700 [==============================] - 0s 56us/step - loss: 0.7476 - accuracy: 0.7114 - val_loss: 2.0251 - val_accuracy: 0.4200\n",
      "Epoch 555/1000\n",
      "700/700 [==============================] - 0s 56us/step - loss: 0.7474 - accuracy: 0.7114 - val_loss: 2.0393 - val_accuracy: 0.4100\n",
      "Epoch 556/1000\n",
      "700/700 [==============================] - 0s 56us/step - loss: 0.7478 - accuracy: 0.7057 - val_loss: 2.0389 - val_accuracy: 0.4167\n",
      "Epoch 557/1000\n",
      "700/700 [==============================] - 0s 53us/step - loss: 0.7464 - accuracy: 0.7100 - val_loss: 2.0031 - val_accuracy: 0.4233\n",
      "Epoch 558/1000\n",
      "700/700 [==============================] - 0s 51us/step - loss: 0.7468 - accuracy: 0.7157 - val_loss: 2.0244 - val_accuracy: 0.4300\n",
      "Epoch 559/1000\n",
      "700/700 [==============================] - 0s 56us/step - loss: 0.7459 - accuracy: 0.7186 - val_loss: 2.0285 - val_accuracy: 0.4300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 560/1000\n",
      "700/700 [==============================] - 0s 53us/step - loss: 0.7459 - accuracy: 0.7086 - val_loss: 2.0341 - val_accuracy: 0.4233\n",
      "Epoch 561/1000\n",
      "700/700 [==============================] - 0s 53us/step - loss: 0.7457 - accuracy: 0.7129 - val_loss: 2.0482 - val_accuracy: 0.4200\n",
      "Epoch 562/1000\n",
      "700/700 [==============================] - 0s 53us/step - loss: 0.7450 - accuracy: 0.7171 - val_loss: 2.0519 - val_accuracy: 0.4067\n",
      "Epoch 563/1000\n",
      "700/700 [==============================] - 0s 56us/step - loss: 0.7454 - accuracy: 0.7000 - val_loss: 2.0510 - val_accuracy: 0.4100\n",
      "Epoch 564/1000\n",
      "700/700 [==============================] - 0s 56us/step - loss: 0.7442 - accuracy: 0.7157 - val_loss: 2.0258 - val_accuracy: 0.4267\n",
      "Epoch 565/1000\n",
      "700/700 [==============================] - 0s 58us/step - loss: 0.7440 - accuracy: 0.7186 - val_loss: 2.0502 - val_accuracy: 0.4200\n",
      "Epoch 566/1000\n",
      "700/700 [==============================] - 0s 56us/step - loss: 0.7429 - accuracy: 0.7100 - val_loss: 2.0208 - val_accuracy: 0.4333\n",
      "Epoch 567/1000\n",
      "700/700 [==============================] - 0s 56us/step - loss: 0.7432 - accuracy: 0.7129 - val_loss: 2.0677 - val_accuracy: 0.4133\n",
      "Epoch 568/1000\n",
      "700/700 [==============================] - 0s 54us/step - loss: 0.7436 - accuracy: 0.7114 - val_loss: 2.0267 - val_accuracy: 0.4200\n",
      "Epoch 569/1000\n",
      "700/700 [==============================] - 0s 56us/step - loss: 0.7437 - accuracy: 0.7129 - val_loss: 2.0540 - val_accuracy: 0.4200\n",
      "Epoch 570/1000\n",
      "700/700 [==============================] - 0s 57us/step - loss: 0.7415 - accuracy: 0.7129 - val_loss: 2.0544 - val_accuracy: 0.4133\n",
      "Epoch 571/1000\n",
      "700/700 [==============================] - 0s 57us/step - loss: 0.7430 - accuracy: 0.7171 - val_loss: 2.0371 - val_accuracy: 0.4267\n",
      "Epoch 572/1000\n",
      "700/700 [==============================] - 0s 56us/step - loss: 0.7424 - accuracy: 0.7186 - val_loss: 2.0205 - val_accuracy: 0.4233\n",
      "Epoch 573/1000\n",
      "700/700 [==============================] - 0s 54us/step - loss: 0.7419 - accuracy: 0.7114 - val_loss: 2.0448 - val_accuracy: 0.4267\n",
      "Epoch 574/1000\n",
      "700/700 [==============================] - 0s 57us/step - loss: 0.7417 - accuracy: 0.7157 - val_loss: 2.0660 - val_accuracy: 0.4100\n",
      "Epoch 575/1000\n",
      "700/700 [==============================] - 0s 59us/step - loss: 0.7412 - accuracy: 0.7143 - val_loss: 2.0428 - val_accuracy: 0.4333\n",
      "Epoch 576/1000\n",
      "700/700 [==============================] - 0s 56us/step - loss: 0.7403 - accuracy: 0.7129 - val_loss: 2.0564 - val_accuracy: 0.4200\n",
      "Epoch 577/1000\n",
      "700/700 [==============================] - 0s 58us/step - loss: 0.7397 - accuracy: 0.7086 - val_loss: 2.0497 - val_accuracy: 0.4167\n",
      "Epoch 578/1000\n",
      "700/700 [==============================] - 0s 58us/step - loss: 0.7386 - accuracy: 0.7171 - val_loss: 2.0687 - val_accuracy: 0.4133\n",
      "Epoch 579/1000\n",
      "700/700 [==============================] - 0s 57us/step - loss: 0.7408 - accuracy: 0.7186 - val_loss: 2.0483 - val_accuracy: 0.4267\n",
      "Epoch 580/1000\n",
      "700/700 [==============================] - 0s 58us/step - loss: 0.7385 - accuracy: 0.7143 - val_loss: 2.0699 - val_accuracy: 0.4167\n",
      "Epoch 581/1000\n",
      "700/700 [==============================] - 0s 58us/step - loss: 0.7392 - accuracy: 0.7186 - val_loss: 2.0589 - val_accuracy: 0.4200\n",
      "Epoch 582/1000\n",
      "700/700 [==============================] - 0s 60us/step - loss: 0.7375 - accuracy: 0.7186 - val_loss: 2.0471 - val_accuracy: 0.4300\n",
      "Epoch 583/1000\n",
      "700/700 [==============================] - 0s 60us/step - loss: 0.7387 - accuracy: 0.7186 - val_loss: 2.0756 - val_accuracy: 0.4200\n",
      "Epoch 584/1000\n",
      "700/700 [==============================] - 0s 58us/step - loss: 0.7372 - accuracy: 0.7157 - val_loss: 2.0813 - val_accuracy: 0.4167\n",
      "Epoch 585/1000\n",
      "700/700 [==============================] - 0s 58us/step - loss: 0.7378 - accuracy: 0.7200 - val_loss: 2.0600 - val_accuracy: 0.4200\n",
      "Epoch 586/1000\n",
      "700/700 [==============================] - 0s 57us/step - loss: 0.7373 - accuracy: 0.7214 - val_loss: 2.0480 - val_accuracy: 0.4200\n",
      "Epoch 587/1000\n",
      "700/700 [==============================] - 0s 58us/step - loss: 0.7372 - accuracy: 0.7171 - val_loss: 2.0734 - val_accuracy: 0.4200\n",
      "Epoch 588/1000\n",
      "700/700 [==============================] - 0s 60us/step - loss: 0.7359 - accuracy: 0.7129 - val_loss: 2.0512 - val_accuracy: 0.4233\n",
      "Epoch 589/1000\n",
      "700/700 [==============================] - 0s 58us/step - loss: 0.7377 - accuracy: 0.7129 - val_loss: 2.0510 - val_accuracy: 0.4233\n",
      "Epoch 590/1000\n",
      "700/700 [==============================] - 0s 57us/step - loss: 0.7359 - accuracy: 0.7243 - val_loss: 2.0774 - val_accuracy: 0.4200\n",
      "Epoch 591/1000\n",
      "700/700 [==============================] - 0s 57us/step - loss: 0.7348 - accuracy: 0.7171 - val_loss: 2.0704 - val_accuracy: 0.4200\n",
      "Epoch 592/1000\n",
      "700/700 [==============================] - 0s 54us/step - loss: 0.7336 - accuracy: 0.7300 - val_loss: 2.0850 - val_accuracy: 0.4167\n",
      "Epoch 593/1000\n",
      "700/700 [==============================] - 0s 58us/step - loss: 0.7332 - accuracy: 0.7114 - val_loss: 2.0622 - val_accuracy: 0.4267\n",
      "Epoch 594/1000\n",
      "700/700 [==============================] - 0s 57us/step - loss: 0.7351 - accuracy: 0.7157 - val_loss: 2.0932 - val_accuracy: 0.4133\n",
      "Epoch 595/1000\n",
      "700/700 [==============================] - 0s 58us/step - loss: 0.7341 - accuracy: 0.7200 - val_loss: 2.0680 - val_accuracy: 0.4300\n",
      "Epoch 596/1000\n",
      "700/700 [==============================] - 0s 60us/step - loss: 0.7333 - accuracy: 0.7214 - val_loss: 2.0914 - val_accuracy: 0.4200\n",
      "Epoch 597/1000\n",
      "700/700 [==============================] - 0s 54us/step - loss: 0.7329 - accuracy: 0.7229 - val_loss: 2.1071 - val_accuracy: 0.4167\n",
      "Epoch 598/1000\n",
      "700/700 [==============================] - 0s 57us/step - loss: 0.7319 - accuracy: 0.7243 - val_loss: 2.0945 - val_accuracy: 0.4200\n",
      "Epoch 599/1000\n",
      "700/700 [==============================] - 0s 58us/step - loss: 0.7315 - accuracy: 0.7171 - val_loss: 2.0581 - val_accuracy: 0.4200\n",
      "Epoch 600/1000\n",
      "700/700 [==============================] - 0s 54us/step - loss: 0.7318 - accuracy: 0.7200 - val_loss: 2.0772 - val_accuracy: 0.4200\n",
      "Epoch 601/1000\n",
      "700/700 [==============================] - 0s 60us/step - loss: 0.7332 - accuracy: 0.7143 - val_loss: 2.0854 - val_accuracy: 0.4133\n",
      "Epoch 602/1000\n",
      "700/700 [==============================] - 0s 57us/step - loss: 0.7307 - accuracy: 0.7271 - val_loss: 2.0829 - val_accuracy: 0.4233\n",
      "Epoch 603/1000\n",
      "700/700 [==============================] - 0s 57us/step - loss: 0.7311 - accuracy: 0.7214 - val_loss: 2.0787 - val_accuracy: 0.4233\n",
      "Epoch 604/1000\n",
      "700/700 [==============================] - 0s 57us/step - loss: 0.7320 - accuracy: 0.7214 - val_loss: 2.0943 - val_accuracy: 0.4233\n",
      "Epoch 605/1000\n",
      "700/700 [==============================] - 0s 57us/step - loss: 0.7326 - accuracy: 0.7186 - val_loss: 2.0880 - val_accuracy: 0.4233\n",
      "Epoch 606/1000\n",
      "700/700 [==============================] - 0s 57us/step - loss: 0.7310 - accuracy: 0.7200 - val_loss: 2.0840 - val_accuracy: 0.4167\n",
      "Epoch 607/1000\n",
      "700/700 [==============================] - 0s 60us/step - loss: 0.7297 - accuracy: 0.7200 - val_loss: 2.0715 - val_accuracy: 0.4233\n",
      "Epoch 608/1000\n",
      "700/700 [==============================] - 0s 57us/step - loss: 0.7289 - accuracy: 0.7129 - val_loss: 2.1205 - val_accuracy: 0.4233\n",
      "Epoch 609/1000\n",
      "700/700 [==============================] - 0s 54us/step - loss: 0.7293 - accuracy: 0.7171 - val_loss: 2.1029 - val_accuracy: 0.4167\n",
      "Epoch 610/1000\n",
      "700/700 [==============================] - 0s 56us/step - loss: 0.7288 - accuracy: 0.7243 - val_loss: 2.0717 - val_accuracy: 0.4233\n",
      "Epoch 611/1000\n",
      "700/700 [==============================] - 0s 56us/step - loss: 0.7279 - accuracy: 0.7229 - val_loss: 2.1137 - val_accuracy: 0.4133\n",
      "Epoch 612/1000\n",
      "700/700 [==============================] - 0s 54us/step - loss: 0.7286 - accuracy: 0.7243 - val_loss: 2.1000 - val_accuracy: 0.4233\n",
      "Epoch 613/1000\n",
      "700/700 [==============================] - 0s 56us/step - loss: 0.7280 - accuracy: 0.7200 - val_loss: 2.0729 - val_accuracy: 0.4300\n",
      "Epoch 614/1000\n",
      "700/700 [==============================] - 0s 57us/step - loss: 0.7285 - accuracy: 0.7243 - val_loss: 2.1015 - val_accuracy: 0.4133\n",
      "Epoch 615/1000\n",
      "700/700 [==============================] - 0s 60us/step - loss: 0.7270 - accuracy: 0.7257 - val_loss: 2.1021 - val_accuracy: 0.4200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 616/1000\n",
      "700/700 [==============================] - 0s 58us/step - loss: 0.7270 - accuracy: 0.7243 - val_loss: 2.0936 - val_accuracy: 0.4233\n",
      "Epoch 617/1000\n",
      "700/700 [==============================] - 0s 57us/step - loss: 0.7256 - accuracy: 0.7214 - val_loss: 2.0668 - val_accuracy: 0.4200\n",
      "Epoch 618/1000\n",
      "700/700 [==============================] - 0s 56us/step - loss: 0.7273 - accuracy: 0.7229 - val_loss: 2.0986 - val_accuracy: 0.4267\n",
      "Epoch 619/1000\n",
      "700/700 [==============================] - 0s 56us/step - loss: 0.7259 - accuracy: 0.7243 - val_loss: 2.1212 - val_accuracy: 0.4133\n",
      "Epoch 620/1000\n",
      "700/700 [==============================] - 0s 60us/step - loss: 0.7254 - accuracy: 0.7157 - val_loss: 2.1131 - val_accuracy: 0.4233\n",
      "Epoch 621/1000\n",
      "700/700 [==============================] - 0s 58us/step - loss: 0.7268 - accuracy: 0.7229 - val_loss: 2.1053 - val_accuracy: 0.4267\n",
      "Epoch 622/1000\n",
      "700/700 [==============================] - 0s 57us/step - loss: 0.7246 - accuracy: 0.7214 - val_loss: 2.1236 - val_accuracy: 0.4133\n",
      "Epoch 623/1000\n",
      "700/700 [==============================] - 0s 54us/step - loss: 0.7241 - accuracy: 0.7186 - val_loss: 2.0860 - val_accuracy: 0.4233\n",
      "Epoch 624/1000\n",
      "700/700 [==============================] - 0s 54us/step - loss: 0.7244 - accuracy: 0.7257 - val_loss: 2.1114 - val_accuracy: 0.4233\n",
      "Epoch 625/1000\n",
      "700/700 [==============================] - 0s 54us/step - loss: 0.7250 - accuracy: 0.7229 - val_loss: 2.1239 - val_accuracy: 0.4167\n",
      "Epoch 626/1000\n",
      "700/700 [==============================] - 0s 53us/step - loss: 0.7237 - accuracy: 0.7171 - val_loss: 2.1385 - val_accuracy: 0.4167\n",
      "Epoch 627/1000\n",
      "700/700 [==============================] - 0s 54us/step - loss: 0.7253 - accuracy: 0.7200 - val_loss: 2.1060 - val_accuracy: 0.4167\n",
      "Epoch 628/1000\n",
      "700/700 [==============================] - 0s 56us/step - loss: 0.7232 - accuracy: 0.7257 - val_loss: 2.1252 - val_accuracy: 0.4133\n",
      "Epoch 629/1000\n",
      "700/700 [==============================] - 0s 58us/step - loss: 0.7227 - accuracy: 0.7300 - val_loss: 2.1102 - val_accuracy: 0.4233\n",
      "Epoch 630/1000\n",
      "700/700 [==============================] - 0s 57us/step - loss: 0.7231 - accuracy: 0.7243 - val_loss: 2.1554 - val_accuracy: 0.4100\n",
      "Epoch 631/1000\n",
      "700/700 [==============================] - 0s 58us/step - loss: 0.7229 - accuracy: 0.7200 - val_loss: 2.1440 - val_accuracy: 0.4100\n",
      "Epoch 632/1000\n",
      "700/700 [==============================] - 0s 58us/step - loss: 0.7225 - accuracy: 0.7186 - val_loss: 2.1162 - val_accuracy: 0.4167\n",
      "Epoch 633/1000\n",
      "700/700 [==============================] - 0s 57us/step - loss: 0.7217 - accuracy: 0.7229 - val_loss: 2.1741 - val_accuracy: 0.4133\n",
      "Epoch 634/1000\n",
      "700/700 [==============================] - 0s 56us/step - loss: 0.7220 - accuracy: 0.7229 - val_loss: 2.1205 - val_accuracy: 0.4200\n",
      "Epoch 635/1000\n",
      "700/700 [==============================] - 0s 53us/step - loss: 0.7217 - accuracy: 0.7257 - val_loss: 2.1195 - val_accuracy: 0.4233\n",
      "Epoch 636/1000\n",
      "700/700 [==============================] - 0s 53us/step - loss: 0.7211 - accuracy: 0.7257 - val_loss: 2.1350 - val_accuracy: 0.4200\n",
      "Epoch 637/1000\n",
      "700/700 [==============================] - 0s 54us/step - loss: 0.7209 - accuracy: 0.7214 - val_loss: 2.1127 - val_accuracy: 0.4233\n",
      "Epoch 638/1000\n",
      "700/700 [==============================] - 0s 51us/step - loss: 0.7187 - accuracy: 0.7229 - val_loss: 2.2151 - val_accuracy: 0.4067\n",
      "Epoch 639/1000\n",
      "700/700 [==============================] - 0s 51us/step - loss: 0.7208 - accuracy: 0.7243 - val_loss: 2.1400 - val_accuracy: 0.4167\n",
      "Epoch 640/1000\n",
      "700/700 [==============================] - 0s 53us/step - loss: 0.7193 - accuracy: 0.7229 - val_loss: 2.1513 - val_accuracy: 0.4067\n",
      "Epoch 641/1000\n",
      "700/700 [==============================] - 0s 56us/step - loss: 0.7189 - accuracy: 0.7271 - val_loss: 2.1274 - val_accuracy: 0.4133\n",
      "Epoch 642/1000\n",
      "700/700 [==============================] - 0s 56us/step - loss: 0.7184 - accuracy: 0.7286 - val_loss: 2.1288 - val_accuracy: 0.4233\n",
      "Epoch 643/1000\n",
      "700/700 [==============================] - 0s 56us/step - loss: 0.7182 - accuracy: 0.7271 - val_loss: 2.1606 - val_accuracy: 0.4133\n",
      "Epoch 644/1000\n",
      "700/700 [==============================] - 0s 58us/step - loss: 0.7185 - accuracy: 0.7314 - val_loss: 2.1806 - val_accuracy: 0.4133\n",
      "Epoch 645/1000\n",
      "700/700 [==============================] - 0s 54us/step - loss: 0.7188 - accuracy: 0.7286 - val_loss: 2.1339 - val_accuracy: 0.4200\n",
      "Epoch 646/1000\n",
      "700/700 [==============================] - 0s 57us/step - loss: 0.7163 - accuracy: 0.7229 - val_loss: 2.1278 - val_accuracy: 0.4267\n",
      "Epoch 647/1000\n",
      "700/700 [==============================] - 0s 58us/step - loss: 0.7184 - accuracy: 0.7243 - val_loss: 2.1424 - val_accuracy: 0.4200\n",
      "Epoch 648/1000\n",
      "700/700 [==============================] - 0s 56us/step - loss: 0.7171 - accuracy: 0.7257 - val_loss: 2.1126 - val_accuracy: 0.4300\n",
      "Epoch 649/1000\n",
      "700/700 [==============================] - 0s 57us/step - loss: 0.7177 - accuracy: 0.7243 - val_loss: 2.1456 - val_accuracy: 0.4200\n",
      "Epoch 650/1000\n",
      "700/700 [==============================] - 0s 60us/step - loss: 0.7155 - accuracy: 0.7243 - val_loss: 2.1431 - val_accuracy: 0.4233\n",
      "Epoch 651/1000\n",
      "700/700 [==============================] - 0s 56us/step - loss: 0.7156 - accuracy: 0.7286 - val_loss: 2.1446 - val_accuracy: 0.4200\n",
      "Epoch 652/1000\n",
      "700/700 [==============================] - 0s 54us/step - loss: 0.7163 - accuracy: 0.7271 - val_loss: 2.1521 - val_accuracy: 0.4267\n",
      "Epoch 653/1000\n",
      "700/700 [==============================] - 0s 54us/step - loss: 0.7148 - accuracy: 0.7257 - val_loss: 2.1520 - val_accuracy: 0.4200\n",
      "Epoch 654/1000\n",
      "700/700 [==============================] - 0s 56us/step - loss: 0.7151 - accuracy: 0.7271 - val_loss: 2.1643 - val_accuracy: 0.4200\n",
      "Epoch 655/1000\n",
      "700/700 [==============================] - 0s 60us/step - loss: 0.7157 - accuracy: 0.7343 - val_loss: 2.1627 - val_accuracy: 0.4133\n",
      "Epoch 656/1000\n",
      "700/700 [==============================] - 0s 56us/step - loss: 0.7147 - accuracy: 0.7257 - val_loss: 2.1689 - val_accuracy: 0.4067\n",
      "Epoch 657/1000\n",
      "700/700 [==============================] - ETA: 0s - loss: 0.5479 - accuracy: 0.90 - 0s 54us/step - loss: 0.7153 - accuracy: 0.7286 - val_loss: 2.1599 - val_accuracy: 0.4200\n",
      "Epoch 658/1000\n",
      "700/700 [==============================] - 0s 53us/step - loss: 0.7156 - accuracy: 0.7229 - val_loss: 2.1550 - val_accuracy: 0.4267\n",
      "Epoch 659/1000\n",
      "700/700 [==============================] - 0s 53us/step - loss: 0.7141 - accuracy: 0.7243 - val_loss: 2.1484 - val_accuracy: 0.4133\n",
      "Epoch 660/1000\n",
      "700/700 [==============================] - ETA: 0s - loss: 0.5616 - accuracy: 0.80 - 0s 54us/step - loss: 0.7129 - accuracy: 0.7314 - val_loss: 2.1882 - val_accuracy: 0.4167\n",
      "Epoch 661/1000\n",
      "700/700 [==============================] - 0s 58us/step - loss: 0.7130 - accuracy: 0.7286 - val_loss: 2.1634 - val_accuracy: 0.4067\n",
      "Epoch 662/1000\n",
      "700/700 [==============================] - 0s 57us/step - loss: 0.7127 - accuracy: 0.7286 - val_loss: 2.1860 - val_accuracy: 0.4100\n",
      "Epoch 663/1000\n",
      "700/700 [==============================] - 0s 58us/step - loss: 0.7128 - accuracy: 0.7271 - val_loss: 2.1481 - val_accuracy: 0.4267\n",
      "Epoch 664/1000\n",
      "700/700 [==============================] - 0s 57us/step - loss: 0.7126 - accuracy: 0.7314 - val_loss: 2.1769 - val_accuracy: 0.4133\n",
      "Epoch 665/1000\n",
      "700/700 [==============================] - 0s 58us/step - loss: 0.7120 - accuracy: 0.7229 - val_loss: 2.1598 - val_accuracy: 0.4233\n",
      "Epoch 666/1000\n",
      "700/700 [==============================] - 0s 57us/step - loss: 0.7113 - accuracy: 0.7243 - val_loss: 2.1731 - val_accuracy: 0.4067\n",
      "Epoch 667/1000\n",
      "700/700 [==============================] - 0s 58us/step - loss: 0.7107 - accuracy: 0.7271 - val_loss: 2.1924 - val_accuracy: 0.4067\n",
      "Epoch 668/1000\n",
      "700/700 [==============================] - 0s 58us/step - loss: 0.7120 - accuracy: 0.7300 - val_loss: 2.1773 - val_accuracy: 0.4233\n",
      "Epoch 669/1000\n",
      "700/700 [==============================] - 0s 59us/step - loss: 0.7113 - accuracy: 0.7257 - val_loss: 2.1936 - val_accuracy: 0.4167\n",
      "Epoch 670/1000\n",
      "700/700 [==============================] - 0s 56us/step - loss: 0.7106 - accuracy: 0.7257 - val_loss: 2.1770 - val_accuracy: 0.4100\n",
      "Epoch 671/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "700/700 [==============================] - 0s 56us/step - loss: 0.7103 - accuracy: 0.7271 - val_loss: 2.2006 - val_accuracy: 0.4167\n",
      "Epoch 672/1000\n",
      "700/700 [==============================] - 0s 57us/step - loss: 0.7103 - accuracy: 0.7300 - val_loss: 2.1587 - val_accuracy: 0.4233\n",
      "Epoch 673/1000\n",
      "700/700 [==============================] - 0s 54us/step - loss: 0.7105 - accuracy: 0.7257 - val_loss: 2.1732 - val_accuracy: 0.4233\n",
      "Epoch 674/1000\n",
      "700/700 [==============================] - 0s 54us/step - loss: 0.7101 - accuracy: 0.7343 - val_loss: 2.1567 - val_accuracy: 0.4300\n",
      "Epoch 675/1000\n",
      "700/700 [==============================] - 0s 56us/step - loss: 0.7089 - accuracy: 0.7286 - val_loss: 2.1615 - val_accuracy: 0.4133\n",
      "Epoch 676/1000\n",
      "700/700 [==============================] - 0s 57us/step - loss: 0.7087 - accuracy: 0.7314 - val_loss: 2.2026 - val_accuracy: 0.4133\n",
      "Epoch 677/1000\n",
      "700/700 [==============================] - 0s 58us/step - loss: 0.7084 - accuracy: 0.7271 - val_loss: 2.1847 - val_accuracy: 0.4233\n",
      "Epoch 678/1000\n",
      "700/700 [==============================] - 0s 57us/step - loss: 0.7084 - accuracy: 0.7271 - val_loss: 2.1669 - val_accuracy: 0.4167\n",
      "Epoch 679/1000\n",
      "700/700 [==============================] - 0s 54us/step - loss: 0.7089 - accuracy: 0.7314 - val_loss: 2.1988 - val_accuracy: 0.4167\n",
      "Epoch 680/1000\n",
      "700/700 [==============================] - 0s 56us/step - loss: 0.7075 - accuracy: 0.7314 - val_loss: 2.1983 - val_accuracy: 0.4200\n",
      "Epoch 681/1000\n",
      "700/700 [==============================] - ETA: 0s - loss: 0.5067 - accuracy: 0.80 - 0s 54us/step - loss: 0.7066 - accuracy: 0.7343 - val_loss: 2.1701 - val_accuracy: 0.4333\n",
      "Epoch 682/1000\n",
      "700/700 [==============================] - 0s 51us/step - loss: 0.7072 - accuracy: 0.7329 - val_loss: 2.1704 - val_accuracy: 0.4267\n",
      "Epoch 683/1000\n",
      "700/700 [==============================] - 0s 54us/step - loss: 0.7069 - accuracy: 0.7286 - val_loss: 2.1777 - val_accuracy: 0.4267\n",
      "Epoch 684/1000\n",
      "700/700 [==============================] - 0s 57us/step - loss: 0.7076 - accuracy: 0.7271 - val_loss: 2.2061 - val_accuracy: 0.4067\n",
      "Epoch 685/1000\n",
      "700/700 [==============================] - 0s 56us/step - loss: 0.7071 - accuracy: 0.7343 - val_loss: 2.1935 - val_accuracy: 0.4167\n",
      "Epoch 686/1000\n",
      "700/700 [==============================] - 0s 58us/step - loss: 0.7060 - accuracy: 0.7300 - val_loss: 2.2026 - val_accuracy: 0.4067\n",
      "Epoch 687/1000\n",
      "700/700 [==============================] - 0s 59us/step - loss: 0.7059 - accuracy: 0.7314 - val_loss: 2.2117 - val_accuracy: 0.4033\n",
      "Epoch 688/1000\n",
      "700/700 [==============================] - 0s 56us/step - loss: 0.7057 - accuracy: 0.7286 - val_loss: 2.1718 - val_accuracy: 0.4333\n",
      "Epoch 689/1000\n",
      "700/700 [==============================] - 0s 58us/step - loss: 0.7058 - accuracy: 0.7314 - val_loss: 2.2395 - val_accuracy: 0.4133\n",
      "Epoch 690/1000\n",
      "700/700 [==============================] - 0s 56us/step - loss: 0.7043 - accuracy: 0.7329 - val_loss: 2.1506 - val_accuracy: 0.4367\n",
      "Epoch 691/1000\n",
      "700/700 [==============================] - 0s 53us/step - loss: 0.7063 - accuracy: 0.7343 - val_loss: 2.2057 - val_accuracy: 0.4100\n",
      "Epoch 692/1000\n",
      "700/700 [==============================] - 0s 50us/step - loss: 0.7046 - accuracy: 0.7243 - val_loss: 2.2043 - val_accuracy: 0.4200\n",
      "Epoch 693/1000\n",
      "700/700 [==============================] - 0s 51us/step - loss: 0.7028 - accuracy: 0.7329 - val_loss: 2.1816 - val_accuracy: 0.4200\n",
      "Epoch 694/1000\n",
      "700/700 [==============================] - 0s 53us/step - loss: 0.7027 - accuracy: 0.7329 - val_loss: 2.2302 - val_accuracy: 0.4167\n",
      "Epoch 695/1000\n",
      "700/700 [==============================] - 0s 53us/step - loss: 0.7038 - accuracy: 0.7343 - val_loss: 2.2339 - val_accuracy: 0.4133\n",
      "Epoch 696/1000\n",
      "700/700 [==============================] - 0s 57us/step - loss: 0.7053 - accuracy: 0.7300 - val_loss: 2.1923 - val_accuracy: 0.4233\n",
      "Epoch 697/1000\n",
      "700/700 [==============================] - 0s 56us/step - loss: 0.7013 - accuracy: 0.7357 - val_loss: 2.2119 - val_accuracy: 0.4200\n",
      "Epoch 698/1000\n",
      "700/700 [==============================] - 0s 53us/step - loss: 0.7022 - accuracy: 0.7300 - val_loss: 2.2330 - val_accuracy: 0.4200\n",
      "Epoch 699/1000\n",
      "700/700 [==============================] - 0s 56us/step - loss: 0.7028 - accuracy: 0.7414 - val_loss: 2.2048 - val_accuracy: 0.4267\n",
      "Epoch 700/1000\n",
      "700/700 [==============================] - 0s 57us/step - loss: 0.7041 - accuracy: 0.7329 - val_loss: 2.2226 - val_accuracy: 0.4200\n",
      "Epoch 701/1000\n",
      "700/700 [==============================] - 0s 57us/step - loss: 0.7023 - accuracy: 0.7286 - val_loss: 2.2253 - val_accuracy: 0.4067\n",
      "Epoch 702/1000\n",
      "700/700 [==============================] - 0s 58us/step - loss: 0.7023 - accuracy: 0.7314 - val_loss: 2.2119 - val_accuracy: 0.4200\n",
      "Epoch 703/1000\n",
      "700/700 [==============================] - 0s 57us/step - loss: 0.7025 - accuracy: 0.7329 - val_loss: 2.2062 - val_accuracy: 0.4267\n",
      "Epoch 704/1000\n",
      "700/700 [==============================] - 0s 57us/step - loss: 0.7014 - accuracy: 0.7343 - val_loss: 2.2340 - val_accuracy: 0.4067\n",
      "Epoch 705/1000\n",
      "700/700 [==============================] - 0s 57us/step - loss: 0.7012 - accuracy: 0.7371 - val_loss: 2.2119 - val_accuracy: 0.4233\n",
      "Epoch 706/1000\n",
      "700/700 [==============================] - 0s 56us/step - loss: 0.6997 - accuracy: 0.7371 - val_loss: 2.2523 - val_accuracy: 0.4167\n",
      "Epoch 707/1000\n",
      "700/700 [==============================] - 0s 60us/step - loss: 0.7003 - accuracy: 0.7314 - val_loss: 2.2187 - val_accuracy: 0.4167\n",
      "Epoch 708/1000\n",
      "700/700 [==============================] - 0s 54us/step - loss: 0.7003 - accuracy: 0.7371 - val_loss: 2.2173 - val_accuracy: 0.4233\n",
      "Epoch 709/1000\n",
      "700/700 [==============================] - 0s 57us/step - loss: 0.7002 - accuracy: 0.7343 - val_loss: 2.2265 - val_accuracy: 0.4167\n",
      "Epoch 710/1000\n",
      "700/700 [==============================] - 0s 58us/step - loss: 0.6991 - accuracy: 0.7343 - val_loss: 2.2444 - val_accuracy: 0.4167\n",
      "Epoch 711/1000\n",
      "700/700 [==============================] - 0s 56us/step - loss: 0.6998 - accuracy: 0.7286 - val_loss: 2.2572 - val_accuracy: 0.4067\n",
      "Epoch 712/1000\n",
      "700/700 [==============================] - 0s 53us/step - loss: 0.6995 - accuracy: 0.7343 - val_loss: 2.2138 - val_accuracy: 0.4233\n",
      "Epoch 713/1000\n",
      "700/700 [==============================] - 0s 57us/step - loss: 0.6991 - accuracy: 0.7414 - val_loss: 2.2391 - val_accuracy: 0.4133\n",
      "Epoch 714/1000\n",
      "700/700 [==============================] - 0s 54us/step - loss: 0.6973 - accuracy: 0.7371 - val_loss: 2.2451 - val_accuracy: 0.4167\n",
      "Epoch 715/1000\n",
      "700/700 [==============================] - 0s 54us/step - loss: 0.6976 - accuracy: 0.7357 - val_loss: 2.2246 - val_accuracy: 0.4267\n",
      "Epoch 716/1000\n",
      "700/700 [==============================] - 0s 56us/step - loss: 0.6980 - accuracy: 0.7371 - val_loss: 2.2508 - val_accuracy: 0.4167\n",
      "Epoch 717/1000\n",
      "700/700 [==============================] - 0s 56us/step - loss: 0.6989 - accuracy: 0.7314 - val_loss: 2.2303 - val_accuracy: 0.4133\n",
      "Epoch 718/1000\n",
      "700/700 [==============================] - 0s 53us/step - loss: 0.6982 - accuracy: 0.7386 - val_loss: 2.2481 - val_accuracy: 0.4133\n",
      "Epoch 719/1000\n",
      "700/700 [==============================] - 0s 54us/step - loss: 0.6969 - accuracy: 0.7343 - val_loss: 2.2441 - val_accuracy: 0.4167\n",
      "Epoch 720/1000\n",
      "700/700 [==============================] - 0s 53us/step - loss: 0.6963 - accuracy: 0.7357 - val_loss: 2.2337 - val_accuracy: 0.4200\n",
      "Epoch 721/1000\n",
      "700/700 [==============================] - 0s 56us/step - loss: 0.6965 - accuracy: 0.7300 - val_loss: 2.2232 - val_accuracy: 0.4267\n",
      "Epoch 722/1000\n",
      "700/700 [==============================] - 0s 54us/step - loss: 0.6959 - accuracy: 0.7414 - val_loss: 2.2184 - val_accuracy: 0.4200\n",
      "Epoch 723/1000\n",
      "700/700 [==============================] - 0s 53us/step - loss: 0.6964 - accuracy: 0.7357 - val_loss: 2.2532 - val_accuracy: 0.4100\n",
      "Epoch 724/1000\n",
      "700/700 [==============================] - 0s 57us/step - loss: 0.6962 - accuracy: 0.7371 - val_loss: 2.2270 - val_accuracy: 0.4233\n",
      "Epoch 725/1000\n",
      "700/700 [==============================] - 0s 57us/step - loss: 0.6944 - accuracy: 0.7386 - val_loss: 2.2340 - val_accuracy: 0.4267\n",
      "Epoch 726/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "700/700 [==============================] - 0s 58us/step - loss: 0.6950 - accuracy: 0.7414 - val_loss: 2.2486 - val_accuracy: 0.4167\n",
      "Epoch 727/1000\n",
      "700/700 [==============================] - 0s 59us/step - loss: 0.6955 - accuracy: 0.7371 - val_loss: 2.2600 - val_accuracy: 0.4100\n",
      "Epoch 728/1000\n",
      "700/700 [==============================] - 0s 57us/step - loss: 0.6944 - accuracy: 0.7343 - val_loss: 2.2392 - val_accuracy: 0.4200\n",
      "Epoch 729/1000\n",
      "700/700 [==============================] - 0s 54us/step - loss: 0.6934 - accuracy: 0.7386 - val_loss: 2.2599 - val_accuracy: 0.4200\n",
      "Epoch 730/1000\n",
      "700/700 [==============================] - 0s 54us/step - loss: 0.6944 - accuracy: 0.7371 - val_loss: 2.2464 - val_accuracy: 0.4200\n",
      "Epoch 731/1000\n",
      "700/700 [==============================] - 0s 56us/step - loss: 0.6947 - accuracy: 0.7371 - val_loss: 2.2490 - val_accuracy: 0.4167\n",
      "Epoch 732/1000\n",
      "700/700 [==============================] - 0s 56us/step - loss: 0.6949 - accuracy: 0.7371 - val_loss: 2.2616 - val_accuracy: 0.4133\n",
      "Epoch 733/1000\n",
      "700/700 [==============================] - 0s 54us/step - loss: 0.6921 - accuracy: 0.7386 - val_loss: 2.2218 - val_accuracy: 0.4267\n",
      "Epoch 734/1000\n",
      "700/700 [==============================] - 0s 57us/step - loss: 0.6924 - accuracy: 0.7400 - val_loss: 2.2326 - val_accuracy: 0.4267\n",
      "Epoch 735/1000\n",
      "700/700 [==============================] - ETA: 0s - loss: 0.5802 - accuracy: 0.80 - 0s 54us/step - loss: 0.6924 - accuracy: 0.7314 - val_loss: 2.2731 - val_accuracy: 0.4100\n",
      "Epoch 736/1000\n",
      "700/700 [==============================] - 0s 53us/step - loss: 0.6931 - accuracy: 0.7343 - val_loss: 2.2522 - val_accuracy: 0.4233\n",
      "Epoch 737/1000\n",
      "700/700 [==============================] - 0s 57us/step - loss: 0.6920 - accuracy: 0.7414 - val_loss: 2.2779 - val_accuracy: 0.4133\n",
      "Epoch 738/1000\n",
      "700/700 [==============================] - 0s 54us/step - loss: 0.6912 - accuracy: 0.7329 - val_loss: 2.2429 - val_accuracy: 0.4200\n",
      "Epoch 739/1000\n",
      "700/700 [==============================] - 0s 54us/step - loss: 0.6923 - accuracy: 0.7429 - val_loss: 2.2930 - val_accuracy: 0.4100\n",
      "Epoch 740/1000\n",
      "700/700 [==============================] - 0s 56us/step - loss: 0.6907 - accuracy: 0.7400 - val_loss: 2.2948 - val_accuracy: 0.4133\n",
      "Epoch 741/1000\n",
      "700/700 [==============================] - 0s 58us/step - loss: 0.6920 - accuracy: 0.7429 - val_loss: 2.2751 - val_accuracy: 0.4133\n",
      "Epoch 742/1000\n",
      "700/700 [==============================] - 0s 57us/step - loss: 0.6920 - accuracy: 0.7386 - val_loss: 2.2895 - val_accuracy: 0.4100\n",
      "Epoch 743/1000\n",
      "700/700 [==============================] - 0s 56us/step - loss: 0.6905 - accuracy: 0.7386 - val_loss: 2.2430 - val_accuracy: 0.4233\n",
      "Epoch 744/1000\n",
      "700/700 [==============================] - 0s 51us/step - loss: 0.6904 - accuracy: 0.7400 - val_loss: 2.2506 - val_accuracy: 0.4233\n",
      "Epoch 745/1000\n",
      "700/700 [==============================] - 0s 53us/step - loss: 0.6904 - accuracy: 0.7371 - val_loss: 2.2677 - val_accuracy: 0.4233\n",
      "Epoch 746/1000\n",
      "700/700 [==============================] - 0s 56us/step - loss: 0.6892 - accuracy: 0.7414 - val_loss: 2.2621 - val_accuracy: 0.4233\n",
      "Epoch 747/1000\n",
      "700/700 [==============================] - 0s 56us/step - loss: 0.6895 - accuracy: 0.7414 - val_loss: 2.2614 - val_accuracy: 0.4267\n",
      "Epoch 748/1000\n",
      "700/700 [==============================] - 0s 57us/step - loss: 0.6897 - accuracy: 0.7371 - val_loss: 2.2776 - val_accuracy: 0.4133\n",
      "Epoch 749/1000\n",
      "700/700 [==============================] - 0s 57us/step - loss: 0.6879 - accuracy: 0.7386 - val_loss: 2.2999 - val_accuracy: 0.4100\n",
      "Epoch 750/1000\n",
      "700/700 [==============================] - 0s 58us/step - loss: 0.6886 - accuracy: 0.7386 - val_loss: 2.2511 - val_accuracy: 0.4333\n",
      "Epoch 751/1000\n",
      "700/700 [==============================] - 0s 58us/step - loss: 0.6883 - accuracy: 0.7414 - val_loss: 2.3042 - val_accuracy: 0.4067\n",
      "Epoch 752/1000\n",
      "700/700 [==============================] - 0s 60us/step - loss: 0.6893 - accuracy: 0.7371 - val_loss: 2.2692 - val_accuracy: 0.4200\n",
      "Epoch 753/1000\n",
      "700/700 [==============================] - 0s 58us/step - loss: 0.6889 - accuracy: 0.7371 - val_loss: 2.2754 - val_accuracy: 0.4233\n",
      "Epoch 754/1000\n",
      "700/700 [==============================] - 0s 58us/step - loss: 0.6877 - accuracy: 0.7386 - val_loss: 2.2732 - val_accuracy: 0.4267\n",
      "Epoch 755/1000\n",
      "700/700 [==============================] - 0s 59us/step - loss: 0.6878 - accuracy: 0.7386 - val_loss: 2.2760 - val_accuracy: 0.4233\n",
      "Epoch 756/1000\n",
      "700/700 [==============================] - 0s 53us/step - loss: 0.6863 - accuracy: 0.7386 - val_loss: 2.2622 - val_accuracy: 0.4233\n",
      "Epoch 757/1000\n",
      "700/700 [==============================] - 0s 53us/step - loss: 0.6867 - accuracy: 0.7414 - val_loss: 2.2476 - val_accuracy: 0.4333\n",
      "Epoch 758/1000\n",
      "700/700 [==============================] - 0s 53us/step - loss: 0.6880 - accuracy: 0.7414 - val_loss: 2.2852 - val_accuracy: 0.4233\n",
      "Epoch 759/1000\n",
      "700/700 [==============================] - ETA: 0s - loss: 0.4580 - accuracy: 0.90 - 0s 53us/step - loss: 0.6869 - accuracy: 0.7386 - val_loss: 2.3041 - val_accuracy: 0.4100\n",
      "Epoch 760/1000\n",
      "700/700 [==============================] - 0s 57us/step - loss: 0.6865 - accuracy: 0.7371 - val_loss: 2.2732 - val_accuracy: 0.4200\n",
      "Epoch 761/1000\n",
      "700/700 [==============================] - 0s 56us/step - loss: 0.6866 - accuracy: 0.7400 - val_loss: 2.2886 - val_accuracy: 0.4200\n",
      "Epoch 762/1000\n",
      "700/700 [==============================] - 0s 56us/step - loss: 0.6865 - accuracy: 0.7400 - val_loss: 2.2921 - val_accuracy: 0.4200\n",
      "Epoch 763/1000\n",
      "700/700 [==============================] - 0s 58us/step - loss: 0.6856 - accuracy: 0.7414 - val_loss: 2.3143 - val_accuracy: 0.4067\n",
      "Epoch 764/1000\n",
      "700/700 [==============================] - 0s 58us/step - loss: 0.6864 - accuracy: 0.7414 - val_loss: 2.3083 - val_accuracy: 0.4100\n",
      "Epoch 765/1000\n",
      "700/700 [==============================] - 0s 58us/step - loss: 0.6864 - accuracy: 0.7414 - val_loss: 2.2762 - val_accuracy: 0.4233\n",
      "Epoch 766/1000\n",
      "700/700 [==============================] - 0s 61us/step - loss: 0.6854 - accuracy: 0.7443 - val_loss: 2.2767 - val_accuracy: 0.4300\n",
      "Epoch 767/1000\n",
      "700/700 [==============================] - 0s 59us/step - loss: 0.6857 - accuracy: 0.7414 - val_loss: 2.2938 - val_accuracy: 0.4167\n",
      "Epoch 768/1000\n",
      "700/700 [==============================] - 0s 58us/step - loss: 0.6841 - accuracy: 0.7357 - val_loss: 2.2866 - val_accuracy: 0.4300\n",
      "Epoch 769/1000\n",
      "700/700 [==============================] - 0s 58us/step - loss: 0.6836 - accuracy: 0.7414 - val_loss: 2.2953 - val_accuracy: 0.4233\n",
      "Epoch 770/1000\n",
      "700/700 [==============================] - 0s 54us/step - loss: 0.6834 - accuracy: 0.7357 - val_loss: 2.2869 - val_accuracy: 0.4233\n",
      "Epoch 771/1000\n",
      "700/700 [==============================] - 0s 57us/step - loss: 0.6834 - accuracy: 0.7343 - val_loss: 2.2937 - val_accuracy: 0.4267\n",
      "Epoch 772/1000\n",
      "700/700 [==============================] - 0s 54us/step - loss: 0.6816 - accuracy: 0.7400 - val_loss: 2.2770 - val_accuracy: 0.4333\n",
      "Epoch 773/1000\n",
      "700/700 [==============================] - 0s 54us/step - loss: 0.6831 - accuracy: 0.7443 - val_loss: 2.3090 - val_accuracy: 0.4167\n",
      "Epoch 774/1000\n",
      "700/700 [==============================] - 0s 57us/step - loss: 0.6823 - accuracy: 0.7443 - val_loss: 2.3254 - val_accuracy: 0.4033\n",
      "Epoch 775/1000\n",
      "700/700 [==============================] - 0s 57us/step - loss: 0.6832 - accuracy: 0.7386 - val_loss: 2.2895 - val_accuracy: 0.4333\n",
      "Epoch 776/1000\n",
      "700/700 [==============================] - 0s 57us/step - loss: 0.6831 - accuracy: 0.7386 - val_loss: 2.2992 - val_accuracy: 0.4233\n",
      "Epoch 777/1000\n",
      "700/700 [==============================] - 0s 54us/step - loss: 0.6831 - accuracy: 0.7400 - val_loss: 2.2892 - val_accuracy: 0.4300\n",
      "Epoch 778/1000\n",
      "700/700 [==============================] - 0s 57us/step - loss: 0.6820 - accuracy: 0.7414 - val_loss: 2.2875 - val_accuracy: 0.4233\n",
      "Epoch 779/1000\n",
      "700/700 [==============================] - 0s 58us/step - loss: 0.6821 - accuracy: 0.7443 - val_loss: 2.2887 - val_accuracy: 0.4300\n",
      "Epoch 780/1000\n",
      "700/700 [==============================] - 0s 58us/step - loss: 0.6822 - accuracy: 0.7414 - val_loss: 2.3100 - val_accuracy: 0.4167\n",
      "Epoch 781/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "700/700 [==============================] - 0s 56us/step - loss: 0.6829 - accuracy: 0.7471 - val_loss: 2.3331 - val_accuracy: 0.4067\n",
      "Epoch 782/1000\n",
      "700/700 [==============================] - 0s 57us/step - loss: 0.6812 - accuracy: 0.7429 - val_loss: 2.3123 - val_accuracy: 0.4267\n",
      "Epoch 783/1000\n",
      "700/700 [==============================] - 0s 56us/step - loss: 0.6796 - accuracy: 0.7429 - val_loss: 2.3650 - val_accuracy: 0.4067\n",
      "Epoch 784/1000\n",
      "700/700 [==============================] - 0s 60us/step - loss: 0.6818 - accuracy: 0.7443 - val_loss: 2.3103 - val_accuracy: 0.4200\n",
      "Epoch 785/1000\n",
      "700/700 [==============================] - 0s 58us/step - loss: 0.6796 - accuracy: 0.7486 - val_loss: 2.3222 - val_accuracy: 0.4167\n",
      "Epoch 786/1000\n",
      "700/700 [==============================] - 0s 58us/step - loss: 0.6808 - accuracy: 0.7429 - val_loss: 2.3214 - val_accuracy: 0.4233\n",
      "Epoch 787/1000\n",
      "700/700 [==============================] - 0s 58us/step - loss: 0.6800 - accuracy: 0.7429 - val_loss: 2.3145 - val_accuracy: 0.4200\n",
      "Epoch 788/1000\n",
      "700/700 [==============================] - 0s 58us/step - loss: 0.6793 - accuracy: 0.7414 - val_loss: 2.3231 - val_accuracy: 0.4167\n",
      "Epoch 789/1000\n",
      "700/700 [==============================] - 0s 57us/step - loss: 0.6795 - accuracy: 0.7443 - val_loss: 2.3126 - val_accuracy: 0.4233\n",
      "Epoch 790/1000\n",
      "700/700 [==============================] - 0s 57us/step - loss: 0.6795 - accuracy: 0.7443 - val_loss: 2.3150 - val_accuracy: 0.4167\n",
      "Epoch 791/1000\n",
      "700/700 [==============================] - 0s 58us/step - loss: 0.6799 - accuracy: 0.7429 - val_loss: 2.3152 - val_accuracy: 0.4233\n",
      "Epoch 792/1000\n",
      "700/700 [==============================] - 0s 57us/step - loss: 0.6766 - accuracy: 0.7457 - val_loss: 2.3719 - val_accuracy: 0.4033\n",
      "Epoch 793/1000\n",
      "700/700 [==============================] - 0s 56us/step - loss: 0.6792 - accuracy: 0.7429 - val_loss: 2.3226 - val_accuracy: 0.4100\n",
      "Epoch 794/1000\n",
      "700/700 [==============================] - 0s 57us/step - loss: 0.6790 - accuracy: 0.7414 - val_loss: 2.3340 - val_accuracy: 0.4133\n",
      "Epoch 795/1000\n",
      "700/700 [==============================] - 0s 53us/step - loss: 0.6771 - accuracy: 0.7443 - val_loss: 2.3442 - val_accuracy: 0.4100\n",
      "Epoch 796/1000\n",
      "700/700 [==============================] - 0s 56us/step - loss: 0.6773 - accuracy: 0.7443 - val_loss: 2.3314 - val_accuracy: 0.4167\n",
      "Epoch 797/1000\n",
      "700/700 [==============================] - 0s 54us/step - loss: 0.6771 - accuracy: 0.7471 - val_loss: 2.3431 - val_accuracy: 0.4067\n",
      "Epoch 798/1000\n",
      "700/700 [==============================] - 0s 56us/step - loss: 0.6772 - accuracy: 0.7471 - val_loss: 2.3379 - val_accuracy: 0.4167\n",
      "Epoch 799/1000\n",
      "700/700 [==============================] - 0s 56us/step - loss: 0.6767 - accuracy: 0.7471 - val_loss: 2.3667 - val_accuracy: 0.4033\n",
      "Epoch 800/1000\n",
      "700/700 [==============================] - 0s 54us/step - loss: 0.6778 - accuracy: 0.7414 - val_loss: 2.3254 - val_accuracy: 0.4233\n",
      "Epoch 801/1000\n",
      "700/700 [==============================] - 0s 53us/step - loss: 0.6763 - accuracy: 0.7400 - val_loss: 2.3234 - val_accuracy: 0.4233\n",
      "Epoch 802/1000\n",
      "700/700 [==============================] - 0s 54us/step - loss: 0.6762 - accuracy: 0.7414 - val_loss: 2.3428 - val_accuracy: 0.4233\n",
      "Epoch 803/1000\n",
      "700/700 [==============================] - 0s 54us/step - loss: 0.6751 - accuracy: 0.7443 - val_loss: 2.3269 - val_accuracy: 0.4200\n",
      "Epoch 804/1000\n",
      "700/700 [==============================] - 0s 54us/step - loss: 0.6753 - accuracy: 0.7514 - val_loss: 2.3160 - val_accuracy: 0.4267\n",
      "Epoch 805/1000\n",
      "700/700 [==============================] - 0s 54us/step - loss: 0.6761 - accuracy: 0.7471 - val_loss: 2.3379 - val_accuracy: 0.4200\n",
      "Epoch 806/1000\n",
      "700/700 [==============================] - 0s 56us/step - loss: 0.6753 - accuracy: 0.7429 - val_loss: 2.3515 - val_accuracy: 0.4167\n",
      "Epoch 807/1000\n",
      "700/700 [==============================] - 0s 54us/step - loss: 0.6747 - accuracy: 0.7429 - val_loss: 2.3589 - val_accuracy: 0.4133\n",
      "Epoch 808/1000\n",
      "700/700 [==============================] - 0s 51us/step - loss: 0.6751 - accuracy: 0.7457 - val_loss: 2.3377 - val_accuracy: 0.4167\n",
      "Epoch 809/1000\n",
      "700/700 [==============================] - 0s 54us/step - loss: 0.6753 - accuracy: 0.7457 - val_loss: 2.3907 - val_accuracy: 0.4067\n",
      "Epoch 810/1000\n",
      "700/700 [==============================] - 0s 53us/step - loss: 0.6754 - accuracy: 0.7514 - val_loss: 2.3486 - val_accuracy: 0.4167\n",
      "Epoch 811/1000\n",
      "700/700 [==============================] - 0s 51us/step - loss: 0.6749 - accuracy: 0.7386 - val_loss: 2.3270 - val_accuracy: 0.4367\n",
      "Epoch 812/1000\n",
      "700/700 [==============================] - 0s 54us/step - loss: 0.6736 - accuracy: 0.7486 - val_loss: 2.3782 - val_accuracy: 0.4033\n",
      "Epoch 813/1000\n",
      "700/700 [==============================] - 0s 57us/step - loss: 0.6727 - accuracy: 0.7457 - val_loss: 2.3220 - val_accuracy: 0.4333\n",
      "Epoch 814/1000\n",
      "700/700 [==============================] - 0s 57us/step - loss: 0.6720 - accuracy: 0.7471 - val_loss: 2.3369 - val_accuracy: 0.4300\n",
      "Epoch 815/1000\n",
      "700/700 [==============================] - 0s 60us/step - loss: 0.6733 - accuracy: 0.7486 - val_loss: 2.3789 - val_accuracy: 0.4100\n",
      "Epoch 816/1000\n",
      "700/700 [==============================] - 0s 56us/step - loss: 0.6736 - accuracy: 0.7486 - val_loss: 2.3654 - val_accuracy: 0.4133\n",
      "Epoch 817/1000\n",
      "700/700 [==============================] - 0s 57us/step - loss: 0.6726 - accuracy: 0.7471 - val_loss: 2.3503 - val_accuracy: 0.4233\n",
      "Epoch 818/1000\n",
      "700/700 [==============================] - 0s 57us/step - loss: 0.6731 - accuracy: 0.7443 - val_loss: 2.3461 - val_accuracy: 0.4200\n",
      "Epoch 819/1000\n",
      "700/700 [==============================] - 0s 60us/step - loss: 0.6718 - accuracy: 0.7500 - val_loss: 2.3661 - val_accuracy: 0.4333\n",
      "Epoch 820/1000\n",
      "700/700 [==============================] - 0s 54us/step - loss: 0.6719 - accuracy: 0.7486 - val_loss: 2.3328 - val_accuracy: 0.4333\n",
      "Epoch 821/1000\n",
      "700/700 [==============================] - 0s 53us/step - loss: 0.6734 - accuracy: 0.7457 - val_loss: 2.3765 - val_accuracy: 0.4167\n",
      "Epoch 822/1000\n",
      "700/700 [==============================] - 0s 54us/step - loss: 0.6726 - accuracy: 0.7457 - val_loss: 2.3618 - val_accuracy: 0.4167\n",
      "Epoch 823/1000\n",
      "700/700 [==============================] - 0s 56us/step - loss: 0.6717 - accuracy: 0.7429 - val_loss: 2.3706 - val_accuracy: 0.4167\n",
      "Epoch 824/1000\n",
      "700/700 [==============================] - 0s 56us/step - loss: 0.6721 - accuracy: 0.7443 - val_loss: 2.3585 - val_accuracy: 0.4300\n",
      "Epoch 825/1000\n",
      "700/700 [==============================] - 0s 54us/step - loss: 0.6715 - accuracy: 0.7486 - val_loss: 2.3897 - val_accuracy: 0.4067\n",
      "Epoch 826/1000\n",
      "700/700 [==============================] - 0s 58us/step - loss: 0.6715 - accuracy: 0.7514 - val_loss: 2.3682 - val_accuracy: 0.4100\n",
      "Epoch 827/1000\n",
      "700/700 [==============================] - 0s 60us/step - loss: 0.6716 - accuracy: 0.7471 - val_loss: 2.3692 - val_accuracy: 0.4267\n",
      "Epoch 828/1000\n",
      "700/700 [==============================] - 0s 58us/step - loss: 0.6698 - accuracy: 0.7471 - val_loss: 2.3877 - val_accuracy: 0.4067\n",
      "Epoch 829/1000\n",
      "700/700 [==============================] - 0s 60us/step - loss: 0.6704 - accuracy: 0.7457 - val_loss: 2.3581 - val_accuracy: 0.4300\n",
      "Epoch 830/1000\n",
      "700/700 [==============================] - 0s 57us/step - loss: 0.6696 - accuracy: 0.7471 - val_loss: 2.4005 - val_accuracy: 0.4000\n",
      "Epoch 831/1000\n",
      "700/700 [==============================] - 0s 57us/step - loss: 0.6699 - accuracy: 0.7514 - val_loss: 2.3908 - val_accuracy: 0.4033\n",
      "Epoch 832/1000\n",
      "700/700 [==============================] - 0s 54us/step - loss: 0.6699 - accuracy: 0.7443 - val_loss: 2.3942 - val_accuracy: 0.4000\n",
      "Epoch 833/1000\n",
      "700/700 [==============================] - 0s 56us/step - loss: 0.6698 - accuracy: 0.7486 - val_loss: 2.3654 - val_accuracy: 0.4300\n",
      "Epoch 834/1000\n",
      "700/700 [==============================] - 0s 57us/step - loss: 0.6692 - accuracy: 0.7486 - val_loss: 2.3619 - val_accuracy: 0.4333\n",
      "Epoch 835/1000\n",
      "700/700 [==============================] - 0s 58us/step - loss: 0.6676 - accuracy: 0.7500 - val_loss: 2.4369 - val_accuracy: 0.4033\n",
      "Epoch 836/1000\n",
      "700/700 [==============================] - 0s 57us/step - loss: 0.6701 - accuracy: 0.7529 - val_loss: 2.3735 - val_accuracy: 0.4333\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 837/1000\n",
      "700/700 [==============================] - 0s 58us/step - loss: 0.6668 - accuracy: 0.7500 - val_loss: 2.3657 - val_accuracy: 0.4333\n",
      "Epoch 838/1000\n",
      "700/700 [==============================] - 0s 57us/step - loss: 0.6693 - accuracy: 0.7557 - val_loss: 2.3863 - val_accuracy: 0.4067\n",
      "Epoch 839/1000\n",
      "700/700 [==============================] - 0s 56us/step - loss: 0.6684 - accuracy: 0.7500 - val_loss: 2.4124 - val_accuracy: 0.4067\n",
      "Epoch 840/1000\n",
      "700/700 [==============================] - 0s 57us/step - loss: 0.6686 - accuracy: 0.7500 - val_loss: 2.3752 - val_accuracy: 0.4300\n",
      "Epoch 841/1000\n",
      "700/700 [==============================] - 0s 58us/step - loss: 0.6670 - accuracy: 0.7514 - val_loss: 2.4104 - val_accuracy: 0.4067\n",
      "Epoch 842/1000\n",
      "700/700 [==============================] - 0s 57us/step - loss: 0.6684 - accuracy: 0.7543 - val_loss: 2.3826 - val_accuracy: 0.4200\n",
      "Epoch 843/1000\n",
      "700/700 [==============================] - 0s 57us/step - loss: 0.6676 - accuracy: 0.7471 - val_loss: 2.4054 - val_accuracy: 0.4100\n",
      "Epoch 844/1000\n",
      "700/700 [==============================] - 0s 57us/step - loss: 0.6665 - accuracy: 0.7457 - val_loss: 2.3795 - val_accuracy: 0.4300\n",
      "Epoch 845/1000\n",
      "700/700 [==============================] - 0s 56us/step - loss: 0.6663 - accuracy: 0.7486 - val_loss: 2.3366 - val_accuracy: 0.4333\n",
      "Epoch 846/1000\n",
      "700/700 [==============================] - 0s 55us/step - loss: 0.6673 - accuracy: 0.7529 - val_loss: 2.3971 - val_accuracy: 0.4167\n",
      "Epoch 847/1000\n",
      "700/700 [==============================] - 0s 57us/step - loss: 0.6663 - accuracy: 0.7529 - val_loss: 2.3915 - val_accuracy: 0.4167\n",
      "Epoch 848/1000\n",
      "700/700 [==============================] - 0s 57us/step - loss: 0.6671 - accuracy: 0.7514 - val_loss: 2.4169 - val_accuracy: 0.4067\n",
      "Epoch 849/1000\n",
      "700/700 [==============================] - 0s 57us/step - loss: 0.6655 - accuracy: 0.7514 - val_loss: 2.4143 - val_accuracy: 0.4033\n",
      "Epoch 850/1000\n",
      "700/700 [==============================] - 0s 57us/step - loss: 0.6654 - accuracy: 0.7486 - val_loss: 2.4159 - val_accuracy: 0.4067\n",
      "Epoch 851/1000\n",
      "700/700 [==============================] - 0s 58us/step - loss: 0.6652 - accuracy: 0.7529 - val_loss: 2.3754 - val_accuracy: 0.4333\n",
      "Epoch 852/1000\n",
      "700/700 [==============================] - 0s 53us/step - loss: 0.6650 - accuracy: 0.7514 - val_loss: 2.3834 - val_accuracy: 0.4233\n",
      "Epoch 853/1000\n",
      "700/700 [==============================] - 0s 53us/step - loss: 0.6647 - accuracy: 0.7529 - val_loss: 2.4147 - val_accuracy: 0.4100\n",
      "Epoch 854/1000\n",
      "700/700 [==============================] - 0s 53us/step - loss: 0.6648 - accuracy: 0.7586 - val_loss: 2.4090 - val_accuracy: 0.4233\n",
      "Epoch 855/1000\n",
      "700/700 [==============================] - 0s 56us/step - loss: 0.6654 - accuracy: 0.7529 - val_loss: 2.4445 - val_accuracy: 0.4033\n",
      "Epoch 856/1000\n",
      "700/700 [==============================] - 0s 56us/step - loss: 0.6653 - accuracy: 0.7500 - val_loss: 2.4074 - val_accuracy: 0.4100\n",
      "Epoch 857/1000\n",
      "700/700 [==============================] - 0s 54us/step - loss: 0.6639 - accuracy: 0.7500 - val_loss: 2.4181 - val_accuracy: 0.4133\n",
      "Epoch 858/1000\n",
      "700/700 [==============================] - 0s 57us/step - loss: 0.6632 - accuracy: 0.7514 - val_loss: 2.4071 - val_accuracy: 0.4233\n",
      "Epoch 859/1000\n",
      "700/700 [==============================] - 0s 56us/step - loss: 0.6641 - accuracy: 0.7457 - val_loss: 2.3828 - val_accuracy: 0.4300\n",
      "Epoch 860/1000\n",
      "700/700 [==============================] - 0s 58us/step - loss: 0.6630 - accuracy: 0.7486 - val_loss: 2.3998 - val_accuracy: 0.4233\n",
      "Epoch 861/1000\n",
      "700/700 [==============================] - 0s 57us/step - loss: 0.6636 - accuracy: 0.7500 - val_loss: 2.3788 - val_accuracy: 0.4300\n",
      "Epoch 862/1000\n",
      "700/700 [==============================] - 0s 60us/step - loss: 0.6627 - accuracy: 0.7500 - val_loss: 2.4159 - val_accuracy: 0.4267\n",
      "Epoch 863/1000\n",
      "700/700 [==============================] - 0s 58us/step - loss: 0.6623 - accuracy: 0.7557 - val_loss: 2.4615 - val_accuracy: 0.4067\n",
      "Epoch 864/1000\n",
      "700/700 [==============================] - 0s 57us/step - loss: 0.6636 - accuracy: 0.7514 - val_loss: 2.4132 - val_accuracy: 0.4233\n",
      "Epoch 865/1000\n",
      "700/700 [==============================] - 0s 58us/step - loss: 0.6621 - accuracy: 0.7543 - val_loss: 2.4268 - val_accuracy: 0.4100\n",
      "Epoch 866/1000\n",
      "700/700 [==============================] - 0s 58us/step - loss: 0.6618 - accuracy: 0.7543 - val_loss: 2.4305 - val_accuracy: 0.4133\n",
      "Epoch 867/1000\n",
      "700/700 [==============================] - 0s 56us/step - loss: 0.6626 - accuracy: 0.7529 - val_loss: 2.4217 - val_accuracy: 0.4267\n",
      "Epoch 868/1000\n",
      "700/700 [==============================] - 0s 54us/step - loss: 0.6618 - accuracy: 0.7557 - val_loss: 2.4259 - val_accuracy: 0.4133\n",
      "Epoch 869/1000\n",
      "700/700 [==============================] - 0s 57us/step - loss: 0.6620 - accuracy: 0.7557 - val_loss: 2.4408 - val_accuracy: 0.4100\n",
      "Epoch 870/1000\n",
      "700/700 [==============================] - 0s 54us/step - loss: 0.6613 - accuracy: 0.7557 - val_loss: 2.4148 - val_accuracy: 0.4200\n",
      "Epoch 871/1000\n",
      "700/700 [==============================] - 0s 54us/step - loss: 0.6611 - accuracy: 0.7543 - val_loss: 2.4433 - val_accuracy: 0.4033\n",
      "Epoch 872/1000\n",
      "700/700 [==============================] - 0s 56us/step - loss: 0.6609 - accuracy: 0.7543 - val_loss: 2.4440 - val_accuracy: 0.4100\n",
      "Epoch 873/1000\n",
      "700/700 [==============================] - 0s 54us/step - loss: 0.6615 - accuracy: 0.7557 - val_loss: 2.4244 - val_accuracy: 0.4200\n",
      "Epoch 874/1000\n",
      "700/700 [==============================] - 0s 53us/step - loss: 0.6604 - accuracy: 0.7514 - val_loss: 2.4595 - val_accuracy: 0.4067\n",
      "Epoch 875/1000\n",
      "700/700 [==============================] - 0s 57us/step - loss: 0.6611 - accuracy: 0.7514 - val_loss: 2.4507 - val_accuracy: 0.4067\n",
      "Epoch 876/1000\n",
      "700/700 [==============================] - 0s 56us/step - loss: 0.6601 - accuracy: 0.7557 - val_loss: 2.4431 - val_accuracy: 0.4133\n",
      "Epoch 877/1000\n",
      "700/700 [==============================] - 0s 58us/step - loss: 0.6588 - accuracy: 0.7571 - val_loss: 2.4494 - val_accuracy: 0.4067\n",
      "Epoch 878/1000\n",
      "700/700 [==============================] - 0s 58us/step - loss: 0.6597 - accuracy: 0.7514 - val_loss: 2.4151 - val_accuracy: 0.4233\n",
      "Epoch 879/1000\n",
      "700/700 [==============================] - 0s 54us/step - loss: 0.6596 - accuracy: 0.7514 - val_loss: 2.4521 - val_accuracy: 0.4033\n",
      "Epoch 880/1000\n",
      "700/700 [==============================] - 0s 57us/step - loss: 0.6599 - accuracy: 0.7500 - val_loss: 2.4549 - val_accuracy: 0.4033\n",
      "Epoch 881/1000\n",
      "700/700 [==============================] - 0s 60us/step - loss: 0.6601 - accuracy: 0.7529 - val_loss: 2.4398 - val_accuracy: 0.4067\n",
      "Epoch 882/1000\n",
      "700/700 [==============================] - 0s 58us/step - loss: 0.6591 - accuracy: 0.7557 - val_loss: 2.4428 - val_accuracy: 0.4200\n",
      "Epoch 883/1000\n",
      "700/700 [==============================] - 0s 58us/step - loss: 0.6577 - accuracy: 0.7543 - val_loss: 2.4714 - val_accuracy: 0.4033\n",
      "Epoch 884/1000\n",
      "700/700 [==============================] - 0s 58us/step - loss: 0.6582 - accuracy: 0.7614 - val_loss: 2.4544 - val_accuracy: 0.4033\n",
      "Epoch 885/1000\n",
      "700/700 [==============================] - 0s 58us/step - loss: 0.6579 - accuracy: 0.7557 - val_loss: 2.4077 - val_accuracy: 0.4300\n",
      "Epoch 886/1000\n",
      "700/700 [==============================] - 0s 56us/step - loss: 0.6586 - accuracy: 0.7586 - val_loss: 2.4575 - val_accuracy: 0.4067\n",
      "Epoch 887/1000\n",
      "700/700 [==============================] - 0s 54us/step - loss: 0.6569 - accuracy: 0.7543 - val_loss: 2.4903 - val_accuracy: 0.4067\n",
      "Epoch 888/1000\n",
      "700/700 [==============================] - 0s 56us/step - loss: 0.6582 - accuracy: 0.7557 - val_loss: 2.4142 - val_accuracy: 0.4300\n",
      "Epoch 889/1000\n",
      "700/700 [==============================] - 0s 53us/step - loss: 0.6576 - accuracy: 0.7629 - val_loss: 2.4653 - val_accuracy: 0.4133\n",
      "Epoch 890/1000\n",
      "700/700 [==============================] - 0s 58us/step - loss: 0.6572 - accuracy: 0.7614 - val_loss: 2.4647 - val_accuracy: 0.4067\n",
      "Epoch 891/1000\n",
      "700/700 [==============================] - 0s 60us/step - loss: 0.6558 - accuracy: 0.7571 - val_loss: 2.4264 - val_accuracy: 0.4200\n",
      "Epoch 892/1000\n",
      "700/700 [==============================] - 0s 60us/step - loss: 0.6572 - accuracy: 0.7571 - val_loss: 2.4622 - val_accuracy: 0.4067\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 893/1000\n",
      "700/700 [==============================] - 0s 58us/step - loss: 0.6569 - accuracy: 0.7543 - val_loss: 2.4588 - val_accuracy: 0.4167\n",
      "Epoch 894/1000\n",
      "700/700 [==============================] - 0s 56us/step - loss: 0.6573 - accuracy: 0.7586 - val_loss: 2.4461 - val_accuracy: 0.4100\n",
      "Epoch 895/1000\n",
      "700/700 [==============================] - 0s 58us/step - loss: 0.6574 - accuracy: 0.7471 - val_loss: 2.4866 - val_accuracy: 0.4067\n",
      "Epoch 896/1000\n",
      "700/700 [==============================] - 0s 53us/step - loss: 0.6557 - accuracy: 0.7529 - val_loss: 2.4283 - val_accuracy: 0.4267\n",
      "Epoch 897/1000\n",
      "700/700 [==============================] - 0s 56us/step - loss: 0.6568 - accuracy: 0.7571 - val_loss: 2.4230 - val_accuracy: 0.4300\n",
      "Epoch 898/1000\n",
      "700/700 [==============================] - 0s 60us/step - loss: 0.6566 - accuracy: 0.7586 - val_loss: 2.4547 - val_accuracy: 0.4267\n",
      "Epoch 899/1000\n",
      "700/700 [==============================] - 0s 60us/step - loss: 0.6560 - accuracy: 0.7543 - val_loss: 2.4588 - val_accuracy: 0.4200\n",
      "Epoch 900/1000\n",
      "700/700 [==============================] - 0s 60us/step - loss: 0.6558 - accuracy: 0.7543 - val_loss: 2.4583 - val_accuracy: 0.4200\n",
      "Epoch 901/1000\n",
      "700/700 [==============================] - 0s 58us/step - loss: 0.6556 - accuracy: 0.7600 - val_loss: 2.4822 - val_accuracy: 0.4100\n",
      "Epoch 902/1000\n",
      "700/700 [==============================] - 0s 58us/step - loss: 0.6553 - accuracy: 0.7557 - val_loss: 2.4667 - val_accuracy: 0.4167\n",
      "Epoch 903/1000\n",
      "700/700 [==============================] - 0s 57us/step - loss: 0.6555 - accuracy: 0.7557 - val_loss: 2.4421 - val_accuracy: 0.4300\n",
      "Epoch 904/1000\n",
      "700/700 [==============================] - 0s 60us/step - loss: 0.6542 - accuracy: 0.7586 - val_loss: 2.4670 - val_accuracy: 0.4167\n",
      "Epoch 905/1000\n",
      "700/700 [==============================] - 0s 57us/step - loss: 0.6545 - accuracy: 0.7571 - val_loss: 2.4556 - val_accuracy: 0.4233\n",
      "Epoch 906/1000\n",
      "700/700 [==============================] - 0s 57us/step - loss: 0.6544 - accuracy: 0.7600 - val_loss: 2.4680 - val_accuracy: 0.4200\n",
      "Epoch 907/1000\n",
      "700/700 [==============================] - 0s 53us/step - loss: 0.6541 - accuracy: 0.7586 - val_loss: 2.4525 - val_accuracy: 0.4333\n",
      "Epoch 908/1000\n",
      "700/700 [==============================] - 0s 51us/step - loss: 0.6540 - accuracy: 0.7614 - val_loss: 2.4813 - val_accuracy: 0.4133\n",
      "Epoch 909/1000\n",
      "700/700 [==============================] - 0s 53us/step - loss: 0.6546 - accuracy: 0.7557 - val_loss: 2.5021 - val_accuracy: 0.4100\n",
      "Epoch 910/1000\n",
      "700/700 [==============================] - 0s 53us/step - loss: 0.6534 - accuracy: 0.7529 - val_loss: 2.4985 - val_accuracy: 0.4067\n",
      "Epoch 911/1000\n",
      "700/700 [==============================] - 0s 57us/step - loss: 0.6541 - accuracy: 0.7571 - val_loss: 2.4872 - val_accuracy: 0.4100\n",
      "Epoch 912/1000\n",
      "700/700 [==============================] - 0s 60us/step - loss: 0.6526 - accuracy: 0.7614 - val_loss: 2.4978 - val_accuracy: 0.4033\n",
      "Epoch 913/1000\n",
      "700/700 [==============================] - 0s 57us/step - loss: 0.6537 - accuracy: 0.7571 - val_loss: 2.4802 - val_accuracy: 0.4200\n",
      "Epoch 914/1000\n",
      "700/700 [==============================] - 0s 60us/step - loss: 0.6529 - accuracy: 0.7529 - val_loss: 2.4986 - val_accuracy: 0.4067\n",
      "Epoch 915/1000\n",
      "700/700 [==============================] - 0s 57us/step - loss: 0.6525 - accuracy: 0.7614 - val_loss: 2.4644 - val_accuracy: 0.4233\n",
      "Epoch 916/1000\n",
      "700/700 [==============================] - 0s 56us/step - loss: 0.6529 - accuracy: 0.7586 - val_loss: 2.4732 - val_accuracy: 0.4200\n",
      "Epoch 917/1000\n",
      "700/700 [==============================] - 0s 58us/step - loss: 0.6518 - accuracy: 0.7657 - val_loss: 2.4987 - val_accuracy: 0.4033\n",
      "Epoch 918/1000\n",
      "700/700 [==============================] - 0s 58us/step - loss: 0.6530 - accuracy: 0.7586 - val_loss: 2.4989 - val_accuracy: 0.4067\n",
      "Epoch 919/1000\n",
      "700/700 [==============================] - 0s 58us/step - loss: 0.6526 - accuracy: 0.7543 - val_loss: 2.4805 - val_accuracy: 0.4233\n",
      "Epoch 920/1000\n",
      "700/700 [==============================] - 0s 58us/step - loss: 0.6521 - accuracy: 0.7557 - val_loss: 2.4635 - val_accuracy: 0.4233\n",
      "Epoch 921/1000\n",
      "700/700 [==============================] - 0s 58us/step - loss: 0.6524 - accuracy: 0.7614 - val_loss: 2.5176 - val_accuracy: 0.4033\n",
      "Epoch 922/1000\n",
      "700/700 [==============================] - 0s 57us/step - loss: 0.6516 - accuracy: 0.7600 - val_loss: 2.4975 - val_accuracy: 0.4067\n",
      "Epoch 923/1000\n",
      "700/700 [==============================] - 0s 57us/step - loss: 0.6513 - accuracy: 0.7557 - val_loss: 2.4938 - val_accuracy: 0.4200\n",
      "Epoch 924/1000\n",
      "700/700 [==============================] - 0s 53us/step - loss: 0.6509 - accuracy: 0.7614 - val_loss: 2.4969 - val_accuracy: 0.4167\n",
      "Epoch 925/1000\n",
      "700/700 [==============================] - 0s 58us/step - loss: 0.6513 - accuracy: 0.7557 - val_loss: 2.5041 - val_accuracy: 0.4100\n",
      "Epoch 926/1000\n",
      "700/700 [==============================] - 0s 57us/step - loss: 0.6512 - accuracy: 0.7571 - val_loss: 2.4719 - val_accuracy: 0.4200\n",
      "Epoch 927/1000\n",
      "700/700 [==============================] - 0s 57us/step - loss: 0.6508 - accuracy: 0.7543 - val_loss: 2.5057 - val_accuracy: 0.4200\n",
      "Epoch 928/1000\n",
      "700/700 [==============================] - 0s 56us/step - loss: 0.6493 - accuracy: 0.7629 - val_loss: 2.4829 - val_accuracy: 0.4200\n",
      "Epoch 929/1000\n",
      "700/700 [==============================] - 0s 57us/step - loss: 0.6489 - accuracy: 0.7557 - val_loss: 2.4692 - val_accuracy: 0.4233\n",
      "Epoch 930/1000\n",
      "700/700 [==============================] - 0s 57us/step - loss: 0.6499 - accuracy: 0.7614 - val_loss: 2.5044 - val_accuracy: 0.4133\n",
      "Epoch 931/1000\n",
      "700/700 [==============================] - 0s 58us/step - loss: 0.6499 - accuracy: 0.7571 - val_loss: 2.4836 - val_accuracy: 0.4233\n",
      "Epoch 932/1000\n",
      "700/700 [==============================] - 0s 58us/step - loss: 0.6497 - accuracy: 0.7600 - val_loss: 2.5152 - val_accuracy: 0.4067\n",
      "Epoch 933/1000\n",
      "700/700 [==============================] - 0s 58us/step - loss: 0.6496 - accuracy: 0.7600 - val_loss: 2.4845 - val_accuracy: 0.4267\n",
      "Epoch 934/1000\n",
      "700/700 [==============================] - 0s 57us/step - loss: 0.6485 - accuracy: 0.7600 - val_loss: 2.5013 - val_accuracy: 0.4167\n",
      "Epoch 935/1000\n",
      "700/700 [==============================] - 0s 58us/step - loss: 0.6494 - accuracy: 0.7600 - val_loss: 2.4726 - val_accuracy: 0.4267\n",
      "Epoch 936/1000\n",
      "700/700 [==============================] - 0s 56us/step - loss: 0.6493 - accuracy: 0.7629 - val_loss: 2.5233 - val_accuracy: 0.4200\n",
      "Epoch 937/1000\n",
      "700/700 [==============================] - 0s 54us/step - loss: 0.6482 - accuracy: 0.7529 - val_loss: 2.5121 - val_accuracy: 0.4167\n",
      "Epoch 938/1000\n",
      "700/700 [==============================] - 0s 54us/step - loss: 0.6478 - accuracy: 0.7571 - val_loss: 2.5472 - val_accuracy: 0.4100\n",
      "Epoch 939/1000\n",
      "700/700 [==============================] - 0s 58us/step - loss: 0.6486 - accuracy: 0.7643 - val_loss: 2.5215 - val_accuracy: 0.4167\n",
      "Epoch 940/1000\n",
      "700/700 [==============================] - 0s 57us/step - loss: 0.6482 - accuracy: 0.7557 - val_loss: 2.5204 - val_accuracy: 0.4233\n",
      "Epoch 941/1000\n",
      "700/700 [==============================] - 0s 57us/step - loss: 0.6482 - accuracy: 0.7643 - val_loss: 2.5431 - val_accuracy: 0.4067\n",
      "Epoch 942/1000\n",
      "700/700 [==============================] - 0s 60us/step - loss: 0.6479 - accuracy: 0.7600 - val_loss: 2.5028 - val_accuracy: 0.4267\n",
      "Epoch 943/1000\n",
      "700/700 [==============================] - 0s 57us/step - loss: 0.6488 - accuracy: 0.7600 - val_loss: 2.5130 - val_accuracy: 0.4233\n",
      "Epoch 944/1000\n",
      "700/700 [==============================] - 0s 53us/step - loss: 0.6470 - accuracy: 0.7614 - val_loss: 2.5230 - val_accuracy: 0.4100\n",
      "Epoch 945/1000\n",
      "700/700 [==============================] - 0s 58us/step - loss: 0.6467 - accuracy: 0.7614 - val_loss: 2.5600 - val_accuracy: 0.4000\n",
      "Epoch 946/1000\n",
      "700/700 [==============================] - 0s 58us/step - loss: 0.6463 - accuracy: 0.7614 - val_loss: 2.5188 - val_accuracy: 0.4233\n",
      "Epoch 947/1000\n",
      "700/700 [==============================] - 0s 57us/step - loss: 0.6463 - accuracy: 0.7671 - val_loss: 2.5136 - val_accuracy: 0.4167\n",
      "Epoch 948/1000\n",
      "700/700 [==============================] - 0s 58us/step - loss: 0.6465 - accuracy: 0.7657 - val_loss: 2.5463 - val_accuracy: 0.4033\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 949/1000\n",
      "700/700 [==============================] - 0s 57us/step - loss: 0.6467 - accuracy: 0.7586 - val_loss: 2.5182 - val_accuracy: 0.4133\n",
      "Epoch 950/1000\n",
      "700/700 [==============================] - 0s 53us/step - loss: 0.6461 - accuracy: 0.7614 - val_loss: 2.5320 - val_accuracy: 0.4000\n",
      "Epoch 951/1000\n",
      "700/700 [==============================] - 0s 57us/step - loss: 0.6456 - accuracy: 0.7600 - val_loss: 2.5055 - val_accuracy: 0.4200\n",
      "Epoch 952/1000\n",
      "700/700 [==============================] - 0s 57us/step - loss: 0.6471 - accuracy: 0.7614 - val_loss: 2.5338 - val_accuracy: 0.4133\n",
      "Epoch 953/1000\n",
      "700/700 [==============================] - 0s 53us/step - loss: 0.6466 - accuracy: 0.7586 - val_loss: 2.5382 - val_accuracy: 0.4167\n",
      "Epoch 954/1000\n",
      "700/700 [==============================] - 0s 50us/step - loss: 0.6455 - accuracy: 0.7600 - val_loss: 2.5492 - val_accuracy: 0.4000\n",
      "Epoch 955/1000\n",
      "700/700 [==============================] - ETA: 0s - loss: 0.4803 - accuracy: 0.90 - 0s 54us/step - loss: 0.6464 - accuracy: 0.7614 - val_loss: 2.5764 - val_accuracy: 0.4000\n",
      "Epoch 956/1000\n",
      "700/700 [==============================] - 0s 58us/step - loss: 0.6467 - accuracy: 0.7629 - val_loss: 2.5335 - val_accuracy: 0.4200\n",
      "Epoch 957/1000\n",
      "700/700 [==============================] - 0s 57us/step - loss: 0.6450 - accuracy: 0.7600 - val_loss: 2.5105 - val_accuracy: 0.4267\n",
      "Epoch 958/1000\n",
      "700/700 [==============================] - 0s 58us/step - loss: 0.6453 - accuracy: 0.7657 - val_loss: 2.5673 - val_accuracy: 0.4033\n",
      "Epoch 959/1000\n",
      "700/700 [==============================] - 0s 56us/step - loss: 0.6459 - accuracy: 0.7614 - val_loss: 2.5274 - val_accuracy: 0.4233\n",
      "Epoch 960/1000\n",
      "700/700 [==============================] - 0s 57us/step - loss: 0.6440 - accuracy: 0.7629 - val_loss: 2.5493 - val_accuracy: 0.4000\n",
      "Epoch 961/1000\n",
      "700/700 [==============================] - 0s 59us/step - loss: 0.6450 - accuracy: 0.7600 - val_loss: 2.5370 - val_accuracy: 0.4200\n",
      "Epoch 962/1000\n",
      "700/700 [==============================] - 0s 57us/step - loss: 0.6446 - accuracy: 0.7600 - val_loss: 2.5857 - val_accuracy: 0.4000\n",
      "Epoch 963/1000\n",
      "700/700 [==============================] - 0s 54us/step - loss: 0.6431 - accuracy: 0.7643 - val_loss: 2.5199 - val_accuracy: 0.4167\n",
      "Epoch 964/1000\n",
      "700/700 [==============================] - 0s 54us/step - loss: 0.6452 - accuracy: 0.7671 - val_loss: 2.5647 - val_accuracy: 0.4033\n",
      "Epoch 965/1000\n",
      "700/700 [==============================] - 0s 53us/step - loss: 0.6431 - accuracy: 0.7671 - val_loss: 2.5882 - val_accuracy: 0.3967\n",
      "Epoch 966/1000\n",
      "700/700 [==============================] - 0s 54us/step - loss: 0.6442 - accuracy: 0.7700 - val_loss: 2.5372 - val_accuracy: 0.4167\n",
      "Epoch 967/1000\n",
      "700/700 [==============================] - 0s 54us/step - loss: 0.6435 - accuracy: 0.7614 - val_loss: 2.5596 - val_accuracy: 0.4000\n",
      "Epoch 968/1000\n",
      "700/700 [==============================] - 0s 56us/step - loss: 0.6430 - accuracy: 0.7614 - val_loss: 2.5159 - val_accuracy: 0.4267\n",
      "Epoch 969/1000\n",
      "700/700 [==============================] - 0s 58us/step - loss: 0.6433 - accuracy: 0.7671 - val_loss: 2.5596 - val_accuracy: 0.4100\n",
      "Epoch 970/1000\n",
      "700/700 [==============================] - 0s 54us/step - loss: 0.6434 - accuracy: 0.7600 - val_loss: 2.6068 - val_accuracy: 0.4033\n",
      "Epoch 971/1000\n",
      "700/700 [==============================] - 0s 58us/step - loss: 0.6430 - accuracy: 0.7643 - val_loss: 2.5598 - val_accuracy: 0.4200\n",
      "Epoch 972/1000\n",
      "700/700 [==============================] - 0s 59us/step - loss: 0.6424 - accuracy: 0.7600 - val_loss: 2.5588 - val_accuracy: 0.4033\n",
      "Epoch 973/1000\n",
      "700/700 [==============================] - 0s 57us/step - loss: 0.6425 - accuracy: 0.7629 - val_loss: 2.5458 - val_accuracy: 0.4100\n",
      "Epoch 974/1000\n",
      "700/700 [==============================] - 0s 57us/step - loss: 0.6417 - accuracy: 0.7657 - val_loss: 2.5794 - val_accuracy: 0.4000\n",
      "Epoch 975/1000\n",
      "700/700 [==============================] - 0s 58us/step - loss: 0.6416 - accuracy: 0.7686 - val_loss: 2.5337 - val_accuracy: 0.4167\n",
      "Epoch 976/1000\n",
      "700/700 [==============================] - 0s 53us/step - loss: 0.6410 - accuracy: 0.7643 - val_loss: 2.5300 - val_accuracy: 0.4300\n",
      "Epoch 977/1000\n",
      "700/700 [==============================] - 0s 57us/step - loss: 0.6416 - accuracy: 0.7657 - val_loss: 2.5459 - val_accuracy: 0.4233\n",
      "Epoch 978/1000\n",
      "700/700 [==============================] - 0s 53us/step - loss: 0.6415 - accuracy: 0.7629 - val_loss: 2.5255 - val_accuracy: 0.4333\n",
      "Epoch 979/1000\n",
      "700/700 [==============================] - 0s 57us/step - loss: 0.6407 - accuracy: 0.7657 - val_loss: 2.5641 - val_accuracy: 0.4100\n",
      "Epoch 980/1000\n",
      "700/700 [==============================] - 0s 58us/step - loss: 0.6415 - accuracy: 0.7657 - val_loss: 2.5433 - val_accuracy: 0.4100\n",
      "Epoch 981/1000\n",
      "700/700 [==============================] - 0s 57us/step - loss: 0.6410 - accuracy: 0.7614 - val_loss: 2.5215 - val_accuracy: 0.4200\n",
      "Epoch 982/1000\n",
      "700/700 [==============================] - 0s 58us/step - loss: 0.6405 - accuracy: 0.7643 - val_loss: 2.5740 - val_accuracy: 0.4100\n",
      "Epoch 983/1000\n",
      "700/700 [==============================] - 0s 54us/step - loss: 0.6393 - accuracy: 0.7643 - val_loss: 2.5479 - val_accuracy: 0.4167\n",
      "Epoch 984/1000\n",
      "700/700 [==============================] - 0s 57us/step - loss: 0.6400 - accuracy: 0.7629 - val_loss: 2.5467 - val_accuracy: 0.4167\n",
      "Epoch 985/1000\n",
      "700/700 [==============================] - 0s 60us/step - loss: 0.6400 - accuracy: 0.7657 - val_loss: 2.6128 - val_accuracy: 0.4000\n",
      "Epoch 986/1000\n",
      "700/700 [==============================] - 0s 60us/step - loss: 0.6404 - accuracy: 0.7600 - val_loss: 2.6047 - val_accuracy: 0.4033\n",
      "Epoch 987/1000\n",
      "700/700 [==============================] - 0s 60us/step - loss: 0.6407 - accuracy: 0.7643 - val_loss: 2.5718 - val_accuracy: 0.4100\n",
      "Epoch 988/1000\n",
      "700/700 [==============================] - 0s 58us/step - loss: 0.6386 - accuracy: 0.7643 - val_loss: 2.5567 - val_accuracy: 0.4167\n",
      "Epoch 989/1000\n",
      "700/700 [==============================] - 0s 57us/step - loss: 0.6393 - accuracy: 0.7686 - val_loss: 2.5462 - val_accuracy: 0.4267\n",
      "Epoch 990/1000\n",
      "700/700 [==============================] - 0s 57us/step - loss: 0.6386 - accuracy: 0.7700 - val_loss: 2.5716 - val_accuracy: 0.4100\n",
      "Epoch 991/1000\n",
      "700/700 [==============================] - 0s 58us/step - loss: 0.6392 - accuracy: 0.7629 - val_loss: 2.6212 - val_accuracy: 0.4033\n",
      "Epoch 992/1000\n",
      "700/700 [==============================] - 0s 56us/step - loss: 0.6388 - accuracy: 0.7643 - val_loss: 2.5635 - val_accuracy: 0.4133\n",
      "Epoch 993/1000\n",
      "700/700 [==============================] - ETA: 0s - loss: 1.1492 - accuracy: 0.60 - 0s 60us/step - loss: 0.6381 - accuracy: 0.7743 - val_loss: 2.5774 - val_accuracy: 0.4100\n",
      "Epoch 994/1000\n",
      "700/700 [==============================] - 0s 56us/step - loss: 0.6384 - accuracy: 0.7643 - val_loss: 2.5836 - val_accuracy: 0.4033\n",
      "Epoch 995/1000\n",
      "700/700 [==============================] - 0s 58us/step - loss: 0.6387 - accuracy: 0.7671 - val_loss: 2.5711 - val_accuracy: 0.4067\n",
      "Epoch 996/1000\n",
      "700/700 [==============================] - 0s 58us/step - loss: 0.6381 - accuracy: 0.7686 - val_loss: 2.5677 - val_accuracy: 0.4133\n",
      "Epoch 997/1000\n",
      "700/700 [==============================] - 0s 58us/step - loss: 0.6380 - accuracy: 0.7643 - val_loss: 2.5707 - val_accuracy: 0.4200\n",
      "Epoch 998/1000\n",
      "700/700 [==============================] - 0s 58us/step - loss: 0.6379 - accuracy: 0.7643 - val_loss: 2.5524 - val_accuracy: 0.4167\n",
      "Epoch 999/1000\n",
      "700/700 [==============================] - 0s 58us/step - loss: 0.6379 - accuracy: 0.7657 - val_loss: 2.6262 - val_accuracy: 0.3900\n",
      "Epoch 1000/1000\n",
      "700/700 [==============================] - 0s 58us/step - loss: 0.6380 - accuracy: 0.7614 - val_loss: 2.5959 - val_accuracy: 0.4100\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#0\n",
    "from keras.utils import np_utils\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation\n",
    "import numpy as np\n",
    "\n",
    "np.random.seed(3)\n",
    "\n",
    "#1\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "x_val = x_train[50000:]\n",
    "y_val = y_train[50000:]\n",
    "x_train = x_train[:50000]\n",
    "y_train = y_train[:50000]\n",
    "\n",
    "x_train = x_train.reshape(50000, 784).astype('float32') / 255.0\n",
    "x_val = x_val.reshape(10000, 784).astype('float32') / 255.0\n",
    "x_test = x_test.reshape(10000, 784).astype('float32') / 255.0\n",
    "\n",
    "train_rand_idxs = np.random.choice(50000, 700)\n",
    "val_rand_idxs = np.random.choice(10000, 300)\n",
    "x_train = x_train[train_rand_idxs]\n",
    "y_train = y_train[train_rand_idxs]\n",
    "x_val = x_val[val_rand_idxs]\n",
    "y_val = y_val[val_rand_idxs]\n",
    "\n",
    "y_train = np_utils.to_categorical(y_train)\n",
    "y_val = np_utils.to_categorical(y_val)\n",
    "y_test = np_utils.to_categorical(y_test)\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(units=2, input_dim=28*28, activation='relu'))\n",
    "model.add(Dense(units=10, activation='softmax'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer='sgd', metrics=['accuracy'])\n",
    "\n",
    "hist = model.fit(x_train, y_train, epochs=1000, batch_size=10, validation_data=(x_val, y_val))\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, loss_ax = plt.subplots()\n",
    "\n",
    "acc_ax = loss_ax.twinx()\n",
    "\n",
    "loss_ax.plot(hist.history['loss'], 'y', label='train loss')\n",
    "loss_ax.plot(hist.history['val_loss'], 'r', label='val loss')\n",
    "\n",
    "acc_ax.plot(hist.history['accuracy'], 'b', label='train acc') #KERAS 2.0 acc   -> accuracy \n",
    "acc_ax.plot(hist.history['val_accuracy'], 'g', label='val acc')#KERAS 2.0 acc   -> accuracy \n",
    "\n",
    "loss_ax.set_xlabel('epoch')\n",
    "loss_ax.set_ylabel('loss')\n",
    "acc_ax.set_ylabel('accuracy')\n",
    "\n",
    "loss_ax.legend(loc='upper left')\n",
    "acc_ax.legend(loc='lower left')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
